

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Welcome to pycaret’s documentation! &mdash; pycaret 1.0.1 documentation</title>
  

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />

  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/language_data.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="#" class="icon icon-home" alt="Documentation Home"> pycaret
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <!-- Local TOC -->
              <div class="local-toc"><ul>
<li><a class="reference internal" href="#">Welcome to pycaret’s documentation!</a></li>
<li><a class="reference internal" href="#module-pycaret.regression">Regression</a></li>
<li><a class="reference internal" href="#module-pycaret.classification">Classification</a></li>
<li><a class="reference internal" href="#module-pycaret.nlp">NLP</a></li>
<li><a class="reference internal" href="#module-pycaret.clustering">Clustering</a></li>
<li><a class="reference internal" href="#module-pycaret.anomaly">Anomaly</a></li>
<li><a class="reference internal" href="#module-pycaret.datasets">Datasets</a></li>
<li><a class="reference internal" href="#module-pycaret.arules">Arules</a></li>
<li><a class="reference internal" href="#indices-and-tables">Indices and tables</a></li>
</ul>
</div>
            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="#">pycaret</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="#" class="icon icon-home"></a> &raquo;</li>
        
      <li>Welcome to pycaret’s documentation!</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/index.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="welcome-to-pycaret-s-documentation">
<h1>Welcome to pycaret’s documentation!<a class="headerlink" href="#welcome-to-pycaret-s-documentation" title="Permalink to this headline">¶</a></h1>
<p>PyCaret is an open source low-code machine learning library in Python that aims to reduce the hypothesis to insights cycle time in a ML experiment. It enables data scientists to perform end-to-end experiments quickly and efficiently. In comparison with the other open source machine learning libraries, PyCaret is an alternate low-code library that can be used to perform complex machine learning tasks with only few lines of code. PyCaret is essentially a Python wrapper around several machine learning libraries and frameworks such as scikit-learn, XGBoost, Microsoft LightGBM, spaCy and many more.</p>
<p>The design and simplicity of PyCaret is inspired by the emerging role of citizen data scientists, a term first used by Gartner. Citizen Data Scientists are power users who can perform both simple and moderately sophisticated analytical tasks that would previously have required more expertise. Seasoned data scientists are often difficult to find and expensive to hire but citizen data scientists can be an effective way to mitigate this gap and address data related challenges in business setting.</p>
<p>PyCaret is simple, easy to use and deployment ready. All the steps performed in a ML experiment can be reproduced using a pipeline that is automatically developed and orchestrated in PyCaret as you progress through the experiment. A pipeline can be saved in a binary file format that is transferable across environments.</p>
<p>For more information on PyCaret, please visit our official website <a class="reference external" href="https://www.pycaret.org">https://www.pycaret.org</a></p>
<div class="toctree-wrapper compound">
</div>
</div>
<div class="section" id="module-pycaret.regression">
<span id="regression"></span><h1>Regression<a class="headerlink" href="#module-pycaret.regression" title="Permalink to this headline">¶</a></h1>
<dl class="py function">
<dt id="pycaret.regression.automl">
<code class="sig-prename descclassname">pycaret.regression.</code><code class="sig-name descname">automl</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">optimize</span><span class="o">=</span><span class="default_value">'R2'</span></em>, <em class="sig-param"><span class="n">use_holdout</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.regression.automl" title="Permalink to this definition">¶</a></dt>
<dd><p>This function returns the best model out of all models created in
current active environment based on metric defined in optimize parameter.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>optimize</strong> (<em>string</em><em>, </em><em>default = 'R2'</em>) – Other values you can pass in optimize param are ‘MAE’, ‘MSE’, ‘RMSE’,
‘RMSLE’, and ‘MAPE’.</p></li>
<li><p><strong>use_holdout</strong> (<em>bool</em><em>, </em><em>default = False</em>) – When set to True, metrics are evaluated on holdout set instead of CV.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pycaret.regression.blend_models">
<code class="sig-prename descclassname">pycaret.regression.</code><code class="sig-name descname">blend_models</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">estimator_list</span><span class="o">=</span><span class="default_value">'All'</span></em>, <em class="sig-param"><span class="n">fold</span><span class="o">=</span><span class="default_value">10</span></em>, <em class="sig-param"><span class="n">round</span><span class="o">=</span><span class="default_value">4</span></em>, <em class="sig-param"><span class="n">choose_better</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">optimize</span><span class="o">=</span><span class="default_value">'R2'</span></em>, <em class="sig-param"><span class="n">turbo</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.regression.blend_models" title="Permalink to this definition">¶</a></dt>
<dd><p>This function creates an ensemble meta-estimator that fits a base regressor on
the whole dataset. It then averages the predictions to form a final prediction.
By default, this function will use all estimators in the model library (excl.
the few estimators when turbo is True) or a specific trained estimator passed
as a list in estimator_list param. It scores it using Kfold Cross Validation.
The output prints the score grid that shows MAE, MSE, RMSE, R2, RMSLE and MAPE
by fold (default = 10 Fold).</p>
<p>This function returns a trained model object.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pycaret.datasets</span> <span class="kn">import</span> <span class="n">get_data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">boston</span> <span class="o">=</span> <span class="n">get_data</span><span class="p">(</span><span class="s1">&#39;boston&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">experiment_name</span> <span class="o">=</span> <span class="n">setup</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">boston</span><span class="p">,</span>  <span class="n">target</span> <span class="o">=</span> <span class="s1">&#39;medv&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">blend_all</span> <span class="o">=</span> <span class="n">blend_models</span><span class="p">()</span>
</pre></div>
</div>
<p>This will result in VotingRegressor for all models in the library except ‘ard’,
‘kr’ and ‘mlp’.</p>
<p>For specific models, you can use:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">lr</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">(</span><span class="s1">&#39;lr&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rf</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">(</span><span class="s1">&#39;rf&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">knn</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">(</span><span class="s1">&#39;knn&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">blend_three</span> <span class="o">=</span> <span class="n">blend_models</span><span class="p">(</span><span class="n">estimator_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">lr</span><span class="p">,</span><span class="n">rf</span><span class="p">,</span><span class="n">knn</span><span class="p">])</span>
</pre></div>
</div>
<p>This will create a VotingRegressor of lr, rf and knn.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>estimator_list</strong> (<em>string</em><em> (</em><em>'All'</em><em>) or </em><em>list of objects</em><em>, </em><em>default = 'All'</em>) – </p></li>
<li><p><strong>fold</strong> (<em>integer</em><em>, </em><em>default = 10</em>) – Number of folds to be used in Kfold CV. Must be at least 2.</p></li>
<li><p><strong>round</strong> (<em>integer</em><em>, </em><em>default = 4</em>) – Number of decimal places the metrics in the score grid will be rounded to.</p></li>
<li><p><strong>choose_better</strong> (<em>Boolean</em><em>, </em><em>default = False</em>) – When set to True, base estimator is returned when the metric doesn’t
improve by ensemble_model. This gurantees the returned object would perform
atleast equivalent to base estimator created using create_model or model
returned by compare_models.</p></li>
<li><p><strong>optimize</strong> (<em>string</em><em>, </em><em>default = 'R2'</em>) – Only used when choose_better is set to True. optimize parameter is used
to compare emsembled model with base estimator. Values accepted in
optimize parameter are ‘MAE’, ‘MSE’, ‘RMSE’, ‘R2’, ‘RMSLE’, ‘MAPE’.</p></li>
<li><p><strong>turbo</strong> (<em>Boolean</em><em>, </em><em>default = True</em>) – When turbo is set to True, it blacklists estimator that uses Radial Kernel.</p></li>
<li><p><strong>verbose</strong> (<em>Boolean</em><em>, </em><em>default = True</em>) – Score grid is not printed when verbose is set to False.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><em>score_grid</em> – A table containing the scores of the model across the kfolds.
Scoring metrics used are MAE, MSE, RMSE, R2, RMSLE and MAPE.
Mean and standard deviation of the scores across the folds are
also returned.</p></li>
<li><p><em>model</em> – Trained Voting Regressor model object.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pycaret.regression.compare_models">
<code class="sig-prename descclassname">pycaret.regression.</code><code class="sig-name descname">compare_models</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">blacklist</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">whitelist</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">fold</span><span class="o">=</span><span class="default_value">10</span></em>, <em class="sig-param"><span class="n">round</span><span class="o">=</span><span class="default_value">4</span></em>, <em class="sig-param"><span class="n">sort</span><span class="o">=</span><span class="default_value">'R2'</span></em>, <em class="sig-param"><span class="n">n_select</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">turbo</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.regression.compare_models" title="Permalink to this definition">¶</a></dt>
<dd><p>This function train all the models available in the model library and scores them
using Kfold Cross Validation. The output prints a score grid with MAE, MSE
RMSE, R2, RMSLE and MAPE (averaged accross folds), determined by fold parameter.</p>
<p>This function returns the best model based on metric defined in sort parameter.</p>
<p>To select top N models, use n_select parameter that is set to 1 by default.
Where n_select parameter &gt; 1, it will return a list of trained model objects.</p>
<p>When turbo is set to True (‘kr’, ‘ard’ and ‘mlp’) are excluded due to longer
training times. By default turbo param is set to True.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pycaret.datasets</span> <span class="kn">import</span> <span class="n">get_data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">boston</span> <span class="o">=</span> <span class="n">get_data</span><span class="p">(</span><span class="s1">&#39;boston&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">experiment_name</span> <span class="o">=</span> <span class="n">setup</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">boston</span><span class="p">,</span>  <span class="n">target</span> <span class="o">=</span> <span class="s1">&#39;medv&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">best_model</span> <span class="o">=</span> <span class="n">compare_models</span><span class="p">()</span>
</pre></div>
</div>
<p>This will return the averaged score grid of all models except ‘kr’, ‘ard’
and ‘mlp’. When turbo param is set to False, all models including ‘kr’,
‘ard’ and ‘mlp’ are used, but this may result in longer training times.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">best_model</span> <span class="o">=</span> <span class="n">compare_models</span><span class="p">(</span><span class="n">blacklist</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;knn&#39;</span><span class="p">,</span><span class="s1">&#39;gbr&#39;</span><span class="p">],</span> <span class="n">turbo</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
<p>This will return a comparison of all models except K Nearest Neighbour and
Gradient Boosting Regressor.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">best_model</span> <span class="o">=</span> <span class="n">compare_models</span><span class="p">(</span><span class="n">blacklist</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;knn&#39;</span><span class="p">,</span><span class="s1">&#39;gbr&#39;</span><span class="p">]</span> <span class="p">,</span> <span class="n">turbo</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<p>This will return a comparison of all models except K Nearest Neighbour,
Gradient Boosting Regressor, Kernel Ridge Regressor, Automatic Relevance
Determinant and Multi Level Perceptron.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>blacklist</strong> (<em>list of strings</em><em>, </em><em>default = None</em>) – In order to omit certain models from the comparison model ID’s can be passed as
a list of strings in blacklist param.</p></li>
<li><p><strong>whitelist</strong> (<em>list of strings</em><em>, </em><em>default = None</em>) – In order to run only certain models for the comparison, the model ID’s can be
passed as a list of strings in whitelist param.</p></li>
<li><p><strong>fold</strong> (<em>integer</em><em>, </em><em>default = 10</em>) – Number of folds to be used in Kfold CV. Must be at least 2.</p></li>
<li><p><strong>round</strong> (<em>integer</em><em>, </em><em>default = 4</em>) – Number of decimal places the metrics in the score grid will be rounded to.</p></li>
<li><p><strong>sort</strong> (<em>string</em><em>, </em><em>default = 'MAE'</em>) – The scoring measure specified is used for sorting the average score grid
Other options are ‘MAE’, ‘MSE’, ‘RMSE’, ‘R2’, ‘RMSLE’ and ‘MAPE’.</p></li>
<li><p><strong>n_select</strong> (<em>int</em><em>, </em><em>default = 1</em>) – Number of top_n models to return. use negative argument for bottom selection.
for example, n_select = -3 means bottom 3 models.</p></li>
<li><p><strong>turbo</strong> (<em>Boolean</em><em>, </em><em>default = True</em>) – When turbo is set to True, it blacklists estimators that have longer
training times.</p></li>
<li><p><strong>verbose</strong> (<em>Boolean</em><em>, </em><em>default = True</em>) – Score grid is not printed when verbose is set to False.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A table containing the scores of the model across the kfolds.
Scoring metrics used are MAE, MSE, RMSE, R2, RMSLE and MAPE
Mean and standard deviation of the scores across the folds is
also returned.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>score_grid</p>
</dd>
</dl>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<ul class="simple">
<li><p>compare_models() though attractive, might be time consuming with large
datasets. By default turbo is set to True, which blacklists models that
have longer training times. Changing turbo parameter to False may result
in very high training times with datasets where number of samples exceed
10,000.</p></li>
</ul>
</div>
</dd></dl>

<dl class="py function">
<dt id="pycaret.regression.create_model">
<code class="sig-prename descclassname">pycaret.regression.</code><code class="sig-name descname">create_model</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">estimator</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">ensemble</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">method</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">fold</span><span class="o">=</span><span class="default_value">10</span></em>, <em class="sig-param"><span class="n">round</span><span class="o">=</span><span class="default_value">4</span></em>, <em class="sig-param"><span class="n">cross_validation</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">system</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.regression.create_model" title="Permalink to this definition">¶</a></dt>
<dd><p>This function creates a model and scores it using Kfold Cross Validation.
The output prints a score grid that shows MAE, MSE, RMSE, RMSLE, R2 and
MAPE by fold (default = 10 Fold).</p>
<p>This function returns a trained model object.</p>
<p>setup() function must be called before using create_model()</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pycaret.datasets</span> <span class="kn">import</span> <span class="n">get_data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">boston</span> <span class="o">=</span> <span class="n">get_data</span><span class="p">(</span><span class="s1">&#39;boston&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">experiment_name</span> <span class="o">=</span> <span class="n">setup</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">boston</span><span class="p">,</span>  <span class="n">target</span> <span class="o">=</span> <span class="s1">&#39;medv&#39;</span><span class="p">)</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">lr</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">(</span><span class="s1">&#39;lr&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>This will create a trained Linear Regression model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>estimator</strong> (<em>string / object</em><em>, </em><em>default = None</em>) – <p>Enter ID of the estimators available in model library or pass an untrained model
object consistent with fit / predict API to train and evaluate model. All estimators
support binary or multiclass problem. List of estimators in model library:</p>
<p>ID          Name
——–    ———-
‘lr’        Linear Regression
‘lasso’     Lasso Regression
‘ridge’     Ridge Regression
‘en’        Elastic Net
‘lar’       Least Angle Regression
‘llar’      Lasso Least Angle Regression
‘omp’       Orthogonal Matching Pursuit
‘br’        Bayesian Ridge
‘ard’       Automatic Relevance Determination
‘par’       Passive Aggressive Regressor
‘ransac’    Random Sample Consensus
‘tr’        TheilSen Regressor
‘huber’     Huber Regressor
‘kr’        Kernel Ridge
‘svm’       Support Vector Machine
‘knn’       K Neighbors Regressor
‘dt’        Decision Tree
‘rf’        Random Forest
‘et’        Extra Trees Regressor
‘ada’       AdaBoost Regressor
‘gbr’       Gradient Boosting Regressor
‘mlp’       Multi Level Perceptron
‘xgboost’   Extreme Gradient Boosting
‘lightgbm’  Light Gradient Boosting
‘catboost’  CatBoost Regressor</p>
</p></li>
<li><p><strong>ensemble</strong> (<em>Boolean</em><em>, </em><em>default = False</em>) – True would result in an ensemble of estimator using the method parameter defined.</p></li>
<li><p><strong>method</strong> (<em>String</em><em>, </em><em>'Bagging'</em><em> or </em><em>'Boosting'</em><em>, </em><em>default = None.</em>) – method must be defined when ensemble is set to True. Default method is set to None.</p></li>
<li><p><strong>fold</strong> (<em>integer</em><em>, </em><em>default = 10</em>) – Number of folds to be used in Kfold CV. Must be at least 2.</p></li>
<li><p><strong>round</strong> (<em>integer</em><em>, </em><em>default = 4</em>) – Number of decimal places the metrics in the score grid will be rounded to.</p></li>
<li><p><strong>cross_validation</strong> (<em>bool</em><em>, </em><em>default = True</em>) – When cross_validation set to False fold parameter is ignored and model is trained
on entire training dataset. No metric evaluation is returned.</p></li>
<li><p><strong>verbose</strong> (<em>Boolean</em><em>, </em><em>default = True</em>) – Score grid is not printed when verbose is set to False.</p></li>
<li><p><strong>system</strong> (<em>Boolean</em><em>, </em><em>default = True</em>) – Must remain True all times. Only to be changed by internal functions.</p></li>
<li><p><strong>**kwargs</strong> – Additional keyword arguments to pass to the estimator.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><em>score_grid</em> – A table containing the scores of the model across the kfolds.
Scoring metrics used are MAE, MSE, RMSE, RMSLE, R2 and MAPE.
Mean and standard deviation of the scores across the folds are
also returned.</p></li>
<li><p><em>model</em> – Trained model object.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pycaret.regression.deploy_model">
<code class="sig-prename descclassname">pycaret.regression.</code><code class="sig-name descname">deploy_model</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">model</span></em>, <em class="sig-param"><span class="n">model_name</span></em>, <em class="sig-param"><span class="n">authentication</span></em>, <em class="sig-param"><span class="n">platform</span><span class="o">=</span><span class="default_value">'aws'</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.regression.deploy_model" title="Permalink to this definition">¶</a></dt>
<dd><p>(In Preview)</p>
<p>This function deploys the transformation pipeline and trained model object for
production use. The platform of deployment can be defined under the platform
param along with the applicable authentication tokens which are passed as a
dictionary to the authentication param.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pycaret.datasets</span> <span class="kn">import</span> <span class="n">get_data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">boston</span> <span class="o">=</span> <span class="n">get_data</span><span class="p">(</span><span class="s1">&#39;boston&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">experiment_name</span> <span class="o">=</span> <span class="n">setup</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">boston</span><span class="p">,</span>  <span class="n">target</span> <span class="o">=</span> <span class="s1">&#39;medv&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lr</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">(</span><span class="s1">&#39;lr&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">deploy_model</span><span class="p">(</span><span class="n">model</span> <span class="o">=</span> <span class="n">lr</span><span class="p">,</span> <span class="n">model_name</span> <span class="o">=</span> <span class="s1">&#39;deploy_lr&#39;</span><span class="p">,</span> <span class="n">platform</span> <span class="o">=</span> <span class="s1">&#39;aws&#39;</span><span class="p">,</span> <span class="n">authentication</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;bucket&#39;</span> <span class="p">:</span> <span class="s1">&#39;pycaret-test&#39;</span><span class="p">})</span>
</pre></div>
</div>
<p>This will deploy the model on AWS S3 account under bucket ‘pycaret-test’</p>
<p class="rubric">Notes</p>
<p>For AWS users:
Before deploying a model to an AWS S3 (‘aws’), environment variables must be
configured using the command line interface. To configure AWS env. variables,
type aws configure in your python command line. The following information is
required which can be generated using the Identity and Access Management (IAM)
portal of your amazon console account:</p>
<ul class="simple">
<li><p>AWS Access Key ID</p></li>
<li><p>AWS Secret Key Access</p></li>
<li><p>Default Region Name (can be seen under Global settings on your AWS console)</p></li>
<li><p>Default output format (must be left blank)</p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>object</em>) – A trained model object should be passed as an estimator.</p></li>
<li><p><strong>model_name</strong> (<em>string</em>) – Name of model to be passed as a string.</p></li>
<li><p><strong>authentication</strong> (<em>dict</em>) – <p>Dictionary of applicable authentication tokens.</p>
<p>When platform = ‘aws’:
{‘bucket’ : ‘Name of Bucket on S3’}</p>
</p></li>
<li><p><strong>platform</strong> (<em>string</em><em>, </em><em>default = 'aws'</em>) – Name of platform for deployment. Current available options are: ‘aws’.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Success_Message</p>
</dd>
</dl>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<ul class="simple">
<li><p>This function uses file storage services to deploy the model on cloud platform.
As such, this is efficient for batch-use. Where the production objective is to
obtain prediction at an instance level, this may not be the efficient choice as
it transmits the binary pickle file between your local python environment and
the platform.</p></li>
</ul>
</div>
</dd></dl>

<dl class="py function">
<dt id="pycaret.regression.ensemble_model">
<code class="sig-prename descclassname">pycaret.regression.</code><code class="sig-name descname">ensemble_model</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">estimator</span></em>, <em class="sig-param"><span class="n">method</span><span class="o">=</span><span class="default_value">'Bagging'</span></em>, <em class="sig-param"><span class="n">fold</span><span class="o">=</span><span class="default_value">10</span></em>, <em class="sig-param"><span class="n">n_estimators</span><span class="o">=</span><span class="default_value">10</span></em>, <em class="sig-param"><span class="n">round</span><span class="o">=</span><span class="default_value">4</span></em>, <em class="sig-param"><span class="n">choose_better</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">optimize</span><span class="o">=</span><span class="default_value">'R2'</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.regression.ensemble_model" title="Permalink to this definition">¶</a></dt>
<dd><p>This function ensembles the trained base estimator using the method defined
in ‘method’ param (default = ‘Bagging’). The output prints a score grid that
shows MAE, MSE, RMSE, R2, RMSLE and MAPE by fold (default CV = 10 Folds).</p>
<p>This function returns a trained model object.</p>
<p>Model must be created using create_model() or tune_model().</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pycaret.datasets</span> <span class="kn">import</span> <span class="n">get_data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">boston</span> <span class="o">=</span> <span class="n">get_data</span><span class="p">(</span><span class="s1">&#39;boston&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">experiment_name</span> <span class="o">=</span> <span class="n">setup</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">boston</span><span class="p">,</span>  <span class="n">target</span> <span class="o">=</span> <span class="s1">&#39;medv&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dt</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">(</span><span class="s1">&#39;dt&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ensembled_dt</span> <span class="o">=</span> <span class="n">ensemble_model</span><span class="p">(</span><span class="n">dt</span><span class="p">)</span>
</pre></div>
</div>
<p>This will return an ensembled Decision Tree model using ‘Bagging’.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>estimator</strong> (<em>object</em><em>, </em><em>default = None</em>) – </p></li>
<li><p><strong>method</strong> (<em>String</em><em>, </em><em>default = 'Bagging'</em>) – Bagging method will create an ensemble meta-estimator that fits base
regressor each on random subsets of the original dataset. The other
available method is ‘Boosting’ that fits a regressor on the original
dataset and then fits additional copies of the regressor on the same
dataset but where the weights of instances are adjusted according to
the error of the current prediction. As such, subsequent regressors
focus more on difficult cases.</p></li>
<li><p><strong>fold</strong> (<em>integer</em><em>, </em><em>default = 10</em>) – Number of folds to be used in Kfold CV. Must be at least 2.</p></li>
<li><p><strong>n_estimators</strong> (<em>integer</em><em>, </em><em>default = 10</em>) – The number of base estimators in the ensemble.
In case of perfect fit, the learning procedure is stopped early.</p></li>
<li><p><strong>round</strong> (<em>integer</em><em>, </em><em>default = 4</em>) – Number of decimal places the metrics in the score grid will be rounded to.</p></li>
<li><p><strong>choose_better</strong> (<em>Boolean</em><em>, </em><em>default = False</em>) – When set to set to True, base estimator is returned when the metric doesn’t
improve by ensemble_model. This gurantees the returned object would perform
atleast equivalent to base estimator created using create_model or model
returned by compare_models.</p></li>
<li><p><strong>optimize</strong> (<em>string</em><em>, </em><em>default = 'R2'</em>) – Only used when choose_better is set to True. optimize parameter is used
to compare emsembled model with base estimator. Values accepted in
optimize parameter are ‘MAE’, ‘MSE’, ‘RMSE’, ‘R2’, ‘RMSLE’, ‘MAPE’.</p></li>
<li><p><strong>verbose</strong> (<em>Boolean</em><em>, </em><em>default = True</em>) – Score grid is not printed when verbose is set to False.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><em>score_grid</em> – A table containing the scores of the model across the kfolds.
Scoring metrics used are MAE, MSE, RMSE, R2, RMSLE and MAPE.
Mean and standard deviation of the scores across the folds are
also returned.</p></li>
<li><p><em>model</em> – Trained ensembled model object.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pycaret.regression.evaluate_model">
<code class="sig-prename descclassname">pycaret.regression.</code><code class="sig-name descname">evaluate_model</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">estimator</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.regression.evaluate_model" title="Permalink to this definition">¶</a></dt>
<dd><p>This function displays a user interface for all of the available plots for
a given estimator. It internally uses the plot_model() function.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pycaret.datasets</span> <span class="kn">import</span> <span class="n">get_data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">boston</span> <span class="o">=</span> <span class="n">get_data</span><span class="p">(</span><span class="s1">&#39;boston&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">experiment_name</span> <span class="o">=</span> <span class="n">setup</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">boston</span><span class="p">,</span>  <span class="n">target</span> <span class="o">=</span> <span class="s1">&#39;medv&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lr</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">(</span><span class="s1">&#39;lr&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">evaluate_model</span><span class="p">(</span><span class="n">lr</span><span class="p">)</span>
</pre></div>
</div>
<p>This will display the User Interface for all of the plots for a given
estimator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>estimator</strong> (<em>object</em><em>, </em><em>default = none</em>) – A trained model object should be passed as an estimator.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Displays the user interface for plotting.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>User_Interface</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pycaret.regression.finalize_model">
<code class="sig-prename descclassname">pycaret.regression.</code><code class="sig-name descname">finalize_model</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">estimator</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.regression.finalize_model" title="Permalink to this definition">¶</a></dt>
<dd><p>This function fits the estimator onto the complete dataset passed during the
setup() stage. The purpose of this function is to prepare for final model
deployment after experimentation.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pycaret.datasets</span> <span class="kn">import</span> <span class="n">get_data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">boston</span> <span class="o">=</span> <span class="n">get_data</span><span class="p">(</span><span class="s1">&#39;boston&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">experiment_name</span> <span class="o">=</span> <span class="n">setup</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">boston</span><span class="p">,</span>  <span class="n">target</span> <span class="o">=</span> <span class="s1">&#39;medv&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lr</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">(</span><span class="s1">&#39;lr&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">final_lr</span> <span class="o">=</span> <span class="n">finalize_model</span><span class="p">(</span><span class="n">lr</span><span class="p">)</span>
</pre></div>
</div>
<p>This will return the final model object fitted to complete dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>estimator</strong> (<em>object</em><em>, </em><em>default = none</em>) – A trained model object should be passed as an estimator.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Trained model object fitted on complete dataset.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>model</p>
</dd>
</dl>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<ul class="simple">
<li><p>If the model returned by finalize_model(), is used on predict_model() without
passing a new unseen dataset, then the information grid printed is misleading
as the model is trained on the complete dataset including test / hold-out sample.
Once finalize_model() is used, the model is considered ready for deployment and
should be used on new unseens dataset only.</p></li>
</ul>
</div>
</dd></dl>

<dl class="py function">
<dt id="pycaret.regression.get_config">
<code class="sig-prename descclassname">pycaret.regression.</code><code class="sig-name descname">get_config</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">variable</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.regression.get_config" title="Permalink to this definition">¶</a></dt>
<dd><p>This function is used to access global environment variables.
Following variables can be accessed:</p>
<ul class="simple">
<li><p>X: Transformed dataset (X)</p></li>
<li><p>y: Transformed dataset (y)</p></li>
<li><p>X_train: Transformed train dataset (X)</p></li>
<li><p>X_test: Transformed test/holdout dataset (X)</p></li>
<li><p>y_train: Transformed train dataset (y)</p></li>
<li><p>y_test: Transformed test/holdout dataset (y)</p></li>
<li><p>seed: random state set through session_id</p></li>
<li><p>prep_pipe: Transformation pipeline configured through setup</p></li>
<li><p>target_inverse_transformer: Target variable inverse transformer</p></li>
<li><p>folds_shuffle_param: shuffle parameter used in Kfolds</p></li>
<li><p>n_jobs_param: n_jobs parameter used in model training</p></li>
<li><p>html_param: html_param configured through setup</p></li>
<li><p>create_model_container: results grid storage container</p></li>
<li><p>master_model_container: model storage container</p></li>
<li><p>display_container: results display container</p></li>
<li><p>exp_name_log: Name of experiment set through setup</p></li>
<li><p>logging_param: log_experiment param set through setup</p></li>
<li><p>log_plots_param: log_plots param set through setup</p></li>
<li><p>USI: Unique session ID parameter set through setup</p></li>
</ul>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">X_train</span> <span class="o">=</span> <span class="n">get_config</span><span class="p">(</span><span class="s1">&#39;X_train&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>This will return X_train transformed dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>variable</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pycaret.regression.get_logs">
<code class="sig-prename descclassname">pycaret.regression.</code><code class="sig-name descname">get_logs</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">experiment_name</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">save</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.regression.get_logs" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a table with experiment logs consisting
run details, parameter, metrics and tags.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">logs</span> <span class="o">=</span> <span class="n">get_logs</span><span class="p">()</span>
</pre></div>
</div>
<p>This will return pandas dataframe.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>experiment_name</strong> (<em>string</em><em>, </em><em>default = None</em>) – When set to None current active run is used.</p></li>
<li><p><strong>save</strong> (<em>bool</em><em>, </em><em>default = False</em>) – When set to True, csv file is saved in current directory.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>pandas.DataFrame</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pycaret.regression.get_system_logs">
<code class="sig-prename descclassname">pycaret.regression.</code><code class="sig-name descname">get_system_logs</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.regression.get_system_logs" title="Permalink to this definition">¶</a></dt>
<dd><p>Read and print ‘logs.log’ file from current active directory.</p>
</dd></dl>

<dl class="py function">
<dt id="pycaret.regression.interpret_model">
<code class="sig-prename descclassname">pycaret.regression.</code><code class="sig-name descname">interpret_model</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">estimator</span></em>, <em class="sig-param"><span class="n">plot</span><span class="o">=</span><span class="default_value">'summary'</span></em>, <em class="sig-param"><span class="n">feature</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">observation</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.regression.interpret_model" title="Permalink to this definition">¶</a></dt>
<dd><p>This function takes a trained model object and returns an interpretation plot
based on the test / hold-out set. It only supports tree based algorithms.</p>
<p>This function is implemented based on the SHAP (SHapley Additive exPlanations),
which is a unified approach to explain the output of any machine learning model.
SHAP connects game theory with local explanations.</p>
<p>For more information : <a class="reference external" href="https://shap.readthedocs.io/en/latest/">https://shap.readthedocs.io/en/latest/</a></p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pycaret.datasets</span> <span class="kn">import</span> <span class="n">get_data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">boston</span> <span class="o">=</span> <span class="n">get_data</span><span class="p">(</span><span class="s1">&#39;boston&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">experiment_name</span> <span class="o">=</span> <span class="n">setup</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">boston</span><span class="p">,</span>  <span class="n">target</span> <span class="o">=</span> <span class="s1">&#39;medv&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dt</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">(</span><span class="s1">&#39;dt&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">interpret_model</span><span class="p">(</span><span class="n">dt</span><span class="p">)</span>
</pre></div>
</div>
<p>This will return a summary interpretation plot of Decision Tree model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>estimator</strong> (<em>object</em><em>, </em><em>default = none</em>) – A trained tree based model object should be passed as an estimator.</p></li>
<li><p><strong>plot</strong> (<em>string</em><em>, </em><em>default = 'summary'</em>) – Other available options are ‘correlation’ and ‘reason’.</p></li>
<li><p><strong>feature</strong> (<em>string</em><em>, </em><em>default = None</em>) – This parameter is only needed when plot = ‘correlation’. By default feature is
set to None which means the first column of the dataset will be used as a variable.
A feature parameter must be passed to change this.</p></li>
<li><p><strong>observation</strong> (<em>integer</em><em>, </em><em>default = None</em>) – This parameter only comes into effect when plot is set to ‘reason’. If no observation
number is provided, it will return an analysis of all observations with the option
to select the feature on x and y axes through drop down interactivity. For analysis at
the sample level, an observation parameter must be passed with the index value of the
observation in test / hold-out set.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Returns the visual plot.
Returns the interactive JS plot when plot = ‘reason’.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Visual_Plot</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pycaret.regression.load_model">
<code class="sig-prename descclassname">pycaret.regression.</code><code class="sig-name descname">load_model</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">model_name</span></em>, <em class="sig-param"><span class="n">platform</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">authentication</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.regression.load_model" title="Permalink to this definition">¶</a></dt>
<dd><p>This function loads a previously saved transformation pipeline and model
from the current active directory into the current python environment.
Load object must be a pickle file.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">saved_lr</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="s1">&#39;lr_model_23122019&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>This will load the previously saved model in saved_lr variable. The file
must be in the current directory.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_name</strong> (<em>string</em><em>, </em><em>default = none</em>) – Name of pickle file to be passed as a string.</p></li>
<li><p><strong>platform</strong> (<em>string</em><em>, </em><em>default = None</em>) – Name of platform, if loading model from cloud. Current available options are:
‘aws’.</p></li>
<li><p><strong>authentication</strong> (<em>dict</em>) – <p>dictionary of applicable authentication tokens.</p>
<p>When platform = ‘aws’:
{‘bucket’ : ‘Name of Bucket on S3’}</p>
</p></li>
<li><p><strong>verbose</strong> (<em>Boolean</em><em>, </em><em>default = True</em>) – Success message is not printed when verbose is set to False.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Success_Message</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pycaret.regression.models">
<code class="sig-prename descclassname">pycaret.regression.</code><code class="sig-name descname">models</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">type</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.regression.models" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns table of models available in model library.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">all_models</span> <span class="o">=</span> <span class="n">models</span><span class="p">()</span>
</pre></div>
</div>
<p>This will return pandas dataframe with all available
models and their metadata.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>type</strong> (<em>string</em><em>, </em><em>default = None</em>) – <ul class="simple">
<li><p>linear : filters and only return linear models</p></li>
<li><p>tree : filters and only return tree based models</p></li>
<li><p>ensemble : filters and only return ensemble models</p></li>
</ul>
</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>pandas.DataFrame</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pycaret.regression.plot_model">
<code class="sig-prename descclassname">pycaret.regression.</code><code class="sig-name descname">plot_model</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">estimator</span></em>, <em class="sig-param"><span class="n">plot</span><span class="o">=</span><span class="default_value">'residuals'</span></em>, <em class="sig-param"><span class="n">save</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">system</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.regression.plot_model" title="Permalink to this definition">¶</a></dt>
<dd><p>This function takes a trained model object and returns a plot based on the
test / hold-out set. The process may require the model to be re-trained in
certain cases. See list of plots supported below.</p>
<p>Model must be created using create_model() or tune_model().</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pycaret.datasets</span> <span class="kn">import</span> <span class="n">get_data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">boston</span> <span class="o">=</span> <span class="n">get_data</span><span class="p">(</span><span class="s1">&#39;boston&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">experiment_name</span> <span class="o">=</span> <span class="n">setup</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">boston</span><span class="p">,</span>  <span class="n">target</span> <span class="o">=</span> <span class="s1">&#39;medv&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lr</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">(</span><span class="s1">&#39;lr&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">plot_model</span><span class="p">(</span><span class="n">lr</span><span class="p">)</span>
</pre></div>
</div>
<p>This will return an residuals plot of a trained Linear Regression model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>estimator</strong> (<em>object</em><em>, </em><em>default = none</em>) – A trained model object should be passed as an estimator.</p></li>
<li><p><strong>plot</strong> (<em>string</em><em>, </em><em>default = residual</em>) – <p>Enter abbreviation of type of plot. The current list of plots supported are:</p>
<p>Plot            Name
——          ———
‘residuals’     Residuals Plot
‘error’         Prediction Error Plot
‘cooks’         Cooks Distance Plot
‘rfe’           Recursive Feat. Selection
‘learning’      Learning Curve
‘vc’            Validation Curve
‘manifold’      Manifold Learning
‘feature’       Feature Importance
‘parameter’     Model Hyperparameter</p>
</p></li>
<li><p><strong>save</strong> (<em>Boolean</em><em>, </em><em>default = False</em>) – When set to True, Plot is saved as a ‘png’ file in current working directory.</p></li>
<li><p><strong>verbose</strong> (<em>Boolean</em><em>, </em><em>default = True</em>) – Progress bar not shown when verbose set to False.</p></li>
<li><p><strong>system</strong> (<em>Boolean</em><em>, </em><em>default = True</em>) – Must remain True all times. Only to be changed by internal functions.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Prints the visual plot.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Visual_Plot</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pycaret.regression.predict_model">
<code class="sig-prename descclassname">pycaret.regression.</code><code class="sig-name descname">predict_model</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">estimator</span></em>, <em class="sig-param"><span class="n">data</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">platform</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">authentication</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">round</span><span class="o">=</span><span class="default_value">4</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.regression.predict_model" title="Permalink to this definition">¶</a></dt>
<dd><p>This function is used to predict new data using a trained estimator. It accepts
an estimator created using one of the function in pycaret that returns a trained
model object or a list of trained model objects created using stack_models() or
create_stacknet(). New unseen data can be passed to data param as pandas Dataframe.
If data is not passed, the test / hold-out set separated at the time of setup() is
used to generate predictions.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pycaret.datasets</span> <span class="kn">import</span> <span class="n">get_data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">boston</span> <span class="o">=</span> <span class="n">get_data</span><span class="p">(</span><span class="s1">&#39;boston&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">experiment_name</span> <span class="o">=</span> <span class="n">setup</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">boston</span><span class="p">,</span>  <span class="n">target</span> <span class="o">=</span> <span class="s1">&#39;medv&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lr</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">(</span><span class="s1">&#39;lr&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lr_predictions_holdout</span> <span class="o">=</span> <span class="n">predict_model</span><span class="p">(</span><span class="n">lr</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>estimator</strong> (<em>object</em><em> or </em><em>list of objects / string</em><em>,  </em><em>default = None</em>) – When estimator is passed as string, load_model() is called internally to load the
pickle file from active directory or cloud platform when platform param is passed.</p></li>
<li><p><strong>data</strong> (<em>{array-like</em><em>, </em><em>sparse matrix}</em>) – shape (n_samples, n_features) where n_samples is the number of samples and n_features is the number of features.
All features used during training must be present in the new dataset.</p></li>
<li><p><strong>platform</strong> (<em>string</em><em>, </em><em>default = None</em>) – Name of platform, if loading model from cloud. Current available options are:
‘aws’.</p></li>
<li><p><strong>authentication</strong> (<em>dict</em>) – <p>dictionary of applicable authentication tokens.</p>
<p>When platform = ‘aws’:
{‘bucket’ : ‘Name of Bucket on S3’}</p>
</p></li>
<li><p><strong>round</strong> (<em>integer</em><em>, </em><em>default = 4</em>) – Number of decimal places the predicted labels will be rounded to.</p></li>
<li><p><strong>verbose</strong> (<em>Boolean</em><em>, </em><em>default = True</em>) – Holdout score grid is not printed when verbose is set to False.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Information grid is printed when data is None.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>info_grid</p>
</dd>
</dl>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<ul class="simple">
<li><p>if the estimator passed is created using finalize_model() then the metrics
printed in the information grid maybe misleading as the model is trained on
the complete dataset including the test / hold-out set. Once finalize_model()
is used, the model is considered ready for deployment and should be used on new
unseen datasets only.</p></li>
</ul>
</div>
</dd></dl>

<dl class="py function">
<dt id="pycaret.regression.pull">
<code class="sig-prename descclassname">pycaret.regression.</code><code class="sig-name descname">pull</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.regression.pull" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns latest displayed table.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Equivalent to get_config(‘display_container’)[-1]</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>pandas.DataFrame</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pycaret.regression.save_model">
<code class="sig-prename descclassname">pycaret.regression.</code><code class="sig-name descname">save_model</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">model</span></em>, <em class="sig-param"><span class="n">model_name</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.regression.save_model" title="Permalink to this definition">¶</a></dt>
<dd><p>This function saves the transformation pipeline and trained model object
into the current active directory as a pickle file for later use.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pycaret.datasets</span> <span class="kn">import</span> <span class="n">get_data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">boston</span> <span class="o">=</span> <span class="n">get_data</span><span class="p">(</span><span class="s1">&#39;boston&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">experiment_name</span> <span class="o">=</span> <span class="n">setup</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">boston</span><span class="p">,</span>  <span class="n">target</span> <span class="o">=</span> <span class="s1">&#39;medv&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lr</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">(</span><span class="s1">&#39;lr&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">save_model</span><span class="p">(</span><span class="n">lr</span><span class="p">,</span> <span class="s1">&#39;lr_model_23122019&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>This will save the transformation pipeline and model as a binary pickle
file in the current directory.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>object</em><em>, </em><em>default = none</em>) – A trained model object should be passed as an estimator.</p></li>
<li><p><strong>model_name</strong> (<em>string</em><em>, </em><em>default = none</em>) – Name of pickle file to be passed as a string.</p></li>
<li><p><strong>verbose</strong> (<em>Boolean</em><em>, </em><em>default = True</em>) – Success message is not printed when verbose is set to False.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Success_Message</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pycaret.regression.set_config">
<code class="sig-prename descclassname">pycaret.regression.</code><code class="sig-name descname">set_config</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">variable</span></em>, <em class="sig-param"><span class="n">value</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.regression.set_config" title="Permalink to this definition">¶</a></dt>
<dd><p>This function is used to reset global environment variables.
Following variables can be accessed:</p>
<ul class="simple">
<li><p>X: Transformed dataset (X)</p></li>
<li><p>y: Transformed dataset (y)</p></li>
<li><p>X_train: Transformed train dataset (X)</p></li>
<li><p>X_test: Transformed test/holdout dataset (X)</p></li>
<li><p>y_train: Transformed train dataset (y)</p></li>
<li><p>y_test: Transformed test/holdout dataset (y)</p></li>
<li><p>seed: random state set through session_id</p></li>
<li><p>prep_pipe: Transformation pipeline configured through setup</p></li>
<li><p>target_inverse_transformer: Target variable inverse transformer</p></li>
<li><p>folds_shuffle_param: shuffle parameter used in Kfolds</p></li>
<li><p>n_jobs_param: n_jobs parameter used in model training</p></li>
<li><p>html_param: html_param configured through setup</p></li>
<li><p>create_model_container: results grid storage container</p></li>
<li><p>master_model_container: model storage container</p></li>
<li><p>display_container: results display container</p></li>
<li><p>exp_name_log: Name of experiment set through setup</p></li>
<li><p>logging_param: log_experiment param set through setup</p></li>
<li><p>log_plots_param: log_plots param set through setup</p></li>
<li><p>USI: Unique session ID parameter set through setup</p></li>
</ul>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">set_config</span><span class="p">(</span><span class="s1">&#39;seed&#39;</span><span class="p">,</span> <span class="mi">123</span><span class="p">)</span>
</pre></div>
</div>
<p>This will set the global seed to ‘123’.</p>
</dd></dl>

<dl class="py function">
<dt id="pycaret.regression.setup">
<code class="sig-prename descclassname">pycaret.regression.</code><code class="sig-name descname">setup</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">target</span></em>, <em class="sig-param"><span class="n">train_size</span><span class="o">=</span><span class="default_value">0.7</span></em>, <em class="sig-param"><span class="n">sampling</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">sample_estimator</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">categorical_features</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">categorical_imputation</span><span class="o">=</span><span class="default_value">'constant'</span></em>, <em class="sig-param"><span class="n">ordinal_features</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">high_cardinality_features</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">high_cardinality_method</span><span class="o">=</span><span class="default_value">'frequency'</span></em>, <em class="sig-param"><span class="n">numeric_features</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">numeric_imputation</span><span class="o">=</span><span class="default_value">'mean'</span></em>, <em class="sig-param"><span class="n">date_features</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">ignore_features</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">normalize</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">normalize_method</span><span class="o">=</span><span class="default_value">'zscore'</span></em>, <em class="sig-param"><span class="n">transformation</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">transformation_method</span><span class="o">=</span><span class="default_value">'yeo-johnson'</span></em>, <em class="sig-param"><span class="n">handle_unknown_categorical</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">unknown_categorical_method</span><span class="o">=</span><span class="default_value">'least_frequent'</span></em>, <em class="sig-param"><span class="n">pca</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">pca_method</span><span class="o">=</span><span class="default_value">'linear'</span></em>, <em class="sig-param"><span class="n">pca_components</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">ignore_low_variance</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">combine_rare_levels</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">rare_level_threshold</span><span class="o">=</span><span class="default_value">0.1</span></em>, <em class="sig-param"><span class="n">bin_numeric_features</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">remove_outliers</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">outliers_threshold</span><span class="o">=</span><span class="default_value">0.05</span></em>, <em class="sig-param"><span class="n">remove_multicollinearity</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">multicollinearity_threshold</span><span class="o">=</span><span class="default_value">0.9</span></em>, <em class="sig-param"><span class="n">remove_perfect_collinearity</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">create_clusters</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">cluster_iter</span><span class="o">=</span><span class="default_value">20</span></em>, <em class="sig-param"><span class="n">polynomial_features</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">polynomial_degree</span><span class="o">=</span><span class="default_value">2</span></em>, <em class="sig-param"><span class="n">trigonometry_features</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">polynomial_threshold</span><span class="o">=</span><span class="default_value">0.1</span></em>, <em class="sig-param"><span class="n">group_features</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">group_names</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">feature_selection</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">feature_selection_threshold</span><span class="o">=</span><span class="default_value">0.8</span></em>, <em class="sig-param"><span class="n">feature_interaction</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">feature_ratio</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">interaction_threshold</span><span class="o">=</span><span class="default_value">0.01</span></em>, <em class="sig-param"><span class="n">transform_target</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">transform_target_method</span><span class="o">=</span><span class="default_value">'box-cox'</span></em>, <em class="sig-param"><span class="n">data_split_shuffle</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">folds_shuffle</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">n_jobs</span><span class="o">=</span><span class="default_value">- 1</span></em>, <em class="sig-param"><span class="n">html</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">session_id</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">log_experiment</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">experiment_name</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">log_plots</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">log_profile</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">log_data</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">silent</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">profile</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.regression.setup" title="Permalink to this definition">¶</a></dt>
<dd><p>This function initializes the environment in pycaret and creates the transformation
pipeline to prepare the data for modeling and deployment. setup() must called before
executing any other function in pycaret. It takes two mandatory parameters:
dataframe {array-like, sparse matrix} and name of the target column.</p>
<p>All other parameters are optional.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pycaret.datasets</span> <span class="kn">import</span> <span class="n">get_data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">boston</span> <span class="o">=</span> <span class="n">get_data</span><span class="p">(</span><span class="s1">&#39;boston&#39;</span><span class="p">)</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">experiment_name</span> <span class="o">=</span> <span class="n">setup</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">boston</span><span class="p">,</span>  <span class="n">target</span> <span class="o">=</span> <span class="s1">&#39;medv&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>‘boston’ is a pandas DataFrame and ‘medv’ is the name of target column.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<em>{array-like</em><em>, </em><em>sparse matrix}</em>) – Shape (n_samples, n_features) where n_samples is the number of samples and n_features is the number of features.</p></li>
<li><p><strong>target</strong> (<em>string</em>) – Name of target column to be passed in as string.</p></li>
<li><p><strong>train_size</strong> (<em>float</em><em>, </em><em>default = 0.7</em>) – Size of the training set. By default, 70% of the data will be used for training
and validation. The remaining data will be used for test / hold-out set.</p></li>
<li><p><strong>sampling</strong> (<em>bool</em><em>, </em><em>default = True</em>) – When the sample size exceeds 25,000 samples, pycaret will build a base estimator
at various sample sizes from the original dataset. This will return a performance
plot of R2 values at various sample levels, that will assist in deciding the
preferred sample size for modeling.  The desired sample size must then be entered
for training and validation in the  pycaret environment. When sample_size entered
is less than 1, the remaining dataset (1 - sample) is used for fitting the model
only when finalize_model() is called.</p></li>
<li><p><strong>sample_estimator</strong> (<em>object</em><em>, </em><em>default = None</em>) – If None, Linear Regression is used by default.</p></li>
<li><p><strong>categorical_features</strong> (<em>string</em><em>, </em><em>default = None</em>) – If the inferred data types are not correct, categorical_features can be used to
overwrite the inferred type. If when running setup the type of ‘column1’ is
inferred as numeric instead of categorical, then this parameter can be used
to overwrite the type by passing categorical_features = [‘column1’].</p></li>
<li><p><strong>categorical_imputation</strong> (<em>string</em><em>, </em><em>default = 'constant'</em>) – If missing values are found in categorical features, they will be imputed with
a constant ‘not_available’ value. The other available option is ‘mode’ which
imputes the missing value using most frequent value in the training dataset.</p></li>
<li><p><strong>ordinal_features</strong> (<em>dictionary</em><em>, </em><em>default = None</em>) – When the data contains ordinal features, they must be encoded differently using
the ordinal_features param. If the data has a categorical variable with values
of ‘low’, ‘medium’, ‘high’ and it is known that low &lt; medium &lt; high, then it can
be passed as ordinal_features = { ‘column_name’ : [‘low’, ‘medium’, ‘high’] }.
The list sequence must be in increasing order from lowest to highest.</p></li>
<li><p><strong>high_cardinality_features</strong> (<em>string</em><em>, </em><em>default = None</em>) – When the data containts features with high cardinality, they can be compressed
into fewer levels by passing them as a list of column names with high cardinality.
Features are compressed using method defined in high_cardinality_method param.</p></li>
<li><p><strong>high_cardinality_method</strong> (<em>string</em><em>, </em><em>default = 'frequency'</em>) – When method set to ‘frequency’ it will replace the original value of feature
with the frequency distribution and convert the feature into numeric. Other
available method is ‘clustering’ which performs the clustering on statistical
attribute of data and replaces the original value of feature with cluster label.
The number of clusters is determined using a combination of Calinski-Harabasz and
Silhouette criterion.</p></li>
<li><p><strong>numeric_features</strong> (<em>string</em><em>, </em><em>default = None</em>) – If the inferred data types are not correct, numeric_features can be used to
overwrite the inferred type. If when running setup the type of ‘column1’ is
inferred as a categorical instead of numeric, then this parameter can be used
to overwrite by passing numeric_features = [‘column1’].</p></li>
<li><p><strong>numeric_imputation</strong> (<em>string</em><em>, </em><em>default = 'mean'</em>) – If missing values are found in numeric features, they will be imputed with the
mean value of the feature. The other available option is ‘median’ which imputes
the value using the median value in the training dataset.</p></li>
<li><p><strong>date_features</strong> (<em>string</em><em>, </em><em>default = None</em>) – If the data has a DateTime column that is not automatically detected when running
setup, this parameter can be used by passing date_features = ‘date_column_name’.
It can work with multiple date columns. Date columns are not used in modeling.
Instead, feature extraction is performed and date columns are dropped from the
dataset. If the date column includes a time stamp, features related to time will
also be extracted.</p></li>
<li><p><strong>ignore_features</strong> (<em>string</em><em>, </em><em>default = None</em>) – If any feature should be ignored for modeling, it can be passed to the param
ignore_features. The ID and DateTime columns when inferred, are automatically
set to ignore for modeling.</p></li>
<li><p><strong>normalize</strong> (<em>bool</em><em>, </em><em>default = False</em>) – When set to True, the feature space is transformed using the normalized_method
param. Generally, linear algorithms perform better with normalized data however,
the results may vary and it is advised to run multiple experiments to evaluate
the benefit of normalization.</p></li>
<li><p><strong>normalize_method</strong> (<em>string</em><em>, </em><em>default = 'zscore'</em>) – <p>Defines the method to be used for normalization. By default, normalize method
is set to ‘zscore’. The standard zscore is calculated as z = (x - u) / s. The
other available options are:</p>
<dl class="simple">
<dt>’minmax’<span class="classifier">scales and translates each feature individually such that it is in</span></dt><dd><p>the range of 0 - 1.</p>
</dd>
<dt>’maxabs’<span class="classifier">scales and translates each feature individually such that the maximal</span></dt><dd><p>absolute value of each feature will be 1.0. It does not shift/center
the data, and thus does not destroy any sparsity.</p>
</dd>
<dt>’robust’<span class="classifier">scales and translates each feature according to the Interquartile range.</span></dt><dd><p>When the dataset contains outliers, robust scaler often gives better
results.</p>
</dd>
</dl>
</p></li>
<li><p><strong>transformation</strong> (<em>bool</em><em>, </em><em>default = False</em>) – When set to True, a power transformation is applied to make the data more normal /
Gaussian-like. This is useful for modeling issues related to heteroscedasticity or
other situations where normality is desired. The optimal parameter for stabilizing
variance and minimizing skewness is estimated through maximum likelihood.</p></li>
<li><p><strong>transformation_method</strong> (<em>string</em><em>, </em><em>default = 'yeo-johnson'</em>) – Defines the method for transformation. By default, the transformation method is set
to ‘yeo-johnson’. The other available option is ‘quantile’ transformation. Both
the transformation transforms the feature set to follow a Gaussian-like or normal
distribution. Note that the quantile transformer is non-linear and may distort linear
correlations between variables measured at the same scale.</p></li>
<li><p><strong>handle_unknown_categorical</strong> (<em>bool</em><em>, </em><em>default = True</em>) – When set to True, unknown categorical levels in new / unseen data are replaced by
the most or least frequent level as learned in the training data. The method is
defined under the unknown_categorical_method param.</p></li>
<li><p><strong>unknown_categorical_method</strong> (<em>string</em><em>, </em><em>default = 'least_frequent'</em>) – Method used to replace unknown categorical levels in unseen data. Method can be
set to ‘least_frequent’ or ‘most_frequent’.</p></li>
<li><p><strong>pca</strong> (<em>bool</em><em>, </em><em>default = False</em>) – When set to True, dimensionality reduction is applied to project the data into
a lower dimensional space using the method defined in pca_method param. In
supervised learning pca is generally performed when dealing with high feature
space and memory is a constraint. Note that not all datasets can be decomposed
efficiently using a linear PCA technique and that applying PCA may result in loss
of information. As such, it is advised to run multiple experiments with different
pca_methods to evaluate the impact.</p></li>
<li><p><strong>pca_method</strong> (<em>string</em><em>, </em><em>default = 'linear'</em>) – <p>The ‘linear’ method performs Linear dimensionality reduction using Singular Value
Decomposition. The other available options are:</p>
<p>kernel      : dimensionality reduction through the use of RVF kernel.</p>
<dl class="simple">
<dt>incremental<span class="classifier">replacement for ‘linear’ pca when the dataset to be decomposed is</span></dt><dd><p>too large to fit in memory</p>
</dd>
</dl>
</p></li>
<li><p><strong>pca_components</strong> (<em>int/float</em><em>, </em><em>default = 0.99</em>) – Number of components to keep. if pca_components is a float, it is treated as a
target percentage for information retention. When pca_components is an integer
it is treated as the number of features to be kept. pca_components must be strictly
less than the original number of features in the dataset.</p></li>
<li><p><strong>ignore_low_variance</strong> (<em>bool</em><em>, </em><em>default = False</em>) – When set to True, all categorical features with statistically insignificant variances
are removed from the dataset. The variance is calculated using the ratio of unique
values to the number of samples, and the ratio of the most common value to the
frequency of the second most common value.</p></li>
<li><p><strong>combine_rare_levels</strong> (<em>bool</em><em>, </em><em>default = False</em>) – When set to True, all levels in categorical features below the threshold defined
in rare_level_threshold param are combined together as a single level. There must be
atleast two levels under the threshold for this to take effect. rare_level_threshold
represents the percentile distribution of level frequency. Generally, this technique
is applied to limit a sparse matrix caused by high numbers of levels in categorical
features.</p></li>
<li><p><strong>rare_level_threshold</strong> (<em>float</em><em>, </em><em>default = 0.1</em>) – Percentile distribution below which rare categories are combined. Only comes into
effect when combine_rare_levels is set to True.</p></li>
<li><p><strong>bin_numeric_features</strong> (<em>list</em><em>, </em><em>default = None</em>) – When a list of numeric features is passed they are transformed into categorical
features using KMeans, where values in each bin have the same nearest center of a
1D k-means cluster. The number of clusters are determined based on the ‘sturges’
method. It is only optimal for gaussian data and underestimates the number of bins
for large non-gaussian datasets.</p></li>
<li><p><strong>remove_outliers</strong> (<em>bool</em><em>, </em><em>default = False</em>) – When set to True, outliers from the training data are removed using PCA linear
dimensionality reduction using the Singular Value Decomposition technique.</p></li>
<li><p><strong>outliers_threshold</strong> (<em>float</em><em>, </em><em>default = 0.05</em>) – The percentage / proportion of outliers in the dataset can be defined using
the outliers_threshold param. By default, 0.05 is used which means 0.025 of the
values on each side of the distribution’s tail are dropped from training data.</p></li>
<li><p><strong>remove_multicollinearity</strong> (<em>bool</em><em>, </em><em>default = False</em>) – When set to True, the variables with inter-correlations higher than the threshold
defined under the multicollinearity_threshold param are dropped. When two features
are highly correlated with each other, the feature that is less correlated with
the target variable is dropped.</p></li>
<li><p><strong>multicollinearity_threshold</strong> (<em>float</em><em>, </em><em>default = 0.9</em>) – Threshold used for dropping the correlated features. Only comes into effect when
remove_multicollinearity is set to True.</p></li>
<li><p><strong>remove_perfect_collinearity</strong> (<em>bool</em><em>, </em><em>default = False</em>) – When set to True, perfect collinearity (features with correlation = 1) is removed
from the dataset, When two features are 100% correlated, one of it is randomly
dropped from the dataset.</p></li>
<li><p><strong>create_clusters</strong> (<em>bool</em><em>, </em><em>default = False</em>) – When set to True, an additional feature is created where each instance is assigned
to a cluster. The number of clusters is determined using a combination of
Calinski-Harabasz and Silhouette criterion.</p></li>
<li><p><strong>cluster_iter</strong> (<em>int</em><em>, </em><em>default = 20</em>) – Number of iterations used to create a cluster. Each iteration represents cluster
size. Only comes into effect when create_clusters param is set to True.</p></li>
<li><p><strong>polynomial_features</strong> (<em>bool</em><em>, </em><em>default = False</em>) – When set to True, new features are created based on all polynomial combinations
that exist within the numeric features in a dataset to the degree defined in
polynomial_degree param.</p></li>
<li><p><strong>polynomial_degree</strong> (<em>int</em><em>, </em><em>default = 2</em>) – Degree of polynomial features. For example, if an input sample is two dimensional
and of the form [a, b], the polynomial features with degree = 2 are:
[1, a, b, a^2, ab, b^2].</p></li>
<li><p><strong>trigonometry_features</strong> (<em>bool</em><em>, </em><em>default = False</em>) – When set to True, new features are created based on all trigonometric combinations
that exist within the numeric features in a dataset to the degree defined in the
polynomial_degree param.</p></li>
<li><p><strong>polynomial_threshold</strong> (<em>float</em><em>, </em><em>default = 0.1</em>) – This is used to compress a sparse matrix of polynomial and trigonometric features.
Polynomial and trigonometric features whose feature importance based on the
combination of Random Forest, AdaBoost and Linear correlation falls within the
percentile of the defined threshold are kept in the dataset. Remaining features
are dropped before further processing.</p></li>
<li><p><strong>group_features</strong> (<em>list</em><em> or </em><em>list of list</em><em>, </em><em>default = None</em>) – When a dataset contains features that have related characteristics, the group_features
param can be used for statistical feature extraction. For example, if a dataset has
numeric features that are related with each other (i.e ‘Col1’, ‘Col2’, ‘Col3’), a list
containing the column names can be passed under group_features to extract statistical
information such as the mean, median, mode and standard deviation.</p></li>
<li><p><strong>group_names</strong> (<em>list</em><em>, </em><em>default = None</em>) – When group_features is passed, a name of the group can be passed into the group_names
param as a list containing strings. The length of a group_names list must equal to the
length  of group_features. When the length doesn’t match or the name is not passed, new
features are sequentially named such as group_1, group_2 etc.</p></li>
<li><p><strong>feature_selection</strong> (<em>bool</em><em>, </em><em>default = False</em>) – When set to True, a subset of features are selected using a combination of various
permutation importance techniques including Random Forest, Adaboost and Linear
correlation with target variable. The size of the subset is dependent on the
feature_selection_param. Generally, this is used to constrain the feature space
in order to improve efficiency in modeling. When polynomial_features and
feature_interaction  are used, it is highly recommended to define the
feature_selection_threshold param with a lower value.</p></li>
<li><p><strong>feature_selection_threshold</strong> (<em>float</em><em>, </em><em>default = 0.8</em>) – Threshold used for feature selection (including newly created polynomial features).
A higher value will result in a higher feature space. It is recommended to do multiple
trials with different values of feature_selection_threshold specially in cases where
polynomial_features and feature_interaction are used. Setting a very low value may be
efficient but could result in under-fitting.</p></li>
<li><p><strong>feature_interaction</strong> (<em>bool</em><em>, </em><em>default = False</em>) – When set to True, it will create new features by interacting (a * b) for all numeric
variables in the dataset including polynomial and trigonometric features (if created).
This feature is not scalable and may not work as expected on datasets with large
feature space.</p></li>
<li><p><strong>feature_ratio</strong> (<em>bool</em><em>, </em><em>default = False</em>) – When set to True, it will create new features by calculating the ratios (a / b) of all
numeric variables in the dataset. This feature is not scalable and may not work as
expected on datasets with large feature space.</p></li>
<li><p><strong>interaction_threshold</strong> (<em>bool</em><em>, </em><em>default = 0.01</em>) – Similar to polynomial_threshold, It is used to compress a sparse matrix of newly
created features through interaction. Features whose importance based on the
combination  of  Random Forest, AdaBoost and Linear correlation falls within the
percentile of the  defined threshold are kept in the dataset. Remaining features
are dropped before further processing.</p></li>
<li><p><strong>transform_target</strong> (<em>bool</em><em>, </em><em>default = False</em>) – When set to True, target variable is transformed using the method defined in
transform_target_method param. Target transformation is applied separately from
feature transformations.</p></li>
<li><p><strong>transform_target_method</strong> (<em>string</em><em>, </em><em>default = 'box-cox'</em>) – ‘Box-cox’ and ‘yeo-johnson’ methods are supported. Box-Cox requires input data to
be strictly positive, while Yeo-Johnson supports both positive or negative data.
When transform_target_method is ‘box-cox’ and target variable contains negative
values, method is internally forced to ‘yeo-johnson’ to avoid exceptions.</p></li>
<li><p><strong>data_split_shuffle</strong> (<em>bool</em><em>, </em><em>default = True</em>) – If set to False, prevents shuffling of rows when splitting data.</p></li>
<li><p><strong>folds_shuffle</strong> (<em>bool</em><em>, </em><em>default = True</em>) – If set to False, prevents shuffling of rows when using cross validation.</p></li>
<li><p><strong>n_jobs</strong> (<em>int</em><em>, </em><em>default = -1</em>) – The number of jobs to run in parallel (for functions that supports parallel
processing) -1 means using all processors. To run all functions on single processor
set n_jobs to None.</p></li>
<li><p><strong>html</strong> (<em>bool</em><em>, </em><em>default = True</em>) – If set to False, prevents runtime display of monitor. This must be set to False
when using environment that doesnt support HTML.</p></li>
<li><p><strong>session_id</strong> (<em>int</em><em>, </em><em>default = None</em>) – If None, a random seed is generated and returned in the Information grid. The
unique number is then distributed as a seed in all functions used during the
experiment. This can be used for later reproducibility of the entire experiment.</p></li>
<li><p><strong>log_experiment</strong> (<em>bool</em><em>, </em><em>default = False</em>) – When set to True, all metrics and parameters are logged on MLFlow server.</p></li>
<li><p><strong>experiment_name</strong> (<em>str</em><em>, </em><em>default = None</em>) – Name of experiment for logging. When set to None, ‘reg’ is by default used as
alias for the experiment name.</p></li>
<li><p><strong>log_plots</strong> (<em>bool</em><em>, </em><em>default = False</em>) – When set to True, specific plots are logged in MLflow as a png file. By default,
it is set to False.</p></li>
<li><p><strong>log_profile</strong> (<em>bool</em><em>, </em><em>default = False</em>) – When set to True, data profile is also logged on MLflow as a html file. By default,
it is set to False.</p></li>
<li><p><strong>log_data</strong> (<em>bool</em><em>, </em><em>default = False</em>) – When set to True, train and test dataset are logged as csv.</p></li>
<li><p><strong>silent</strong> (<em>bool</em><em>, </em><em>default = False</em>) – When set to True, confirmation of data types is not required. All preprocessing will
be performed assuming automatically inferred data types. Not recommended for direct use
except for established pipelines.</p></li>
<li><p><strong>verbose</strong> (<em>Boolean</em><em>, </em><em>default = True</em>) – Information grid is not printed when verbose is set to False.</p></li>
<li><p><strong>profile</strong> (<em>bool</em><em>, </em><em>default = False</em>) – If set to true, a data profile for Exploratory Data Analysis will be displayed
in an interactive HTML report.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><em>info_grid</em> – Information grid is printed.</p></li>
<li><p><em>environment</em> – This function returns various outputs that are stored in variable
as tuple. They are used by other functions in pycaret.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pycaret.regression.stack_models">
<code class="sig-prename descclassname">pycaret.regression.</code><code class="sig-name descname">stack_models</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">estimator_list</span></em>, <em class="sig-param"><span class="n">meta_model</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">fold</span><span class="o">=</span><span class="default_value">10</span></em>, <em class="sig-param"><span class="n">round</span><span class="o">=</span><span class="default_value">4</span></em>, <em class="sig-param"><span class="n">restack</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">choose_better</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">optimize</span><span class="o">=</span><span class="default_value">'R2'</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.regression.stack_models" title="Permalink to this definition">¶</a></dt>
<dd><p>This function trains a meta model and scores it using Kfold Cross Validation.
The predictions from the base level models as passed in the estimator_list param
are used as input features for the meta model. The restacking parameter controls
the ability to expose raw features to the meta model when set to True
(default = False).</p>
<p>The output prints a score grid that shows MAE, MSE, RMSE, R2, RMSLE and MAPE by
fold (default = 10 Folds).</p>
<p>This function returns a trained model object.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pycaret.datasets</span> <span class="kn">import</span> <span class="n">get_data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">boston</span> <span class="o">=</span> <span class="n">get_data</span><span class="p">(</span><span class="s1">&#39;boston&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">experiment_name</span> <span class="o">=</span> <span class="n">setup</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">boston</span><span class="p">,</span>  <span class="n">target</span> <span class="o">=</span> <span class="s1">&#39;medv&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dt</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">(</span><span class="s1">&#39;dt&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rf</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">(</span><span class="s1">&#39;rf&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ada</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">(</span><span class="s1">&#39;ada&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ridge</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">(</span><span class="s1">&#39;ridge&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">knn</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">(</span><span class="s1">&#39;knn&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span> <span class="n">stacked_models</span> <span class="o">=</span> <span class="n">stack_models</span><span class="p">(</span><span class="n">estimator_list</span><span class="o">=</span><span class="p">[</span><span class="n">dt</span><span class="p">,</span><span class="n">rf</span><span class="p">,</span><span class="n">ada</span><span class="p">,</span><span class="n">ridge</span><span class="p">,</span><span class="n">knn</span><span class="p">])</span>
</pre></div>
</div>
<p>This will create a meta model that will use the predictions of all the
models provided in estimator_list param. By default, the meta model is
Linear Regression but can be changed with meta_model param.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>estimator_list</strong> (<em>list of object</em>) – </p></li>
<li><p><strong>meta_model</strong> (<em>object</em><em>, </em><em>default = None</em>) – If set to None, Linear Regression is used as a meta model.</p></li>
<li><p><strong>fold</strong> (<em>integer</em><em>, </em><em>default = 10</em>) – Number of folds to be used in Kfold CV. Must be at least 2.</p></li>
<li><p><strong>round</strong> (<em>integer</em><em>, </em><em>default = 4</em>) – Number of decimal places the metrics in the score grid will be rounded to.</p></li>
<li><p><strong>restack</strong> (<em>Boolean</em><em>, </em><em>default = True</em>) – When restack is set to True, raw data will be exposed to meta model when
making predictions, otherwise when False, only the predicted label is passed
to meta model when making final predictions.</p></li>
<li><p><strong>choose_better</strong> (<em>Boolean</em><em>, </em><em>default = False</em>) – When set to True, base estimator is returned when the metric doesn’t
improve by ensemble_model. This gurantees the returned object would perform
atleast equivalent to base estimator created using create_model or model
returned by compare_models.</p></li>
<li><p><strong>optimize</strong> (<em>string</em><em>, </em><em>default = 'R2'</em>) – Only used when choose_better is set to True. optimize parameter is used
to compare emsembled model with base estimator. Values accepted in
optimize parameter are ‘MAE’, ‘MSE’, ‘RMSE’, ‘R2’, ‘RMSLE’, ‘MAPE’.</p></li>
<li><p><strong>verbose</strong> (<em>Boolean</em><em>, </em><em>default = True</em>) – Score grid is not printed when verbose is set to False.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><em>score_grid</em> – A table containing the scores of the model across the kfolds.
Scoring metrics used are MAE, MSE, RMSE, R2, RMSLE and MAPE.
Mean and standard deviation of the scores across the folds are
also returned.</p></li>
<li><p><em>model</em> – Trained model object.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pycaret.regression.tune_model">
<code class="sig-prename descclassname">pycaret.regression.</code><code class="sig-name descname">tune_model</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">estimator</span></em>, <em class="sig-param"><span class="n">fold</span><span class="o">=</span><span class="default_value">10</span></em>, <em class="sig-param"><span class="n">round</span><span class="o">=</span><span class="default_value">4</span></em>, <em class="sig-param"><span class="n">n_iter</span><span class="o">=</span><span class="default_value">10</span></em>, <em class="sig-param"><span class="n">custom_grid</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">optimize</span><span class="o">=</span><span class="default_value">'R2'</span></em>, <em class="sig-param"><span class="n">choose_better</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.regression.tune_model" title="Permalink to this definition">¶</a></dt>
<dd><p>This function tunes the hyperparameters of a model and scores it using Kfold
Cross Validation. The output prints the score grid that shows MAE, MSE, RMSE,
R2, RMSLE and MAPE by fold (by default = 10 Folds).</p>
<p>This function returns a trained model object.</p>
<p>tune_model() only accepts a string parameter for estimator.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pycaret.datasets</span> <span class="kn">import</span> <span class="n">get_data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">boston</span> <span class="o">=</span> <span class="n">get_data</span><span class="p">(</span><span class="s1">&#39;boston&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">experiment_name</span> <span class="o">=</span> <span class="n">setup</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">boston</span><span class="p">,</span>  <span class="n">target</span> <span class="o">=</span> <span class="s1">&#39;medv&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">xgboost</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">(</span><span class="s1">&#39;xgboost&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tuned_xgboost</span> <span class="o">=</span> <span class="n">tune_model</span><span class="p">(</span><span class="n">xgboost</span><span class="p">)</span>
</pre></div>
</div>
<p>This will tune the hyperparameters of Extreme Gradient Boosting Regressor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>estimator</strong> (<em>object</em><em>, </em><em>default = None</em>) – </p></li>
<li><p><strong>fold</strong> (<em>integer</em><em>, </em><em>default = 10</em>) – Number of folds to be used in Kfold CV. Must be at least 2.</p></li>
<li><p><strong>round</strong> (<em>integer</em><em>, </em><em>default = 4</em>) – Number of decimal places the metrics in the score grid will be rounded to.</p></li>
<li><p><strong>n_iter</strong> (<em>integer</em><em>, </em><em>default = 10</em>) – Number of iterations within the Random Grid Search. For every iteration,
the model randomly selects one value from the pre-defined grid of hyperparameters.</p></li>
<li><p><strong>custom_grid</strong> (<em>dictionary</em><em>, </em><em>default = None</em>) – To use custom hyperparameters for tuning pass a dictionary with parameter name
and values to be iterated. When set to None it uses pre-defined tuning grid.</p></li>
<li><p><strong>optimize</strong> (<em>string</em><em>, </em><em>default = 'R2'</em>) – Measure used to select the best model through hyperparameter tuning.
The default scoring measure is ‘R2’. Other measures include ‘MAE’, ‘MSE’, ‘RMSE’,
‘RMSLE’, ‘MAPE’. When using ‘RMSE’ or ‘RMSLE’ the base scorer is ‘MSE’ and when using
‘MAPE’ the base scorer is ‘MAE’.</p></li>
<li><p><strong>choose_better</strong> (<em>Boolean</em><em>, </em><em>default = False</em>) – When set to set to True, base estimator is returned when the metric doesn’t improve
by tune_model. This gurantees the returned object would perform atleast equivalent
to base estimator created using create_model or model returned by compare_models.</p></li>
<li><p><strong>verbose</strong> (<em>Boolean</em><em>, </em><em>default = True</em>) – Score grid is not printed when verbose is set to False.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><em>score_grid</em> – A table containing the scores of the model across the kfolds.
Scoring metrics used are MAE, MSE, RMSE, R2, RMSLE and MAPE.
Mean and standard deviation of the scores across the folds are
also returned.</p></li>
<li><p><em>model</em> – trained model object</p></li>
</ul>
</p>
</dd>
</dl>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<ul class="simple">
<li><p>estimator parameter takes an abbreviated string. Passing a trained model object
returns an error. The tune_model() function internally calls create_model()
before tuning the hyperparameters.</p></li>
</ul>
</div>
</dd></dl>

</div>
<div class="section" id="module-pycaret.classification">
<span id="classification"></span><h1>Classification<a class="headerlink" href="#module-pycaret.classification" title="Permalink to this headline">¶</a></h1>
<dl class="py function">
<dt id="pycaret.classification.automl">
<code class="sig-prename descclassname">pycaret.classification.</code><code class="sig-name descname">automl</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">optimize</span><span class="o">=</span><span class="default_value">'Accuracy'</span></em>, <em class="sig-param"><span class="n">use_holdout</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.classification.automl" title="Permalink to this definition">¶</a></dt>
<dd><p>This function returns the best model out of all models created in
current active environment based on metric defined in optimize parameter.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>optimize</strong> (<em>string</em><em>, </em><em>default = 'Accuracy'</em>) – Other values you can pass in optimize param are ‘AUC’, ‘Recall’, ‘Precision’,
‘F1’, ‘Kappa’, and ‘MCC’.</p></li>
<li><p><strong>use_holdout</strong> (<em>bool</em><em>, </em><em>default = False</em>) – When set to True, metrics are evaluated on holdout set instead of CV.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pycaret.classification.blend_models">
<code class="sig-prename descclassname">pycaret.classification.</code><code class="sig-name descname">blend_models</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">estimator_list</span><span class="o">=</span><span class="default_value">'All'</span></em>, <em class="sig-param"><span class="n">fold</span><span class="o">=</span><span class="default_value">10</span></em>, <em class="sig-param"><span class="n">round</span><span class="o">=</span><span class="default_value">4</span></em>, <em class="sig-param"><span class="n">choose_better</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">optimize</span><span class="o">=</span><span class="default_value">'Accuracy'</span></em>, <em class="sig-param"><span class="n">method</span><span class="o">=</span><span class="default_value">'hard'</span></em>, <em class="sig-param"><span class="n">turbo</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.classification.blend_models" title="Permalink to this definition">¶</a></dt>
<dd><p>This function creates a Soft Voting / Majority Rule classifier for all the
estimators in the model library (excluding the few when turbo is True) or
for specific trained estimators passed as a list in estimator_list param.
It scores it using Stratified Cross Validation. The output prints a score
grid that shows Accuracy,  AUC, Recall, Precision, F1, Kappa and MCC by
fold (default CV = 10 Folds).</p>
<p>This function returns a trained model object.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pycaret.datasets</span> <span class="kn">import</span> <span class="n">get_data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">juice</span> <span class="o">=</span> <span class="n">get_data</span><span class="p">(</span><span class="s1">&#39;juice&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">experiment_name</span> <span class="o">=</span> <span class="n">setup</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">juice</span><span class="p">,</span>  <span class="n">target</span> <span class="o">=</span> <span class="s1">&#39;Purchase&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">blend_all</span> <span class="o">=</span> <span class="n">blend_models</span><span class="p">()</span>
</pre></div>
</div>
<p>This will create a VotingClassifier for all models in the model library
except for ‘rbfsvm’, ‘gpc’ and ‘mlp’.</p>
<p>For specific models, you can use:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">lr</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">(</span><span class="s1">&#39;lr&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rf</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">(</span><span class="s1">&#39;rf&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">knn</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">(</span><span class="s1">&#39;knn&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">blend_three</span> <span class="o">=</span> <span class="n">blend_models</span><span class="p">(</span><span class="n">estimator_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">lr</span><span class="p">,</span><span class="n">rf</span><span class="p">,</span><span class="n">knn</span><span class="p">])</span>
</pre></div>
</div>
<p>This will create a VotingClassifier of lr, rf and knn.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>estimator_list</strong> (<em>string</em><em> (</em><em>'All'</em><em>) or </em><em>list of object</em><em>, </em><em>default = 'All'</em>) – </p></li>
<li><p><strong>fold</strong> (<em>integer</em><em>, </em><em>default = 10</em>) – Number of folds to be used in Kfold CV. Must be at least 2.</p></li>
<li><p><strong>round</strong> (<em>integer</em><em>, </em><em>default = 4</em>) – Number of decimal places the metrics in the score grid will be rounded to.</p></li>
<li><p><strong>choose_better</strong> (<em>Boolean</em><em>, </em><em>default = False</em>) – When set to set to True, base estimator is returned when the metric doesn’t
improve by ensemble_model. This gurantees the returned object would perform
atleast equivalent to base estimator created using create_model or model
returned by compare_models.</p></li>
<li><p><strong>optimize</strong> (<em>string</em><em>, </em><em>default = 'Accuracy'</em>) – Only used when choose_better is set to True. optimize parameter is used
to compare emsembled model with base estimator. Values accepted in
optimize parameter are ‘Accuracy’, ‘AUC’, ‘Recall’, ‘Precision’, ‘F1’,
‘Kappa’, ‘MCC’.</p></li>
<li><p><strong>method</strong> (<em>string</em><em>, </em><em>default = 'hard'</em>) – ‘hard’ uses predicted class labels for majority rule voting.’soft’, predicts
the class label based on the argmax of the sums of the predicted probabilities,
which is recommended for an ensemble of well-calibrated classifiers.</p></li>
<li><p><strong>turbo</strong> (<em>Boolean</em><em>, </em><em>default = True</em>) – When turbo is set to True, it blacklists estimator that uses Radial Kernel.</p></li>
<li><p><strong>verbose</strong> (<em>Boolean</em><em>, </em><em>default = True</em>) – Score grid is not printed when verbose is set to False.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><em>score_grid</em> – A table containing the scores of the model across the kfolds.
Scoring metrics used are Accuracy, AUC, Recall, Precision, F1,
Kappa and MCC. Mean and standard deviation of the scores across
the folds are also returned.</p></li>
<li><p><em>model</em> – Trained Voting Classifier model object.</p></li>
</ul>
</p>
</dd>
</dl>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<ul class="simple">
<li><p>When passing estimator_list with method set to ‘soft’. All the models in the
estimator_list must support predict_proba function. ‘svm’ and ‘ridge’ doesnt
support the predict_proba and hence an exception will be raised.</p></li>
<li><p>When estimator_list is set to ‘All’ and method is forced to ‘soft’, estimators
that doesnt support the predict_proba function will be dropped from the estimator
list.</p></li>
<li><p>CatBoost Classifier not supported in blend_models().</p></li>
<li><p>If target variable is multiclass (more than 2 classes), AUC will be returned as
zero (0.0).</p></li>
</ul>
</div>
</dd></dl>

<dl class="py function">
<dt id="pycaret.classification.calibrate_model">
<code class="sig-prename descclassname">pycaret.classification.</code><code class="sig-name descname">calibrate_model</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">estimator</span></em>, <em class="sig-param"><span class="n">method</span><span class="o">=</span><span class="default_value">'sigmoid'</span></em>, <em class="sig-param"><span class="n">fold</span><span class="o">=</span><span class="default_value">10</span></em>, <em class="sig-param"><span class="n">round</span><span class="o">=</span><span class="default_value">4</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.classification.calibrate_model" title="Permalink to this definition">¶</a></dt>
<dd><p>This function takes the input of trained estimator and performs probability
calibration with sigmoid or isotonic regression. The output prints a score
grid that shows Accuracy, AUC, Recall, Precision, F1, Kappa and MCC by fold
(default = 10 Fold). The ouput of the original estimator and the calibrated
estimator (created using this function) might not differ much. In order
to see the calibration differences, use ‘calibration’ plot in plot_model to
see the difference before and after.</p>
<p>This function returns a trained model object.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pycaret.datasets</span> <span class="kn">import</span> <span class="n">get_data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">juice</span> <span class="o">=</span> <span class="n">get_data</span><span class="p">(</span><span class="s1">&#39;juice&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">experiment_name</span> <span class="o">=</span> <span class="n">setup</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">juice</span><span class="p">,</span>  <span class="n">target</span> <span class="o">=</span> <span class="s1">&#39;Purchase&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dt_boosted</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">(</span><span class="s1">&#39;dt&#39;</span><span class="p">,</span> <span class="n">ensemble</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">method</span> <span class="o">=</span> <span class="s1">&#39;Boosting&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">calibrated_dt</span> <span class="o">=</span> <span class="n">calibrate_model</span><span class="p">(</span><span class="n">dt_boosted</span><span class="p">)</span>
</pre></div>
</div>
<p>This will return Calibrated Boosted Decision Tree Model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>estimator</strong> (<em>object</em>) – </p></li>
<li><p><strong>method</strong> (<em>string</em><em>, </em><em>default = 'sigmoid'</em>) – The method to use for calibration. Can be ‘sigmoid’ which corresponds to Platt’s
method or ‘isotonic’ which is a non-parametric approach. It is not advised to use
isotonic calibration with too few calibration samples</p></li>
<li><p><strong>fold</strong> (<em>integer</em><em>, </em><em>default = 10</em>) – Number of folds to be used in Kfold CV. Must be at least 2.</p></li>
<li><p><strong>round</strong> (<em>integer</em><em>, </em><em>default = 4</em>) – Number of decimal places the metrics in the score grid will be rounded to.</p></li>
<li><p><strong>verbose</strong> (<em>Boolean</em><em>, </em><em>default = True</em>) – Score grid is not printed when verbose is set to False.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><em>score_grid</em> – A table containing the scores of the model across the kfolds.
Scoring metrics used are Accuracy, AUC, Recall, Precision, F1,
Kappa and MCC. Mean and standard deviation of the scores across
the folds are also returned.</p></li>
<li><p><em>model</em> – trained and calibrated model object.</p></li>
</ul>
</p>
</dd>
</dl>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<ul class="simple">
<li><p>Avoid isotonic calibration with too few calibration samples (&lt;1000) since it
tends to overfit.</p></li>
<li><p>calibration plot not available for multiclass problems.</p></li>
</ul>
</div>
</dd></dl>

<dl class="py function">
<dt id="pycaret.classification.compare_models">
<code class="sig-prename descclassname">pycaret.classification.</code><code class="sig-name descname">compare_models</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">blacklist</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">whitelist</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">fold</span><span class="o">=</span><span class="default_value">10</span></em>, <em class="sig-param"><span class="n">round</span><span class="o">=</span><span class="default_value">4</span></em>, <em class="sig-param"><span class="n">sort</span><span class="o">=</span><span class="default_value">'Accuracy'</span></em>, <em class="sig-param"><span class="n">n_select</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">turbo</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.classification.compare_models" title="Permalink to this definition">¶</a></dt>
<dd><p>This function train all the models available in the model library and scores them
using Stratified Cross Validation. The output prints a score grid with Accuracy,
AUC, Recall, Precision, F1, Kappa and MCC (averaged accross folds), determined by
fold parameter.</p>
<p>This function returns the best model based on metric defined in sort parameter.</p>
<p>To select top N models, use n_select parameter that is set to 1 by default.
Where n_select parameter &gt; 1, it will return a list of trained model objects.</p>
<p>When turbo is set to True (‘rbfsvm’, ‘gpc’ and ‘mlp’) are excluded due to longer
training time. By default turbo param is set to True.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pycaret.datasets</span> <span class="kn">import</span> <span class="n">get_data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">juice</span> <span class="o">=</span> <span class="n">get_data</span><span class="p">(</span><span class="s1">&#39;juice&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">experiment_name</span> <span class="o">=</span> <span class="n">setup</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">juice</span><span class="p">,</span>  <span class="n">target</span> <span class="o">=</span> <span class="s1">&#39;Purchase&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">best_model</span> <span class="o">=</span> <span class="n">compare_models</span><span class="p">()</span>
</pre></div>
</div>
<p>This will return the averaged score grid of all the models except ‘rbfsvm’, ‘gpc’
and ‘mlp’. When turbo param is set to False, all models including ‘rbfsvm’, ‘gpc’
and ‘mlp’ are used but this may result in longer training time.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">best_model</span> <span class="o">=</span> <span class="n">compare_models</span><span class="p">(</span> <span class="n">blacklist</span> <span class="o">=</span> <span class="p">[</span> <span class="s1">&#39;knn&#39;</span><span class="p">,</span> <span class="s1">&#39;gbc&#39;</span> <span class="p">]</span> <span class="p">,</span> <span class="n">turbo</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
<p>This will return a comparison of all models except K Nearest Neighbour and
Gradient Boosting Classifier.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">best_model</span> <span class="o">=</span> <span class="n">compare_models</span><span class="p">(</span> <span class="n">blacklist</span> <span class="o">=</span> <span class="p">[</span> <span class="s1">&#39;knn&#39;</span><span class="p">,</span> <span class="s1">&#39;gbc&#39;</span> <span class="p">]</span> <span class="p">,</span> <span class="n">turbo</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<p>This will return comparison of all models except K Nearest Neighbour,
Gradient Boosting Classifier, SVM (RBF), Gaussian Process Classifier and
Multi Level Perceptron.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>blacklist</strong> (<em>list of strings</em><em>, </em><em>default = None</em>) – In order to omit certain models from the comparison model ID’s can be passed as
a list of strings in blacklist param.</p></li>
<li><p><strong>whitelist</strong> (<em>list of strings</em><em>, </em><em>default = None</em>) – In order to run only certain models for the comparison, the model ID’s can be
passed as a list of strings in whitelist param.</p></li>
<li><p><strong>fold</strong> (<em>integer</em><em>, </em><em>default = 10</em>) – Number of folds to be used in Kfold CV. Must be at least 2.</p></li>
<li><p><strong>round</strong> (<em>integer</em><em>, </em><em>default = 4</em>) – Number of decimal places the metrics in the score grid will be rounded to.</p></li>
<li><p><strong>sort</strong> (<em>string</em><em>, </em><em>default = 'Accuracy'</em>) – The scoring measure specified is used for sorting the average score grid
Other options are ‘AUC’, ‘Recall’, ‘Precision’, ‘F1’, ‘Kappa’ and ‘MCC’.</p></li>
<li><p><strong>n_select</strong> (<em>int</em><em>, </em><em>default = 1</em>) – Number of top_n models to return. use negative argument for bottom selection.
for example, n_select = -3 means bottom 3 models.</p></li>
<li><p><strong>turbo</strong> (<em>Boolean</em><em>, </em><em>default = True</em>) – When turbo is set to True, it blacklists estimators that have longer
training time.</p></li>
<li><p><strong>verbose</strong> (<em>Boolean</em><em>, </em><em>default = True</em>) – Score grid is not printed when verbose is set to False.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A table containing the scores of the model across the kfolds.
Scoring metrics used are Accuracy, AUC, Recall, Precision, F1,
Kappa and MCC. Mean and standard deviation of the scores across
the folds are also returned.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>score_grid</p>
</dd>
</dl>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<ul class="simple">
<li><p>compare_models() though attractive, might be time consuming with large
datasets. By default turbo is set to True, which blacklists models that
have longer training times. Changing turbo parameter to False may result
in very high training times with datasets where number of samples exceed
10,000.</p></li>
<li><p>If target variable is multiclass (more than 2 classes), AUC will be
returned as zero (0.0)</p></li>
</ul>
</div>
</dd></dl>

<dl class="py function">
<dt id="pycaret.classification.create_model">
<code class="sig-prename descclassname">pycaret.classification.</code><code class="sig-name descname">create_model</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">estimator</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">ensemble</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">method</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">fold</span><span class="o">=</span><span class="default_value">10</span></em>, <em class="sig-param"><span class="n">round</span><span class="o">=</span><span class="default_value">4</span></em>, <em class="sig-param"><span class="n">cross_validation</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">system</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.classification.create_model" title="Permalink to this definition">¶</a></dt>
<dd><p>This function creates a model and scores it using Stratified Cross Validation.
The output prints a score grid that shows Accuracy, AUC, Recall, Precision,
F1, Kappa and MCC by fold (default = 10 Fold).</p>
<p>This function returns a trained model object.</p>
<p>setup() function must be called before using create_model()</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pycaret.datasets</span> <span class="kn">import</span> <span class="n">get_data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">juice</span> <span class="o">=</span> <span class="n">get_data</span><span class="p">(</span><span class="s1">&#39;juice&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">experiment_name</span> <span class="o">=</span> <span class="n">setup</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">juice</span><span class="p">,</span>  <span class="n">target</span> <span class="o">=</span> <span class="s1">&#39;Purchase&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lr</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">(</span><span class="s1">&#39;lr&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>This will create a trained Logistic Regression model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>estimator</strong> (<em>string / object</em><em>, </em><em>default = None</em>) – <p>Enter ID of the estimators available in model library or pass an untrained model
object consistent with fit / predict API to train and evaluate model. All estimators
support binary or multiclass problem. List of estimators in model library:</p>
<p>ID          Name
——–    ———-
‘lr’        Logistic Regression
‘knn’       K Nearest Neighbour
‘nb’        Naive Bayes
‘dt’        Decision Tree Classifier
‘svm’       SVM - Linear Kernel
‘rbfsvm’    SVM - Radial Kernel
‘gpc’       Gaussian Process Classifier
‘mlp’       Multi Level Perceptron
‘ridge’     Ridge Classifier
‘rf’        Random Forest Classifier
‘qda’       Quadratic Discriminant Analysis
‘ada’       Ada Boost Classifier
‘gbc’       Gradient Boosting Classifier
‘lda’       Linear Discriminant Analysis
‘et’        Extra Trees Classifier
‘xgboost’   Extreme Gradient Boosting
‘lightgbm’  Light Gradient Boosting
‘catboost’  CatBoost Classifier</p>
</p></li>
<li><p><strong>ensemble</strong> (<em>Boolean</em><em>, </em><em>default = False</em>) – True would result in an ensemble of estimator using the method parameter defined.</p></li>
<li><p><strong>method</strong> (<em>String</em><em>, </em><em>'Bagging'</em><em> or </em><em>'Boosting'</em><em>, </em><em>default = None.</em>) – method must be defined when ensemble is set to True. Default method is set to None.</p></li>
<li><p><strong>fold</strong> (<em>integer</em><em>, </em><em>default = 10</em>) – Number of folds to be used in Kfold CV. Must be at least 2.</p></li>
<li><p><strong>round</strong> (<em>integer</em><em>, </em><em>default = 4</em>) – Number of decimal places the metrics in the score grid will be rounded to.</p></li>
<li><p><strong>cross_validation</strong> (<em>bool</em><em>, </em><em>default = True</em>) – When cross_validation set to False fold parameter is ignored and model is trained
on entire training dataset. No metric evaluation is returned.</p></li>
<li><p><strong>verbose</strong> (<em>Boolean</em><em>, </em><em>default = True</em>) – Score grid is not printed when verbose is set to False.</p></li>
<li><p><strong>system</strong> (<em>Boolean</em><em>, </em><em>default = True</em>) – Must remain True all times. Only to be changed by internal functions.</p></li>
<li><p><strong>**kwargs</strong> – </p></li>
<li><p><strong>keyword arguments to pass to the estimator.</strong> (<em>Additional</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><em>score_grid</em> – A table containing the scores of the model across the kfolds.
Scoring metrics used are Accuracy, AUC, Recall, Precision, F1,
Kappa and MCC. Mean and standard deviation of the scores across
the folds are highlighted in yellow.</p></li>
<li><p><em>model</em> – trained model object</p></li>
</ul>
</p>
</dd>
</dl>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<ul class="simple">
<li><p>‘svm’ and ‘ridge’ doesn’t support predict_proba method. As such, AUC will be
returned as zero (0.0)</p></li>
<li><p>If target variable is multiclass (more than 2 classes), AUC will be returned
as zero (0.0)</p></li>
<li><p>‘rbfsvm’ and ‘gpc’ uses non-linear kernel and hence the fit time complexity is
more than quadratic. These estimators are hard to scale on datasets with more
than 10,000 samples.</p></li>
</ul>
</div>
</dd></dl>

<dl class="py function">
<dt id="pycaret.classification.deploy_model">
<code class="sig-prename descclassname">pycaret.classification.</code><code class="sig-name descname">deploy_model</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">model</span></em>, <em class="sig-param"><span class="n">model_name</span></em>, <em class="sig-param"><span class="n">authentication</span></em>, <em class="sig-param"><span class="n">platform</span><span class="o">=</span><span class="default_value">'aws'</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.classification.deploy_model" title="Permalink to this definition">¶</a></dt>
<dd><p>(In Preview)</p>
<p>This function deploys the transformation pipeline and trained model object for
production use. The platform of deployment can be defined under the platform
param along with the applicable authentication tokens which are passed as a
dictionary to the authentication param.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pycaret.datasets</span> <span class="kn">import</span> <span class="n">get_data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">juice</span> <span class="o">=</span> <span class="n">get_data</span><span class="p">(</span><span class="s1">&#39;juice&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">experiment_name</span> <span class="o">=</span> <span class="n">setup</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">juice</span><span class="p">,</span>  <span class="n">target</span> <span class="o">=</span> <span class="s1">&#39;Purchase&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lr</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">(</span><span class="s1">&#39;lr&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">deploy_model</span><span class="p">(</span><span class="n">model</span> <span class="o">=</span> <span class="n">lr</span><span class="p">,</span> <span class="n">model_name</span> <span class="o">=</span> <span class="s1">&#39;deploy_lr&#39;</span><span class="p">,</span> <span class="n">platform</span> <span class="o">=</span> <span class="s1">&#39;aws&#39;</span><span class="p">,</span> <span class="n">authentication</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;bucket&#39;</span> <span class="p">:</span> <span class="s1">&#39;pycaret-test&#39;</span><span class="p">})</span>
</pre></div>
</div>
<p>This will deploy the model on an AWS S3 account under bucket ‘pycaret-test’</p>
<p class="rubric">Notes</p>
<p>For AWS users:
Before deploying a model to an AWS S3 (‘aws’), environment variables must be
configured using the command line interface. To configure AWS env. variables,
type aws configure in your python command line. The following information is
required which can be generated using the Identity and Access Management (IAM)
portal of your amazon console account:</p>
<ul class="simple">
<li><p>AWS Access Key ID</p></li>
<li><p>AWS Secret Key Access</p></li>
<li><p>Default Region Name (can be seen under Global settings on your AWS console)</p></li>
<li><p>Default output format (must be left blank)</p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>object</em>) – A trained model object should be passed as an estimator.</p></li>
<li><p><strong>model_name</strong> (<em>string</em>) – Name of model to be passed as a string.</p></li>
<li><p><strong>authentication</strong> (<em>dict</em>) – <p>Dictionary of applicable authentication tokens.</p>
<p>When platform = ‘aws’:
{‘bucket’ : ‘Name of Bucket on S3’}</p>
</p></li>
<li><p><strong>platform</strong> (<em>string</em><em>, </em><em>default = 'aws'</em>) – Name of platform for deployment. Current available options are: ‘aws’.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Success_Message</p>
</dd>
</dl>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<ul class="simple">
<li><p>This function uses file storage services to deploy the model on cloud platform.
As such, this is efficient for batch-use. Where the production objective is to
obtain prediction at an instance level, this may not be the efficient choice as
it transmits the binary pickle file between your local python environment and
the platform.</p></li>
</ul>
</div>
</dd></dl>

<dl class="py function">
<dt id="pycaret.classification.ensemble_model">
<code class="sig-prename descclassname">pycaret.classification.</code><code class="sig-name descname">ensemble_model</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">estimator</span></em>, <em class="sig-param"><span class="n">method</span><span class="o">=</span><span class="default_value">'Bagging'</span></em>, <em class="sig-param"><span class="n">fold</span><span class="o">=</span><span class="default_value">10</span></em>, <em class="sig-param"><span class="n">n_estimators</span><span class="o">=</span><span class="default_value">10</span></em>, <em class="sig-param"><span class="n">round</span><span class="o">=</span><span class="default_value">4</span></em>, <em class="sig-param"><span class="n">choose_better</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">optimize</span><span class="o">=</span><span class="default_value">'Accuracy'</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.classification.ensemble_model" title="Permalink to this definition">¶</a></dt>
<dd><p>This function ensembles the trained base estimator using the method defined in
‘method’ param (default = ‘Bagging’). The output prints a score grid that shows
Accuracy, AUC, Recall, Precision, F1, Kappa and MCC by fold (default = 10 Fold).</p>
<p>This function returns a trained model object.</p>
<p>Model must be created using create_model() or tune_model().</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pycaret.datasets</span> <span class="kn">import</span> <span class="n">get_data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">juice</span> <span class="o">=</span> <span class="n">get_data</span><span class="p">(</span><span class="s1">&#39;juice&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">experiment_name</span> <span class="o">=</span> <span class="n">setup</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">juice</span><span class="p">,</span>  <span class="n">target</span> <span class="o">=</span> <span class="s1">&#39;Purchase&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dt</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">(</span><span class="s1">&#39;dt&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ensembled_dt</span> <span class="o">=</span> <span class="n">ensemble_model</span><span class="p">(</span><span class="n">dt</span><span class="p">)</span>
</pre></div>
</div>
<p>This will return an ensembled Decision Tree model using ‘Bagging’.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>estimator</strong> (<em>object</em><em>, </em><em>default = None</em>) – </p></li>
<li><p><strong>method</strong> (<em>String</em><em>, </em><em>default = 'Bagging'</em>) – Bagging method will create an ensemble meta-estimator that fits base
classifiers each on random subsets of the original dataset. The other
available method is ‘Boosting’ which will create a meta-estimators by
fitting a classifier on the original dataset and then fits additional
copies of the classifier on the same dataset but where the weights of
incorrectly classified instances are adjusted such that subsequent
classifiers focus more on difficult cases.</p></li>
<li><p><strong>fold</strong> (<em>integer</em><em>, </em><em>default = 10</em>) – Number of folds to be used in Kfold CV. Must be at least 2.</p></li>
<li><p><strong>n_estimators</strong> (<em>integer</em><em>, </em><em>default = 10</em>) – The number of base estimators in the ensemble.
In case of perfect fit, the learning procedure is stopped early.</p></li>
<li><p><strong>round</strong> (<em>integer</em><em>, </em><em>default = 4</em>) – Number of decimal places the metrics in the score grid will be rounded to.</p></li>
<li><p><strong>choose_better</strong> (<em>Boolean</em><em>, </em><em>default = False</em>) – When set to set to True, base estimator is returned when the metric doesn’t
improve by ensemble_model. This gurantees the returned object would perform
atleast equivalent to base estimator created using create_model or model
returned by compare_models.</p></li>
<li><p><strong>optimize</strong> (<em>string</em><em>, </em><em>default = 'Accuracy'</em>) – Only used when choose_better is set to True. optimize parameter is used
to compare emsembled model with base estimator. Values accepted in
optimize parameter are ‘Accuracy’, ‘AUC’, ‘Recall’, ‘Precision’, ‘F1’,
‘Kappa’, ‘MCC’.</p></li>
<li><p><strong>verbose</strong> (<em>Boolean</em><em>, </em><em>default = True</em>) – Score grid is not printed when verbose is set to False.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><em>score_grid</em> – A table containing the scores of the model across the kfolds.
Scoring metrics used are Accuracy, AUC, Recall, Precision, F1,
Kappa and MCC. Mean and standard deviation of the scores across
the folds are also returned.</p></li>
<li><p><em>model</em> – Trained ensembled model object.</p></li>
</ul>
</p>
</dd>
</dl>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<ul class="simple">
<li><p>If target variable is multiclass (more than 2 classes), AUC will be returned
as zero (0.0).</p></li>
</ul>
</div>
</dd></dl>

<dl class="py function">
<dt id="pycaret.classification.evaluate_model">
<code class="sig-prename descclassname">pycaret.classification.</code><code class="sig-name descname">evaluate_model</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">estimator</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.classification.evaluate_model" title="Permalink to this definition">¶</a></dt>
<dd><p>This function displays a user interface for all of the available plots for
a given estimator. It internally uses the plot_model() function.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pycaret.datasets</span> <span class="kn">import</span> <span class="n">get_data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">juice</span> <span class="o">=</span> <span class="n">get_data</span><span class="p">(</span><span class="s1">&#39;juice&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">experiment_name</span> <span class="o">=</span> <span class="n">setup</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">juice</span><span class="p">,</span>  <span class="n">target</span> <span class="o">=</span> <span class="s1">&#39;Purchase&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lr</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">(</span><span class="s1">&#39;lr&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">evaluate_model</span><span class="p">(</span><span class="n">lr</span><span class="p">)</span>
</pre></div>
</div>
<p>This will display the User Interface for all of the plots for a given
estimator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>estimator</strong> (<em>object</em><em>, </em><em>default = none</em>) – A trained model object should be passed as an estimator.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Displays the user interface for plotting.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>User_Interface</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pycaret.classification.finalize_model">
<code class="sig-prename descclassname">pycaret.classification.</code><code class="sig-name descname">finalize_model</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">estimator</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.classification.finalize_model" title="Permalink to this definition">¶</a></dt>
<dd><p>This function fits the estimator onto the complete dataset passed during the
setup() stage. The purpose of this function is to prepare for final model
deployment after experimentation.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pycaret.datasets</span> <span class="kn">import</span> <span class="n">get_data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">juice</span> <span class="o">=</span> <span class="n">get_data</span><span class="p">(</span><span class="s1">&#39;juice&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">experiment_name</span> <span class="o">=</span> <span class="n">setup</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">juice</span><span class="p">,</span>  <span class="n">target</span> <span class="o">=</span> <span class="s1">&#39;Purchase&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lr</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">(</span><span class="s1">&#39;lr&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">final_lr</span> <span class="o">=</span> <span class="n">finalize_model</span><span class="p">(</span><span class="n">lr</span><span class="p">)</span>
</pre></div>
</div>
<p>This will return the final model object fitted to complete dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>estimator</strong> (<em>object</em><em>, </em><em>default = none</em>) – A trained model object should be passed as an estimator.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Trained model object fitted on complete dataset.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>model</p>
</dd>
</dl>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<ul class="simple">
<li><p>If the model returned by finalize_model(), is used on predict_model() without
passing a new unseen dataset, then the information grid printed is misleading
as the model is trained on the complete dataset including test / hold-out sample.
Once finalize_model() is used, the model is considered ready for deployment and
should be used on new unseens dataset only.</p></li>
</ul>
</div>
</dd></dl>

<dl class="py function">
<dt id="pycaret.classification.get_config">
<code class="sig-prename descclassname">pycaret.classification.</code><code class="sig-name descname">get_config</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">variable</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.classification.get_config" title="Permalink to this definition">¶</a></dt>
<dd><p>This function is used to access global environment variables.
Following variables can be accessed:</p>
<ul class="simple">
<li><p>X: Transformed dataset (X)</p></li>
<li><p>y: Transformed dataset (y)</p></li>
<li><p>X_train: Transformed train dataset (X)</p></li>
<li><p>X_test: Transformed test/holdout dataset (X)</p></li>
<li><p>y_train: Transformed train dataset (y)</p></li>
<li><p>y_test: Transformed test/holdout dataset (y)</p></li>
<li><p>seed: random state set through session_id</p></li>
<li><p>prep_pipe: Transformation pipeline configured through setup</p></li>
<li><p>folds_shuffle_param: shuffle parameter used in Kfolds</p></li>
<li><p>n_jobs_param: n_jobs parameter used in model training</p></li>
<li><p>html_param: html_param configured through setup</p></li>
<li><p>create_model_container: results grid storage container</p></li>
<li><p>master_model_container: model storage container</p></li>
<li><p>display_container: results display container</p></li>
<li><p>exp_name_log: Name of experiment set through setup</p></li>
<li><p>logging_param: log_experiment param set through setup</p></li>
<li><p>log_plots_param: log_plots param set through setup</p></li>
<li><p>USI: Unique session ID parameter set through setup</p></li>
<li><p>fix_imbalance_param: fix_imbalance param set through setup</p></li>
<li><p>fix_imbalance_method_param: fix_imbalance_method param set through setup</p></li>
</ul>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">X_train</span> <span class="o">=</span> <span class="n">get_config</span><span class="p">(</span><span class="s1">&#39;X_train&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>This will return X_train transformed dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>variable</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pycaret.classification.get_logs">
<code class="sig-prename descclassname">pycaret.classification.</code><code class="sig-name descname">get_logs</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">experiment_name</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">save</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.classification.get_logs" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a table with experiment logs consisting
run details, parameter, metrics and tags.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">logs</span> <span class="o">=</span> <span class="n">get_logs</span><span class="p">()</span>
</pre></div>
</div>
<p>This will return pandas dataframe.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>experiment_name</strong> (<em>string</em><em>, </em><em>default = None</em>) – When set to None current active run is used.</p></li>
<li><p><strong>save</strong> (<em>bool</em><em>, </em><em>default = False</em>) – When set to True, csv file is saved in current directory.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>pandas.DataFrame</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pycaret.classification.get_system_logs">
<code class="sig-prename descclassname">pycaret.classification.</code><code class="sig-name descname">get_system_logs</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.classification.get_system_logs" title="Permalink to this definition">¶</a></dt>
<dd><p>Read and print ‘logs.log’ file from current active directory</p>
</dd></dl>

<dl class="py function">
<dt id="pycaret.classification.interpret_model">
<code class="sig-prename descclassname">pycaret.classification.</code><code class="sig-name descname">interpret_model</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">estimator</span></em>, <em class="sig-param"><span class="n">plot</span><span class="o">=</span><span class="default_value">'summary'</span></em>, <em class="sig-param"><span class="n">feature</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">observation</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.classification.interpret_model" title="Permalink to this definition">¶</a></dt>
<dd><p>This function takes a trained model object and returns an interpretation plot
based on the test / hold-out set. It only supports tree based algorithms.</p>
<p>This function is implemented based on the SHAP (SHapley Additive exPlanations),
which is a unified approach to explain the output of any machine learning model.
SHAP connects game theory with local explanations.</p>
<p>For more information : <a class="reference external" href="https://shap.readthedocs.io/en/latest/">https://shap.readthedocs.io/en/latest/</a></p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pycaret.datasets</span> <span class="kn">import</span> <span class="n">get_data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">juice</span> <span class="o">=</span> <span class="n">get_data</span><span class="p">(</span><span class="s1">&#39;juice&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">experiment_name</span> <span class="o">=</span> <span class="n">setup</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">juice</span><span class="p">,</span>  <span class="n">target</span> <span class="o">=</span> <span class="s1">&#39;Purchase&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dt</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">(</span><span class="s1">&#39;dt&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">interpret_model</span><span class="p">(</span><span class="n">dt</span><span class="p">)</span>
</pre></div>
</div>
<p>This will return a summary interpretation plot of Decision Tree model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>estimator</strong> (<em>object</em><em>, </em><em>default = none</em>) – A trained tree based model object should be passed as an estimator.</p></li>
<li><p><strong>plot</strong> (<em>string</em><em>, </em><em>default = 'summary'</em>) – Other available options are ‘correlation’ and ‘reason’.</p></li>
<li><p><strong>feature</strong> (<em>string</em><em>, </em><em>default = None</em>) – This parameter is only needed when plot = ‘correlation’. By default feature is
set to None which means the first column of the dataset will be used as a variable.
A feature parameter must be passed to change this.</p></li>
<li><p><strong>observation</strong> (<em>integer</em><em>, </em><em>default = None</em>) – This parameter only comes into effect when plot is set to ‘reason’. If no observation
number is provided, it will return an analysis of all observations with the option
to select the feature on x and y axes through drop down interactivity. For analysis at
the sample level, an observation parameter must be passed with the index value of the
observation in test / hold-out set.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Returns the visual plot.
Returns the interactive JS plot when plot = ‘reason’.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Visual_Plot</p>
</dd>
</dl>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<ul class="simple">
<li><p>interpret_model doesn’t support multiclass problems.</p></li>
</ul>
</div>
</dd></dl>

<dl class="py function">
<dt id="pycaret.classification.load_model">
<code class="sig-prename descclassname">pycaret.classification.</code><code class="sig-name descname">load_model</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">model_name</span></em>, <em class="sig-param"><span class="n">platform</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">authentication</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.classification.load_model" title="Permalink to this definition">¶</a></dt>
<dd><p>This function loads a previously saved transformation pipeline and model
from the current active directory into the current python environment.
Load object must be a pickle file.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">saved_lr</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="s1">&#39;lr_model_23122019&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>This will load the previously saved model in saved_lr variable. The file
must be in the current directory.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_name</strong> (<em>string</em><em>, </em><em>default = none</em>) – Name of pickle file to be passed as a string.</p></li>
<li><p><strong>platform</strong> (<em>string</em><em>, </em><em>default = None</em>) – Name of platform, if loading model from cloud. Current available options are:
‘aws’.</p></li>
<li><p><strong>authentication</strong> (<em>dict</em>) – <p>Dictionary of applicable authentication tokens.</p>
<p>When platform = ‘aws’:
{‘bucket’ : ‘Name of Bucket on S3’}</p>
</p></li>
<li><p><strong>verbose</strong> (<em>Boolean</em><em>, </em><em>default = True</em>) – Success message is not printed when verbose is set to False.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Success_Message</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pycaret.classification.models">
<code class="sig-prename descclassname">pycaret.classification.</code><code class="sig-name descname">models</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">type</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.classification.models" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns table of models available in model library.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">all_models</span> <span class="o">=</span> <span class="n">models</span><span class="p">()</span>
</pre></div>
</div>
<p>This will return pandas dataframe with all available
models and their metadata.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>type</strong> (<em>string</em><em>, </em><em>default = None</em>) – <ul class="simple">
<li><p>linear : filters and only return linear models</p></li>
<li><p>tree : filters and only return tree based models</p></li>
<li><p>ensemble : filters and only return ensemble models</p></li>
</ul>
</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>pandas.DataFrame</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pycaret.classification.optimize_threshold">
<code class="sig-prename descclassname">pycaret.classification.</code><code class="sig-name descname">optimize_threshold</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">estimator</span></em>, <em class="sig-param"><span class="n">true_positive</span><span class="o">=</span><span class="default_value">0</span></em>, <em class="sig-param"><span class="n">true_negative</span><span class="o">=</span><span class="default_value">0</span></em>, <em class="sig-param"><span class="n">false_positive</span><span class="o">=</span><span class="default_value">0</span></em>, <em class="sig-param"><span class="n">false_negative</span><span class="o">=</span><span class="default_value">0</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.classification.optimize_threshold" title="Permalink to this definition">¶</a></dt>
<dd><p>This function optimizes probability threshold for a trained model using custom cost
function that can be defined using combination of True Positives, True Negatives,
False Positives (also known as Type I error), and False Negatives (Type II error).</p>
<p>This function returns a plot of optimized cost as a function of probability
threshold between 0 to 100.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pycaret.datasets</span> <span class="kn">import</span> <span class="n">get_data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">juice</span> <span class="o">=</span> <span class="n">get_data</span><span class="p">(</span><span class="s1">&#39;juice&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">experiment_name</span> <span class="o">=</span> <span class="n">setup</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">juice</span><span class="p">,</span>  <span class="n">target</span> <span class="o">=</span> <span class="s1">&#39;Purchase&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lr</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">(</span><span class="s1">&#39;lr&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">optimize_threshold</span><span class="p">(</span><span class="n">lr</span><span class="p">,</span> <span class="n">true_negative</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="n">false_negative</span> <span class="o">=</span> <span class="o">-</span><span class="mi">100</span><span class="p">)</span>
</pre></div>
</div>
<p>This will return a plot of optimized cost as a function of probability threshold.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>estimator</strong> (<em>object</em>) – A trained model object should be passed as an estimator.</p></li>
<li><p><strong>true_positive</strong> (<em>int</em><em>, </em><em>default = 0</em>) – Cost function or returns when prediction is true positive.</p></li>
<li><p><strong>true_negative</strong> (<em>int</em><em>, </em><em>default = 0</em>) – Cost function or returns when prediction is true negative.</p></li>
<li><p><strong>false_positive</strong> (<em>int</em><em>, </em><em>default = 0</em>) – Cost function or returns when prediction is false positive.</p></li>
<li><p><strong>false_negative</strong> (<em>int</em><em>, </em><em>default = 0</em>) – Cost function or returns when prediction is false negative.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Prints the visual plot.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Visual_Plot</p>
</dd>
</dl>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<ul class="simple">
<li><p>This function is not supported for multiclass problems.</p></li>
</ul>
</div>
</dd></dl>

<dl class="py function">
<dt id="pycaret.classification.plot_model">
<code class="sig-prename descclassname">pycaret.classification.</code><code class="sig-name descname">plot_model</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">estimator</span></em>, <em class="sig-param"><span class="n">plot</span><span class="o">=</span><span class="default_value">'auc'</span></em>, <em class="sig-param"><span class="n">save</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">system</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.classification.plot_model" title="Permalink to this definition">¶</a></dt>
<dd><p>This function takes a trained model object and returns a plot based on the
test / hold-out set. The process may require the model to be re-trained in
certain cases. See list of plots supported below.</p>
<p>Model must be created using create_model() or tune_model().</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pycaret.datasets</span> <span class="kn">import</span> <span class="n">get_data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">juice</span> <span class="o">=</span> <span class="n">get_data</span><span class="p">(</span><span class="s1">&#39;juice&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">experiment_name</span> <span class="o">=</span> <span class="n">setup</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">juice</span><span class="p">,</span>  <span class="n">target</span> <span class="o">=</span> <span class="s1">&#39;Purchase&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lr</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">(</span><span class="s1">&#39;lr&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">plot_model</span><span class="p">(</span><span class="n">lr</span><span class="p">)</span>
</pre></div>
</div>
<p>This will return an AUC plot of a trained Logistic Regression model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>estimator</strong> (<em>object</em><em>, </em><em>default = none</em>) – A trained model object should be passed as an estimator.</p></li>
<li><p><strong>plot</strong> (<em>string</em><em>, </em><em>default = auc</em>) – <p>Enter abbreviation of type of plot. The current list of plots supported are:</p>
<p>Plot                    Name
——————      ———————–
‘auc’                   Area Under the Curve
‘threshold’             Discrimination Threshold
‘pr’                    Precision Recall Curve
‘confusion_matrix’      Confusion Matrix
‘error’                 Class Prediction Error
‘class_report’          Classification Report
‘boundary’              Decision Boundary
‘rfe’                   Recursive Feature Selection
‘learning’              Learning Curve
‘manifold’              Manifold Learning
‘calibration’           Calibration Curve
‘vc’                    Validation Curve
‘dimension’             Dimension Learning
‘feature’               Feature Importance
‘parameter’             Model Hyperparameter</p>
</p></li>
<li><p><strong>save</strong> (<em>Boolean</em><em>, </em><em>default = False</em>) – When set to True, Plot is saved as a ‘png’ file in current working directory.</p></li>
<li><p><strong>verbose</strong> (<em>Boolean</em><em>, </em><em>default = True</em>) – Progress bar not shown when verbose set to False.</p></li>
<li><p><strong>system</strong> (<em>Boolean</em><em>, </em><em>default = True</em>) – Must remain True all times. Only to be changed by internal functions.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Prints the visual plot.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Visual_Plot</p>
</dd>
</dl>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<ul class="simple">
<li><dl class="simple">
<dt>‘svm’ and ‘ridge’ doesn’t support the predict_proba method. As such, AUC and</dt><dd><p>calibration plots are not available for these estimators.</p>
</dd>
</dl>
</li>
<li><p>When the ‘max_features’ parameter of a trained model object is not equal to
the number of samples in training set, the ‘rfe’ plot is not available.</p></li>
<li><dl class="simple">
<dt>‘calibration’, ‘threshold’, ‘manifold’ and ‘rfe’ plots are not available for</dt><dd><p>multiclass problems.</p>
</dd>
</dl>
</li>
</ul>
</div>
</dd></dl>

<dl class="py function">
<dt id="pycaret.classification.predict_model">
<code class="sig-prename descclassname">pycaret.classification.</code><code class="sig-name descname">predict_model</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">estimator</span></em>, <em class="sig-param"><span class="n">data</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">probability_threshold</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.classification.predict_model" title="Permalink to this definition">¶</a></dt>
<dd><p>This function is used to predict label and probability score on the new dataset
using a trained estimator. New unseen data can be passed to data param as pandas
Dataframe. If data is not passed, the test / hold-out set separated at the time of
setup() is used to generate predictions.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pycaret.datasets</span> <span class="kn">import</span> <span class="n">get_data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">juice</span> <span class="o">=</span> <span class="n">get_data</span><span class="p">(</span><span class="s1">&#39;juice&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">experiment_name</span> <span class="o">=</span> <span class="n">setup</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">juice</span><span class="p">,</span>  <span class="n">target</span> <span class="o">=</span> <span class="s1">&#39;Purchase&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lr</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">(</span><span class="s1">&#39;lr&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lr_predictions_holdout</span> <span class="o">=</span> <span class="n">predict_model</span><span class="p">(</span><span class="n">lr</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>estimator</strong> (<em>object</em><em>, </em><em>default = none</em>) – A trained model object / pipeline should be passed as an estimator.</p></li>
<li><p><strong>data</strong> (<em>{array-like</em><em>, </em><em>sparse matrix}</em>) – Shape (n_samples, n_features) where n_samples is the number of samples and n_features is the number of features.
All features used during training must be present in the new dataset.</p></li>
<li><p><strong>probability_threshold</strong> (<em>float</em><em>, </em><em>default = None</em>) – Threshold used to convert probability values into binary outcome. By default the
probability threshold for all binary classifiers is 0.5 (50%). This can be changed
using probability_threshold param.</p></li>
<li><p><strong>verbose</strong> (<em>Boolean</em><em>, </em><em>default = True</em>) – Holdout score grid is not printed when verbose is set to False.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><em>Predictions</em> – Predictions (Label and Score) column attached to the original dataset
and returned as pandas dataframe.</p></li>
<li><p><em>score_grid</em> – A table containing the scoring metrics on hold-out / test set.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pycaret.classification.pull">
<code class="sig-prename descclassname">pycaret.classification.</code><code class="sig-name descname">pull</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.classification.pull" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns latest displayed table.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Equivalent to get_config(‘display_container’)[-1]</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>pandas.DataFrame</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pycaret.classification.save_model">
<code class="sig-prename descclassname">pycaret.classification.</code><code class="sig-name descname">save_model</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">model</span></em>, <em class="sig-param"><span class="n">model_name</span></em>, <em class="sig-param"><span class="n">model_only</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.classification.save_model" title="Permalink to this definition">¶</a></dt>
<dd><p>This function saves the transformation pipeline and trained model object
into the current active directory as a pickle file for later use.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pycaret.datasets</span> <span class="kn">import</span> <span class="n">get_data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">juice</span> <span class="o">=</span> <span class="n">get_data</span><span class="p">(</span><span class="s1">&#39;juice&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">experiment_name</span> <span class="o">=</span> <span class="n">setup</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">juice</span><span class="p">,</span>  <span class="n">target</span> <span class="o">=</span> <span class="s1">&#39;Purchase&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lr</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">(</span><span class="s1">&#39;lr&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">save_model</span><span class="p">(</span><span class="n">lr</span><span class="p">,</span> <span class="s1">&#39;lr_model_23122019&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>This will save the transformation pipeline and model as a binary pickle
file in the current active directory.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>object</em><em>, </em><em>default = none</em>) – A trained model object should be passed as an estimator.</p></li>
<li><p><strong>model_name</strong> (<em>string</em><em>, </em><em>default = none</em>) – Name of pickle file to be passed as a string.</p></li>
<li><p><strong>model_only</strong> (<em>bool</em><em>, </em><em>default = False</em>) – When set to True, only trained model object is saved and all the
transformations are ignored.</p></li>
<li><p><strong>verbose</strong> (<em>Boolean</em><em>, </em><em>default = True</em>) – Success message is not printed when verbose is set to False.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Success_Message</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pycaret.classification.set_config">
<code class="sig-prename descclassname">pycaret.classification.</code><code class="sig-name descname">set_config</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">variable</span></em>, <em class="sig-param"><span class="n">value</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.classification.set_config" title="Permalink to this definition">¶</a></dt>
<dd><p>This function is used to reset global environment variables.
Following variables can be accessed:</p>
<ul class="simple">
<li><p>X: Transformed dataset (X)</p></li>
<li><p>y: Transformed dataset (y)</p></li>
<li><p>X_train: Transformed train dataset (X)</p></li>
<li><p>X_test: Transformed test/holdout dataset (X)</p></li>
<li><p>y_train: Transformed train dataset (y)</p></li>
<li><p>y_test: Transformed test/holdout dataset (y)</p></li>
<li><p>seed: random state set through session_id</p></li>
<li><p>prep_pipe: Transformation pipeline configured through setup</p></li>
<li><p>folds_shuffle_param: shuffle parameter used in Kfolds</p></li>
<li><p>n_jobs_param: n_jobs parameter used in model training</p></li>
<li><p>html_param: html_param configured through setup</p></li>
<li><p>create_model_container: results grid storage container</p></li>
<li><p>master_model_container: model storage container</p></li>
<li><p>display_container: results display container</p></li>
<li><p>exp_name_log: Name of experiment set through setup</p></li>
<li><p>logging_param: log_experiment param set through setup</p></li>
<li><p>log_plots_param: log_plots param set through setup</p></li>
<li><p>USI: Unique session ID parameter set through setup</p></li>
<li><p>fix_imbalance_param: fix_imbalance param set through setup</p></li>
<li><p>fix_imbalance_method_param: fix_imbalance_method param set through setup</p></li>
</ul>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">set_config</span><span class="p">(</span><span class="s1">&#39;seed&#39;</span><span class="p">,</span> <span class="mi">123</span><span class="p">)</span>
</pre></div>
</div>
<p>This will set the global seed to ‘123’.</p>
</dd></dl>

<dl class="py function">
<dt id="pycaret.classification.setup">
<code class="sig-prename descclassname">pycaret.classification.</code><code class="sig-name descname">setup</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">target</span></em>, <em class="sig-param"><span class="n">train_size</span><span class="o">=</span><span class="default_value">0.7</span></em>, <em class="sig-param"><span class="n">sampling</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">sample_estimator</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">categorical_features</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">categorical_imputation</span><span class="o">=</span><span class="default_value">'constant'</span></em>, <em class="sig-param"><span class="n">ordinal_features</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">high_cardinality_features</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">high_cardinality_method</span><span class="o">=</span><span class="default_value">'frequency'</span></em>, <em class="sig-param"><span class="n">numeric_features</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">numeric_imputation</span><span class="o">=</span><span class="default_value">'mean'</span></em>, <em class="sig-param"><span class="n">date_features</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">ignore_features</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">normalize</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">normalize_method</span><span class="o">=</span><span class="default_value">'zscore'</span></em>, <em class="sig-param"><span class="n">transformation</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">transformation_method</span><span class="o">=</span><span class="default_value">'yeo-johnson'</span></em>, <em class="sig-param"><span class="n">handle_unknown_categorical</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">unknown_categorical_method</span><span class="o">=</span><span class="default_value">'least_frequent'</span></em>, <em class="sig-param"><span class="n">pca</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">pca_method</span><span class="o">=</span><span class="default_value">'linear'</span></em>, <em class="sig-param"><span class="n">pca_components</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">ignore_low_variance</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">combine_rare_levels</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">rare_level_threshold</span><span class="o">=</span><span class="default_value">0.1</span></em>, <em class="sig-param"><span class="n">bin_numeric_features</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">remove_outliers</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">outliers_threshold</span><span class="o">=</span><span class="default_value">0.05</span></em>, <em class="sig-param"><span class="n">remove_multicollinearity</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">multicollinearity_threshold</span><span class="o">=</span><span class="default_value">0.9</span></em>, <em class="sig-param"><span class="n">remove_perfect_collinearity</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">create_clusters</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">cluster_iter</span><span class="o">=</span><span class="default_value">20</span></em>, <em class="sig-param"><span class="n">polynomial_features</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">polynomial_degree</span><span class="o">=</span><span class="default_value">2</span></em>, <em class="sig-param"><span class="n">trigonometry_features</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">polynomial_threshold</span><span class="o">=</span><span class="default_value">0.1</span></em>, <em class="sig-param"><span class="n">group_features</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">group_names</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">feature_selection</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">feature_selection_threshold</span><span class="o">=</span><span class="default_value">0.8</span></em>, <em class="sig-param"><span class="n">feature_interaction</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">feature_ratio</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">interaction_threshold</span><span class="o">=</span><span class="default_value">0.01</span></em>, <em class="sig-param"><span class="n">fix_imbalance</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">fix_imbalance_method</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">data_split_shuffle</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">folds_shuffle</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">n_jobs</span><span class="o">=</span><span class="default_value">- 1</span></em>, <em class="sig-param"><span class="n">html</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">session_id</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">log_experiment</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">experiment_name</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">log_plots</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">log_profile</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">log_data</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">silent</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">profile</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.classification.setup" title="Permalink to this definition">¶</a></dt>
<dd><p>This function initializes the environment in pycaret and creates the transformation
pipeline to prepare the data for modeling and deployment. setup() must called before
executing any other function in pycaret. It takes two mandatory parameters:
dataframe {array-like, sparse matrix} and name of the target column.</p>
<p>All other parameters are optional.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pycaret.datasets</span> <span class="kn">import</span> <span class="n">get_data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">juice</span> <span class="o">=</span> <span class="n">get_data</span><span class="p">(</span><span class="s1">&#39;juice&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">experiment_name</span> <span class="o">=</span> <span class="n">setup</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">juice</span><span class="p">,</span>  <span class="n">target</span> <span class="o">=</span> <span class="s1">&#39;Purchase&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>‘juice’ is a pandas DataFrame and ‘Purchase’ is the name of target column.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<em>{array-like</em><em>, </em><em>sparse matrix}</em>) – Shape (n_samples, n_features) where n_samples is the number of samples and n_features is the number of features.</p></li>
<li><p><strong>target</strong> (<em>string</em>) – Name of the target column to be passed in as a string. The target variable could
be binary or multiclass. In case of a multiclass target, all estimators are wrapped
with a OneVsRest classifier.</p></li>
<li><p><strong>train_size</strong> (<em>float</em><em>, </em><em>default = 0.7</em>) – Size of the training set. By default, 70% of the data will be used for training
and validation. The remaining data will be used for a test / hold-out set.</p></li>
<li><p><strong>sampling</strong> (<em>bool</em><em>, </em><em>default = True</em>) – When the sample size exceeds 25,000 samples, pycaret will build a base estimator
at various sample sizes from the original dataset. This will return a performance
plot of AUC, Accuracy, Recall, Precision, Kappa and F1 values at various sample
levels, that will assist in deciding the preferred sample size for modeling.
The desired sample size must then be entered for training and validation in the
pycaret environment. When sample_size entered is less than 1, the remaining dataset
(1 - sample) is used for fitting the model only when finalize_model() is called.</p></li>
<li><p><strong>sample_estimator</strong> (<em>object</em><em>, </em><em>default = None</em>) – If None, Logistic Regression is used by default.</p></li>
<li><p><strong>categorical_features</strong> (<em>string</em><em>, </em><em>default = None</em>) – If the inferred data types are not correct, categorical_features can be used to
overwrite the inferred type. If when running setup the type of ‘column1’ is
inferred as numeric instead of categorical, then this parameter can be used
to overwrite the type by passing categorical_features = [‘column1’].</p></li>
<li><p><strong>categorical_imputation</strong> (<em>string</em><em>, </em><em>default = 'constant'</em>) – If missing values are found in categorical features, they will be imputed with
a constant ‘not_available’ value. The other available option is ‘mode’ which
imputes the missing value using most frequent value in the training dataset.</p></li>
<li><p><strong>ordinal_features</strong> (<em>dictionary</em><em>, </em><em>default = None</em>) – When the data contains ordinal features, they must be encoded differently using
the ordinal_features param. If the data has a categorical variable with values
of ‘low’, ‘medium’, ‘high’ and it is known that low &lt; medium &lt; high, then it can
be passed as ordinal_features = { ‘column_name’ : [‘low’, ‘medium’, ‘high’] }.
The list sequence must be in increasing order from lowest to highest.</p></li>
<li><p><strong>high_cardinality_features</strong> (<em>string</em><em>, </em><em>default = None</em>) – When the data containts features with high cardinality, they can be compressed
into fewer levels by passing them as a list of column names with high cardinality.
Features are compressed using method defined in high_cardinality_method param.</p></li>
<li><p><strong>high_cardinality_method</strong> (<em>string</em><em>, </em><em>default = 'frequency'</em>) – When method set to ‘frequency’ it will replace the original value of feature
with the frequency distribution and convert the feature into numeric. Other
available method is ‘clustering’ which performs the clustering on statistical
attribute of data and replaces the original value of feature with cluster label.
The number of clusters is determined using a combination of Calinski-Harabasz and
Silhouette criterion.</p></li>
<li><p><strong>numeric_features</strong> (<em>string</em><em>, </em><em>default = None</em>) – If the inferred data types are not correct, numeric_features can be used to
overwrite the inferred type. If when running setup the type of ‘column1’ is
inferred as a categorical instead of numeric, then this parameter can be used
to overwrite by passing numeric_features = [‘column1’].</p></li>
<li><p><strong>numeric_imputation</strong> (<em>string</em><em>, </em><em>default = 'mean'</em>) – If missing values are found in numeric features, they will be imputed with the
mean value of the feature. The other available option is ‘median’ which imputes
the value using the median value in the training dataset.</p></li>
<li><p><strong>date_features</strong> (<em>string</em><em>, </em><em>default = None</em>) – If the data has a DateTime column that is not automatically detected when running
setup, this parameter can be used by passing date_features = ‘date_column_name’.
It can work with multiple date columns. Date columns are not used in modeling.
Instead, feature extraction is performed and date columns are dropped from the
dataset. If the date column includes a time stamp, features related to time will
also be extracted.</p></li>
<li><p><strong>ignore_features</strong> (<em>string</em><em>, </em><em>default = None</em>) – If any feature should be ignored for modeling, it can be passed to the param
ignore_features. The ID and DateTime columns when inferred, are automatically
set to ignore for modeling.</p></li>
<li><p><strong>normalize</strong> (<em>bool</em><em>, </em><em>default = False</em>) – When set to True, the feature space is transformed using the normalized_method
param. Generally, linear algorithms perform better with normalized data however,
the results may vary and it is advised to run multiple experiments to evaluate
the benefit of normalization.</p></li>
<li><p><strong>normalize_method</strong> (<em>string</em><em>, </em><em>default = 'zscore'</em>) – <p>Defines the method to be used for normalization. By default, normalize method
is set to ‘zscore’. The standard zscore is calculated as z = (x - u) / s. The
other available options are:</p>
<dl class="simple">
<dt>’minmax’<span class="classifier">scales and translates each feature individually such that it is in</span></dt><dd><p>the range of 0 - 1.</p>
</dd>
<dt>’maxabs’<span class="classifier">scales and translates each feature individually such that the maximal</span></dt><dd><p>absolute value of each feature will be 1.0. It does not shift/center
the data, and thus does not destroy any sparsity.</p>
</dd>
<dt>’robust’<span class="classifier">scales and translates each feature according to the Interquartile range.</span></dt><dd><p>When the dataset contains outliers, robust scaler often gives better
results.</p>
</dd>
</dl>
</p></li>
<li><p><strong>transformation</strong> (<em>bool</em><em>, </em><em>default = False</em>) – When set to True, a power transformation is applied to make the data more normal /
Gaussian-like. This is useful for modeling issues related to heteroscedasticity or
other situations where normality is desired. The optimal parameter for stabilizing
variance and minimizing skewness is estimated through maximum likelihood.</p></li>
<li><p><strong>transformation_method</strong> (<em>string</em><em>, </em><em>default = 'yeo-johnson'</em>) – Defines the method for transformation. By default, the transformation method is set
to ‘yeo-johnson’. The other available option is ‘quantile’ transformation. Both
the transformation transforms the feature set to follow a Gaussian-like or normal
distribution. Note that the quantile transformer is non-linear and may distort linear
correlations between variables measured at the same scale.</p></li>
<li><p><strong>handle_unknown_categorical</strong> (<em>bool</em><em>, </em><em>default = True</em>) – When set to True, unknown categorical levels in new / unseen data are replaced by
the most or least frequent level as learned in the training data. The method is
defined under the unknown_categorical_method param.</p></li>
<li><p><strong>unknown_categorical_method</strong> (<em>string</em><em>, </em><em>default = 'least_frequent'</em>) – Method used to replace unknown categorical levels in unseen data. Method can be
set to ‘least_frequent’ or ‘most_frequent’.</p></li>
<li><p><strong>pca</strong> (<em>bool</em><em>, </em><em>default = False</em>) – When set to True, dimensionality reduction is applied to project the data into
a lower dimensional space using the method defined in pca_method param. In
supervised learning pca is generally performed when dealing with high feature
space and memory is a constraint. Note that not all datasets can be decomposed
efficiently using a linear PCA technique and that applying PCA may result in loss
of information. As such, it is advised to run multiple experiments with different
pca_methods to evaluate the impact.</p></li>
<li><p><strong>pca_method</strong> (<em>string</em><em>, </em><em>default = 'linear'</em>) – <p>The ‘linear’ method performs Linear dimensionality reduction using Singular Value
Decomposition. The other available options are:</p>
<p>kernel      : dimensionality reduction through the use of RVF kernel.</p>
<dl class="simple">
<dt>incremental<span class="classifier">replacement for ‘linear’ pca when the dataset to be decomposed is</span></dt><dd><p>too large to fit in memory</p>
</dd>
</dl>
</p></li>
<li><p><strong>pca_components</strong> (<em>int/float</em><em>, </em><em>default = 0.99</em>) – Number of components to keep. if pca_components is a float, it is treated as a
target percentage for information retention. When pca_components is an integer
it is treated as the number of features to be kept. pca_components must be strictly
less than the original number of features in the dataset.</p></li>
<li><p><strong>ignore_low_variance</strong> (<em>bool</em><em>, </em><em>default = False</em>) – When set to True, all categorical features with statistically insignificant variances
are removed from the dataset. The variance is calculated using the ratio of unique
values to the number of samples, and the ratio of the most common value to the
frequency of the second most common value.</p></li>
<li><p><strong>combine_rare_levels</strong> (<em>bool</em><em>, </em><em>default = False</em>) – When set to True, all levels in categorical features below the threshold defined
in rare_level_threshold param are combined together as a single level. There must be
atleast two levels under the threshold for this to take effect. rare_level_threshold
represents the percentile distribution of level frequency. Generally, this technique
is applied to limit a sparse matrix caused by high numbers of levels in categorical
features.</p></li>
<li><p><strong>rare_level_threshold</strong> (<em>float</em><em>, </em><em>default = 0.1</em>) – Percentile distribution below which rare categories are combined. Only comes into
effect when combine_rare_levels is set to True.</p></li>
<li><p><strong>bin_numeric_features</strong> (<em>list</em><em>, </em><em>default = None</em>) – When a list of numeric features is passed they are transformed into categorical
features using KMeans, where values in each bin have the same nearest center of a
1D k-means cluster. The number of clusters are determined based on the ‘sturges’
method. It is only optimal for gaussian data and underestimates the number of bins
for large non-gaussian datasets.</p></li>
<li><p><strong>remove_outliers</strong> (<em>bool</em><em>, </em><em>default = False</em>) – When set to True, outliers from the training data are removed using PCA linear
dimensionality reduction using the Singular Value Decomposition technique.</p></li>
<li><p><strong>outliers_threshold</strong> (<em>float</em><em>, </em><em>default = 0.05</em>) – The percentage / proportion of outliers in the dataset can be defined using
the outliers_threshold param. By default, 0.05 is used which means 0.025 of the
values on each side of the distribution’s tail are dropped from training data.</p></li>
<li><p><strong>remove_multicollinearity</strong> (<em>bool</em><em>, </em><em>default = False</em>) – When set to True, the variables with inter-correlations higher than the threshold
defined under the multicollinearity_threshold param are dropped. When two features
are highly correlated with each other, the feature that is less correlated with
the target variable is dropped.</p></li>
<li><p><strong>multicollinearity_threshold</strong> (<em>float</em><em>, </em><em>default = 0.9</em>) – Threshold used for dropping the correlated features. Only comes into effect when
remove_multicollinearity is set to True.</p></li>
<li><p><strong>remove_perfect_collinearity</strong> (<em>bool</em><em>, </em><em>default = False</em>) – When set to True, perfect collinearity (features with correlation = 1) is removed
from the dataset, When two features are 100% correlated, one of it is randomly
dropped from the dataset.</p></li>
<li><p><strong>create_clusters</strong> (<em>bool</em><em>, </em><em>default = False</em>) – When set to True, an additional feature is created where each instance is assigned
to a cluster. The number of clusters is determined using a combination of
Calinski-Harabasz and Silhouette criterion.</p></li>
<li><p><strong>cluster_iter</strong> (<em>int</em><em>, </em><em>default = 20</em>) – Number of iterations used to create a cluster. Each iteration represents cluster
size. Only comes into effect when create_clusters param is set to True.</p></li>
<li><p><strong>polynomial_features</strong> (<em>bool</em><em>, </em><em>default = False</em>) – When set to True, new features are created based on all polynomial combinations
that exist within the numeric features in a dataset to the degree defined in
polynomial_degree param.</p></li>
<li><p><strong>polynomial_degree</strong> (<em>int</em><em>, </em><em>default = 2</em>) – Degree of polynomial features. For example, if an input sample is two dimensional
and of the form [a, b], the polynomial features with degree = 2 are:
[1, a, b, a^2, ab, b^2].</p></li>
<li><p><strong>trigonometry_features</strong> (<em>bool</em><em>, </em><em>default = False</em>) – When set to True, new features are created based on all trigonometric combinations
that exist within the numeric features in a dataset to the degree defined in the
polynomial_degree param.</p></li>
<li><p><strong>polynomial_threshold</strong> (<em>float</em><em>, </em><em>default = 0.1</em>) – This is used to compress a sparse matrix of polynomial and trigonometric features.
Polynomial and trigonometric features whose feature importance based on the
combination of Random Forest, AdaBoost and Linear correlation falls within the
percentile of the defined threshold are kept in the dataset. Remaining features
are dropped before further processing.</p></li>
<li><p><strong>group_features</strong> (<em>list</em><em> or </em><em>list of list</em><em>, </em><em>default = None</em>) – When a dataset contains features that have related characteristics, the group_features
param can be used for statistical feature extraction. For example, if a dataset has
numeric features that are related with each other (i.e ‘Col1’, ‘Col2’, ‘Col3’), a list
containing the column names can be passed under group_features to extract statistical
information such as the mean, median, mode and standard deviation.</p></li>
<li><p><strong>group_names</strong> (<em>list</em><em>, </em><em>default = None</em>) – When group_features is passed, a name of the group can be passed into the group_names
param as a list containing strings. The length of a group_names list must equal to the
length  of group_features. When the length doesn’t match or the name is not passed, new
features are sequentially named such as group_1, group_2 etc.</p></li>
<li><p><strong>feature_selection</strong> (<em>bool</em><em>, </em><em>default = False</em>) – When set to True, a subset of features are selected using a combination of various
permutation importance techniques including Random Forest, Adaboost and Linear
correlation with target variable. The size of the subset is dependent on the
feature_selection_param. Generally, this is used to constrain the feature space
in order to improve efficiency in modeling. When polynomial_features and
feature_interaction  are used, it is highly recommended to define the
feature_selection_threshold param with a lower value.</p></li>
<li><p><strong>feature_selection_threshold</strong> (<em>float</em><em>, </em><em>default = 0.8</em>) – Threshold used for feature selection (including newly created polynomial features).
A higher value will result in a higher feature space. It is recommended to do multiple
trials with different values of feature_selection_threshold specially in cases where
polynomial_features and feature_interaction are used. Setting a very low value may be
efficient but could result in under-fitting.</p></li>
<li><p><strong>feature_interaction</strong> (<em>bool</em><em>, </em><em>default = False</em>) – When set to True, it will create new features by interacting (a * b) for all numeric
variables in the dataset including polynomial and trigonometric features (if created).
This feature is not scalable and may not work as expected on datasets with large
feature space.</p></li>
<li><p><strong>feature_ratio</strong> (<em>bool</em><em>, </em><em>default = False</em>) – When set to True, it will create new features by calculating the ratios (a / b) of all
numeric variables in the dataset. This feature is not scalable and may not work as
expected on datasets with large feature space.</p></li>
<li><p><strong>interaction_threshold</strong> (<em>bool</em><em>, </em><em>default = 0.01</em>) – Similar to polynomial_threshold, It is used to compress a sparse matrix of newly
created features through interaction. Features whose importance based on the
combination  of  Random Forest, AdaBoost and Linear correlation falls within the
percentile of the  defined threshold are kept in the dataset. Remaining features
are dropped before further processing.</p></li>
<li><p><strong>fix_imbalance</strong> (<em>bool</em><em>, </em><em>default = False</em>) – When dataset has unequal distribution of target class it can be fixed using
fix_imbalance parameter. When set to True, SMOTE (Synthetic Minority Over-sampling
Technique) is applied by default to create synthetic datapoints for minority class.</p></li>
<li><p><strong>fix_imbalance_method</strong> (<em>obj</em><em>, </em><em>default = None</em>) – When fix_imbalance is set to True and fix_imbalance_method is None, ‘smote’ is applied
by default to oversample minority class during cross validation. This parameter
accepts any module from ‘imblearn’ that supports ‘fit_resample’ method.</p></li>
<li><p><strong>data_split_shuffle</strong> (<em>bool</em><em>, </em><em>default = True</em>) – If set to False, prevents shuffling of rows when splitting data.</p></li>
<li><p><strong>folds_shuffle</strong> (<em>bool</em><em>, </em><em>default = False</em>) – If set to False, prevents shuffling of rows when using cross validation.</p></li>
<li><p><strong>n_jobs</strong> (<em>int</em><em>, </em><em>default = -1</em>) – The number of jobs to run in parallel (for functions that supports parallel
processing) -1 means using all processors. To run all functions on single processor
set n_jobs to None.</p></li>
<li><p><strong>html</strong> (<em>bool</em><em>, </em><em>default = True</em>) – If set to False, prevents runtime display of monitor. This must be set to False
when using environment that doesnt support HTML.</p></li>
<li><p><strong>session_id</strong> (<em>int</em><em>, </em><em>default = None</em>) – If None, a random seed is generated and returned in the Information grid. The
unique number is then distributed as a seed in all functions used during the
experiment. This can be used for later reproducibility of the entire experiment.</p></li>
<li><p><strong>log_experiment</strong> (<em>bool</em><em>, </em><em>default = False</em>) – When set to True, all metrics and parameters are logged on MLFlow server.</p></li>
<li><p><strong>experiment_name</strong> (<em>str</em><em>, </em><em>default = None</em>) – Name of experiment for logging. When set to None, ‘clf’ is by default used as
alias for the experiment name.</p></li>
<li><p><strong>log_plots</strong> (<em>bool</em><em>, </em><em>default = False</em>) – When set to True, specific plots are logged in MLflow as a png file. By default,
it is set to False.</p></li>
<li><p><strong>log_profile</strong> (<em>bool</em><em>, </em><em>default = False</em>) – When set to True, data profile is also logged on MLflow as a html file. By default,
it is set to False.</p></li>
<li><p><strong>log_data</strong> (<em>bool</em><em>, </em><em>default = False</em>) – When set to True, train and test dataset are logged as csv.</p></li>
<li><p><strong>silent</strong> (<em>bool</em><em>, </em><em>default = False</em>) – When set to True, confirmation of data types is not required. All preprocessing will
be performed assuming automatically inferred data types. Not recommended for direct use
except for established pipelines.</p></li>
<li><p><strong>verbose</strong> (<em>Boolean</em><em>, </em><em>default = True</em>) – Information grid is not printed when verbose is set to False.</p></li>
<li><p><strong>profile</strong> (<em>bool</em><em>, </em><em>default = False</em>) – If set to true, a data profile for Exploratory Data Analysis will be displayed
in an interactive HTML report.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><em>info_grid</em> – Information grid is printed.</p></li>
<li><p><em>environment</em> – This function returns various outputs that are stored in variables
as tuples. They are used by other functions in pycaret.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pycaret.classification.stack_models">
<code class="sig-prename descclassname">pycaret.classification.</code><code class="sig-name descname">stack_models</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">estimator_list</span></em>, <em class="sig-param"><span class="n">meta_model</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">fold</span><span class="o">=</span><span class="default_value">10</span></em>, <em class="sig-param"><span class="n">round</span><span class="o">=</span><span class="default_value">4</span></em>, <em class="sig-param"><span class="n">method</span><span class="o">=</span><span class="default_value">'auto'</span></em>, <em class="sig-param"><span class="n">restack</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">choose_better</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">optimize</span><span class="o">=</span><span class="default_value">'Accuracy'</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.classification.stack_models" title="Permalink to this definition">¶</a></dt>
<dd><p>This function trains a meta model and scores it using Stratified Cross Validation.
The predictions from the base level models as passed in the estimator_list param
are used as input features for the meta model. The restacking parameter controls
the ability to expose raw features to the meta model when set to True
(default = False).</p>
<p>The output prints the score grid that shows Accuracy, AUC, Recall, Precision,
F1, Kappa and MCC by fold (default = 10 Folds).</p>
<p>This function returns a trained model object.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pycaret.datasets</span> <span class="kn">import</span> <span class="n">get_data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">juice</span> <span class="o">=</span> <span class="n">get_data</span><span class="p">(</span><span class="s1">&#39;juice&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">experiment_name</span> <span class="o">=</span> <span class="n">setup</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">juice</span><span class="p">,</span>  <span class="n">target</span> <span class="o">=</span> <span class="s1">&#39;Purchase&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dt</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">(</span><span class="s1">&#39;dt&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rf</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">(</span><span class="s1">&#39;rf&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ada</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">(</span><span class="s1">&#39;ada&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ridge</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">(</span><span class="s1">&#39;ridge&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">knn</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">(</span><span class="s1">&#39;knn&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">stacked_models</span> <span class="o">=</span> <span class="n">stack_models</span><span class="p">(</span><span class="n">estimator_list</span><span class="o">=</span><span class="p">[</span><span class="n">dt</span><span class="p">,</span><span class="n">rf</span><span class="p">,</span><span class="n">ada</span><span class="p">,</span><span class="n">ridge</span><span class="p">,</span><span class="n">knn</span><span class="p">])</span>
</pre></div>
</div>
<p>This will create a meta model that will use the predictions of all the
models provided in estimator_list param. By default, the meta model is
Logistic Regression but can be changed with meta_model param.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>estimator_list</strong> (<em>list of objects</em>) – </p></li>
<li><p><strong>meta_model</strong> (<em>object</em><em>, </em><em>default = None</em>) – If set to None, Logistic Regression is used as a meta model.</p></li>
<li><p><strong>fold</strong> (<em>integer</em><em>, </em><em>default = 10</em>) – Number of folds to be used in Kfold CV. Must be at least 2.</p></li>
<li><p><strong>round</strong> (<em>integer</em><em>, </em><em>default = 4</em>) – Number of decimal places the metrics in the score grid will be rounded to.</p></li>
<li><p><strong>method</strong> (<em>string</em><em>, </em><em>default = 'auto'</em>) – <ul>
<li><p>if ‘auto’, it will try to invoke, for each estimator, ‘predict_proba’, ‘decision_function’ or ‘predict’ in that order.</p></li>
<li><p>otherwise, one of ‘predict_proba’, ‘decision_function’ or ‘predict’. If the method is not implemented by the estimator, it will raise an error.</p></li>
</ul>
</p></li>
<li><p><strong>restack</strong> (<em>Boolean</em><em>, </em><em>default = True</em>) – When restack is set to True, raw data will be exposed to meta model when
making predictions, otherwise when False, only the predicted label or
probabilities is passed to meta model when making final predictions.</p></li>
<li><p><strong>choose_better</strong> (<em>Boolean</em><em>, </em><em>default = False</em>) – When set to set to True, base estimator is returned when the metric doesn’t
improve by ensemble_model. This gurantees the returned object would perform
atleast equivalent to base estimator created using create_model or model
returned by compare_models.</p></li>
<li><p><strong>optimize</strong> (<em>string</em><em>, </em><em>default = 'Accuracy'</em>) – Only used when choose_better is set to True. optimize parameter is used
to compare emsembled model with base estimator. Values accepted in
optimize parameter are ‘Accuracy’, ‘AUC’, ‘Recall’, ‘Precision’, ‘F1’,
‘Kappa’, ‘MCC’.</p></li>
<li><p><strong>verbose</strong> (<em>Boolean</em><em>, </em><em>default = True</em>) – Score grid is not printed when verbose is set to False.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><em>score_grid</em> – A table containing the scores of the model across the kfolds.
Scoring metrics used are Accuracy, AUC, Recall, Precision, F1,
Kappa and MCC. Mean and standard deviation of the scores across
the folds are also returned.</p></li>
<li><p><em>model</em> – Trained model object.</p></li>
</ul>
</p>
</dd>
</dl>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<ul class="simple">
<li><p>If target variable is multiclass (more than 2 classes), AUC will be returned as zero (0.0).</p></li>
</ul>
</div>
</dd></dl>

<dl class="py function">
<dt id="pycaret.classification.tune_model">
<code class="sig-prename descclassname">pycaret.classification.</code><code class="sig-name descname">tune_model</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">estimator</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">fold</span><span class="o">=</span><span class="default_value">10</span></em>, <em class="sig-param"><span class="n">round</span><span class="o">=</span><span class="default_value">4</span></em>, <em class="sig-param"><span class="n">n_iter</span><span class="o">=</span><span class="default_value">10</span></em>, <em class="sig-param"><span class="n">custom_grid</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">optimize</span><span class="o">=</span><span class="default_value">'Accuracy'</span></em>, <em class="sig-param"><span class="n">choose_better</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.classification.tune_model" title="Permalink to this definition">¶</a></dt>
<dd><p>This function tunes the hyperparameters of a model and scores it using Stratified
Cross Validation. The output prints a score grid that shows Accuracy, AUC, Recall
Precision, F1, Kappa and MCC by fold (by default = 10 Folds).</p>
<p>This function returns a trained model object.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pycaret.datasets</span> <span class="kn">import</span> <span class="n">get_data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">juice</span> <span class="o">=</span> <span class="n">get_data</span><span class="p">(</span><span class="s1">&#39;juice&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">experiment_name</span> <span class="o">=</span> <span class="n">setup</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">juice</span><span class="p">,</span>  <span class="n">target</span> <span class="o">=</span> <span class="s1">&#39;Purchase&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">xgboost</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">(</span><span class="s1">&#39;xgboost&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tuned_xgboost</span> <span class="o">=</span> <span class="n">tune_model</span><span class="p">(</span><span class="n">xgboost</span><span class="p">)</span>
</pre></div>
</div>
<p>This will tune the hyperparameters of Extreme Gradient Boosting Classifier.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>estimator</strong> (<em>object</em><em>, </em><em>default = None</em>) – </p></li>
<li><p><strong>fold</strong> (<em>integer</em><em>, </em><em>default = 10</em>) – Number of folds to be used in Kfold CV. Must be at least 2.</p></li>
<li><p><strong>round</strong> (<em>integer</em><em>, </em><em>default = 4</em>) – Number of decimal places the metrics in the score grid will be rounded to.</p></li>
<li><p><strong>n_iter</strong> (<em>integer</em><em>, </em><em>default = 10</em>) – Number of iterations within the Random Grid Search. For every iteration,
the model randomly selects one value from the pre-defined grid of hyperparameters.</p></li>
<li><p><strong>custom_grid</strong> (<em>dictionary</em><em>, </em><em>default = None</em>) – To use custom hyperparameters for tuning pass a dictionary with parameter name
and values to be iterated. When set to None it uses pre-defined tuning grid.</p></li>
<li><p><strong>optimize</strong> (<em>string</em><em>, </em><em>default = 'accuracy'</em>) – Measure used to select the best model through hyperparameter tuning.
The default scoring measure is ‘Accuracy’. Other measures include ‘AUC’,
‘Recall’, ‘Precision’, ‘F1’.</p></li>
<li><p><strong>choose_better</strong> (<em>Boolean</em><em>, </em><em>default = False</em>) – When set to set to True, base estimator is returned when the performance doesn’t
improve by tune_model. This gurantees the returned object would perform atleast
equivalent to base estimator created using create_model or model returned by
compare_models.</p></li>
<li><p><strong>verbose</strong> (<em>Boolean</em><em>, </em><em>default = True</em>) – Score grid is not printed when verbose is set to False.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><em>score_grid</em> – A table containing the scores of the model across the kfolds.
Scoring metrics used are Accuracy, AUC, Recall, Precision, F1,
Kappa and MCC. Mean and standard deviation of the scores across
the folds are also returned.</p></li>
<li><p><em>model</em> – Trained and tuned model object.</p></li>
</ul>
</p>
</dd>
</dl>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<ul class="simple">
<li><p>If target variable is multiclass (more than 2 classes), optimize param ‘AUC’ is
not acceptable.</p></li>
<li><p>If target variable is multiclass (more than 2 classes), AUC will be returned as
zero (0.0)</p></li>
</ul>
</div>
</dd></dl>

</div>
<div class="section" id="module-pycaret.nlp">
<span id="nlp"></span><h1>NLP<a class="headerlink" href="#module-pycaret.nlp" title="Permalink to this headline">¶</a></h1>
<dl class="py function">
<dt id="pycaret.nlp.assign_model">
<code class="sig-prename descclassname">pycaret.nlp.</code><code class="sig-name descname">assign_model</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">model</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.nlp.assign_model" title="Permalink to this definition">¶</a></dt>
<dd><p>This function assigns each of the data point in the dataset passed during setup
stage to one of the topic using trained model object passed as model param.
create_model() function must be called before using assign_model().</p>
<p>This function returns dataframe with topic weights, dominant topic and % of the
dominant topic (where applicable).</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pycaret.datasets</span> <span class="kn">import</span> <span class="n">get_data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">kiva</span> <span class="o">=</span> <span class="n">get_data</span><span class="p">(</span><span class="s1">&#39;kiva&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">experiment_name</span> <span class="o">=</span> <span class="n">setup</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">kiva</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="s1">&#39;en&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lda</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">(</span><span class="s1">&#39;lda&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lda_df</span> <span class="o">=</span> <span class="n">assign_model</span><span class="p">(</span><span class="n">lda</span><span class="p">)</span>
</pre></div>
</div>
<p>This will return a dataframe with inferred topics using trained model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>trained model object</em><em>, </em><em>default = None</em>) – </p></li>
<li><p><strong>verbose</strong> (<em>Boolean</em><em>, </em><em>default = True</em>) – Status update is not printed when verbose is set to False.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Returns dataframe with inferred topics using trained model object.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>pandas.DataFrame</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pycaret.nlp.create_model">
<code class="sig-prename descclassname">pycaret.nlp.</code><code class="sig-name descname">create_model</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">model</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">multi_core</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">num_topics</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">system</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.nlp.create_model" title="Permalink to this definition">¶</a></dt>
<dd><p>This function creates a model on the dataset passed as a data param during
the setup stage. setup() function must be called before using create_model().</p>
<p>This function returns a trained model object.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pycaret.datasets</span> <span class="kn">import</span> <span class="n">get_data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">kiva</span> <span class="o">=</span> <span class="n">get_data</span><span class="p">(</span><span class="s1">&#39;kiva&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">experiment_name</span> <span class="o">=</span> <span class="n">setup</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">kiva</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="s1">&#39;en&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lda</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">(</span><span class="s1">&#39;lda&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>This will return trained Latent Dirichlet Allocation model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>string</em><em>, </em><em>default = None</em>) – <p>Enter ID of the model available in model library.</p>
<p>ID          Model
——      ———
‘lda’       Latent Dirichlet Allocation
‘lsi’       Latent Semantic Indexing
‘hdp’       Hierarchical Dirichlet Process
‘rp’        Random Projections
‘nmf’       Non-Negative Matrix Factorization</p>
</p></li>
<li><p><strong>multi_core</strong> (<em>Boolean</em><em>, </em><em>default = False</em>) – True would utilize all CPU cores to parallelize and speed up model training. Only
available for ‘lda’. For all other models, the multi_core parameter is ignored.</p></li>
<li><p><strong>num_topics</strong> (<em>integer</em><em>, </em><em>default = 4</em>) – Number of topics to be created. If None, default is set to 4.</p></li>
<li><p><strong>verbose</strong> (<em>Boolean</em><em>, </em><em>default = True</em>) – Status update is not printed when verbose is set to False.</p></li>
<li><p><strong>system</strong> (<em>Boolean</em><em>, </em><em>default = True</em>) – Must remain True all times. Only to be changed by internal functions.</p></li>
<li><p><strong>**kwargs</strong> – Additional keyword arguments to pass to the estimator.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Trained model object.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>model</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pycaret.nlp.evaluate_model">
<code class="sig-prename descclassname">pycaret.nlp.</code><code class="sig-name descname">evaluate_model</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">model</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.nlp.evaluate_model" title="Permalink to this definition">¶</a></dt>
<dd><p>This function displays the user interface for all the available plots
for a given model. It internally uses the plot_model() function.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pycaret.datasets</span> <span class="kn">import</span> <span class="n">get_data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">kiva</span> <span class="o">=</span> <span class="n">get_data</span><span class="p">(</span><span class="s1">&#39;kiva&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">experiment_name</span> <span class="o">=</span> <span class="n">setup</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">kiva</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="s1">&#39;en&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lda</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">(</span><span class="s1">&#39;lda&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">evaluate_model</span><span class="p">(</span><span class="n">lda</span><span class="p">)</span>
</pre></div>
</div>
<p>This will display the User Interface for all of the plots for
given model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>model</strong> (<em>object</em><em>, </em><em>default = none</em>) – A trained model object should be passed.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Displays the user interface for plotting.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>User_Interface</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pycaret.nlp.get_config">
<code class="sig-prename descclassname">pycaret.nlp.</code><code class="sig-name descname">get_config</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">variable</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.nlp.get_config" title="Permalink to this definition">¶</a></dt>
<dd><p>This function is used to access global environment variables.
Following variables can be accessed:</p>
<ul class="simple">
<li><p>text: Tokenized words as a list with length = # documents</p></li>
<li><p><a href="#id1"><span class="problematic" id="id2">data_</span></a>: Dataframe containing text after all processing</p></li>
<li><p>corpus: List containing tuples of id to word mapping</p></li>
<li><p>id2word: gensim.corpora.dictionary.Dictionary</p></li>
<li><p>seed: random state set through session_id</p></li>
<li><p><a href="#id3"><span class="problematic" id="id4">target_</span></a>: Name of column containing text. ‘en’ by default.</p></li>
<li><p>html_param: html_param configured through setup</p></li>
<li><p>exp_name_log: Name of experiment set through setup</p></li>
<li><p>logging_param: log_experiment param set through setup</p></li>
<li><p>log_plots_param: log_plots param set through setup</p></li>
<li><p>USI: Unique session ID parameter set through setup</p></li>
</ul>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">text</span> <span class="o">=</span> <span class="n">get_config</span><span class="p">(</span><span class="s1">&#39;text&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>This will return transformed dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>variable</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pycaret.nlp.get_logs">
<code class="sig-prename descclassname">pycaret.nlp.</code><code class="sig-name descname">get_logs</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">experiment_name</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">save</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.nlp.get_logs" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a table with experiment logs consisting
run details, parameter, metrics and tags.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">logs</span> <span class="o">=</span> <span class="n">get_logs</span><span class="p">()</span>
</pre></div>
</div>
<p>This will return pandas dataframe.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>experiment_name</strong> (<em>string</em><em>, </em><em>default = None</em>) – When set to None current active run is used.</p></li>
<li><p><strong>save</strong> (<em>bool</em><em>, </em><em>default = False</em>) – When set to True, csv file is saved in current directory.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>pandas.DataFrame</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pycaret.nlp.get_system_logs">
<code class="sig-prename descclassname">pycaret.nlp.</code><code class="sig-name descname">get_system_logs</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.nlp.get_system_logs" title="Permalink to this definition">¶</a></dt>
<dd><p>Read and print ‘logs.log’ file from current active directory</p>
</dd></dl>

<dl class="py function">
<dt id="pycaret.nlp.get_topics">
<code class="sig-prename descclassname">pycaret.nlp.</code><code class="sig-name descname">get_topics</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">text</span></em>, <em class="sig-param"><span class="n">model</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">num_topics</span><span class="o">=</span><span class="default_value">4</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.nlp.get_topics" title="Permalink to this definition">¶</a></dt>
<dd><p>Callable from any external environment without requiring setup initialization.</p>
</dd></dl>

<dl class="py function">
<dt id="pycaret.nlp.load_model">
<code class="sig-prename descclassname">pycaret.nlp.</code><code class="sig-name descname">load_model</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">model_name</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.nlp.load_model" title="Permalink to this definition">¶</a></dt>
<dd><p>This function loads a previously saved model from the current active directory
into the current python environment. Load object must be a pickle file.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">saved_lda</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="s1">&#39;lda_model_23122019&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>This will call the trained model in saved_lr variable using model_name param.
The file must be in current directory.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_name</strong> (<em>string</em><em>, </em><em>default = none</em>) – Name of pickle file to be passed as a string.</p></li>
<li><p><strong>verbose</strong> (<em>bool</em><em>, </em><em>default = True</em>) – When set to False, success message is not printed.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Success_Message</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pycaret.nlp.models">
<code class="sig-prename descclassname">pycaret.nlp.</code><code class="sig-name descname">models</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.nlp.models" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns table of models available in model library.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">all_models</span> <span class="o">=</span> <span class="n">models</span><span class="p">()</span>
</pre></div>
</div>
<p>This will return pandas dataframe with all available
models and their metadata.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>pandas.DataFrame</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pycaret.nlp.plot_model">
<code class="sig-prename descclassname">pycaret.nlp.</code><code class="sig-name descname">plot_model</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">model</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">plot</span><span class="o">=</span><span class="default_value">'frequency'</span></em>, <em class="sig-param"><span class="n">topic_num</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">save</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">system</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.nlp.plot_model" title="Permalink to this definition">¶</a></dt>
<dd><p>This function takes a trained model object (optional) and returns a plot based
on the inferred dataset by internally calling assign_model before generating a
plot. Where a model parameter is not passed, a plot on the entire dataset will
be returned instead of one at the topic level. As such, plot_model can be used
with or without model. All plots with a model parameter passed as a trained
model object will return a plot based on the first topic i.e.  ‘Topic 0’. This
can be changed using the topic_num param.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pycaret.datasets</span> <span class="kn">import</span> <span class="n">get_data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">kiva</span> <span class="o">=</span> <span class="n">get_data</span><span class="p">(</span><span class="s1">&#39;kiva&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">experiment_name</span> <span class="o">=</span> <span class="n">setup</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">kiva</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="s1">&#39;en&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lda</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">(</span><span class="s1">&#39;lda&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">plot_model</span><span class="p">(</span><span class="n">lda</span><span class="p">,</span> <span class="n">plot</span> <span class="o">=</span> <span class="s1">&#39;frequency&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>This will return a frequency plot on a trained Latent Dirichlet Allocation
model for all documents in ‘Topic 0’. The topic number can be changed as
follows:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">plot_model</span><span class="p">(</span><span class="n">lda</span><span class="p">,</span> <span class="n">plot</span> <span class="o">=</span> <span class="s1">&#39;frequency&#39;</span><span class="p">,</span> <span class="n">topic_num</span> <span class="o">=</span> <span class="s1">&#39;Topic 1&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>This will now return a frequency plot on a trained LDA model for all
documents inferred in ‘Topic 1’.</p>
<p>Alternatively, if following is used:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">plot_model</span><span class="p">(</span><span class="n">plot</span> <span class="o">=</span> <span class="s1">&#39;frequency&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>This will return frequency plot on the entire training corpus compiled
during setup stage.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>object</em><em>, </em><em>default = none</em>) – A trained model object can be passed. Model must be created using create_model().</p></li>
<li><p><strong>plot</strong> (<em>string</em><em>, </em><em>default = 'frequency'</em>) – <p>Enter abbreviation for type of plot. The current list of plots supported are:</p>
<p>Name                           Abbreviated String
———                      ——————
Word Token Frequency           ‘frequency’
Word Distribution Plot         ‘distribution’
Bigram Frequency Plot          ‘bigram’
Trigram Frequency Plot         ‘trigram’
Sentiment Polarity Plot        ‘sentiment’
Part of Speech Frequency       ‘pos’
t-SNE (3d) Dimension Plot      ‘tsne’
Topic Model (pyLDAvis)         ‘topic_model’
Topic Infer Distribution       ‘topic_distribution’
Wordcloud                      ‘wordcloud’
UMAP Dimensionality Plot       ‘umap’</p>
</p></li>
<li><p><strong>topic_num</strong> (<em>string</em><em>, </em><em>default = None</em>) – Topic number to be passed as a string. If set to None, default generation will
be on ‘Topic 0’</p></li>
<li><p><strong>save</strong> (<em>Boolean</em><em>, </em><em>default = False</em>) – Plot is saved as png file in local directory when save parameter set to True.</p></li>
<li><p><strong>system</strong> (<em>Boolean</em><em>, </em><em>default = True</em>) – Must remain True all times. Only to be changed by internal functions.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Prints the visual plot.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Visual_Plot</p>
</dd>
</dl>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<ul class="simple">
<li><p>‘pos’ and ‘umap’ plot not available at model level. Hence the model parameter is
ignored. The result will always be based on the entire training corpus.</p></li>
<li><p>‘topic_model’ plot is based on pyLDAVis implementation. Hence its not available
for model = ‘lsi’, ‘rp’ and ‘nmf’.</p></li>
</ul>
</div>
</dd></dl>

<dl class="py function">
<dt id="pycaret.nlp.save_model">
<code class="sig-prename descclassname">pycaret.nlp.</code><code class="sig-name descname">save_model</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">model</span></em>, <em class="sig-param"><span class="n">model_name</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.nlp.save_model" title="Permalink to this definition">¶</a></dt>
<dd><p>This function saves the trained model object into the current active
directory as a pickle file for later use.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pycaret.datasets</span> <span class="kn">import</span> <span class="n">get_data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">kiva</span> <span class="o">=</span> <span class="n">get_data</span><span class="p">(</span><span class="s1">&#39;kiva&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">experiment_name</span> <span class="o">=</span> <span class="n">setup</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">kiva</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="s1">&#39;en&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lda</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">(</span><span class="s1">&#39;lda&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">save_model</span><span class="p">(</span><span class="n">lda</span><span class="p">,</span> <span class="s1">&#39;lda_model_23122019&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>This will save the model as a binary pickle file in the current
directory.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>object</em><em>, </em><em>default = none</em>) – A trained model object should be passed.</p></li>
<li><p><strong>model_name</strong> (<em>string</em><em>, </em><em>default = none</em>) – Name of pickle file to be passed as a string.</p></li>
<li><p><strong>verbose</strong> (<em>bool</em><em>, </em><em>default = True</em>) – When set to False, success message is not printed.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Success_Message</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pycaret.nlp.set_config">
<code class="sig-prename descclassname">pycaret.nlp.</code><code class="sig-name descname">set_config</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">variable</span></em>, <em class="sig-param"><span class="n">value</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.nlp.set_config" title="Permalink to this definition">¶</a></dt>
<dd><p>This function is used to reset global environment variables.
Following variables can be accessed:</p>
<ul class="simple">
<li><p>text: Tokenized words as a list with length = # documents</p></li>
<li><p><a href="#id5"><span class="problematic" id="id6">data_</span></a>: Dataframe containing text after all processing</p></li>
<li><p>corpus: List containing tuples of id to word mapping</p></li>
<li><p>id2word: gensim.corpora.dictionary.Dictionary</p></li>
<li><p>seed: random state set through session_id</p></li>
<li><p><a href="#id7"><span class="problematic" id="id8">target_</span></a>: Name of column containing text. ‘en’ by default.</p></li>
<li><p>html_param: html_param configured through setup</p></li>
<li><p>exp_name_log: Name of experiment set through setup</p></li>
<li><p>logging_param: log_experiment param set through setup</p></li>
<li><p>log_plots_param: log_plots param set through setup</p></li>
<li><p>USI: Unique session ID parameter set through setup</p></li>
</ul>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">set_config</span><span class="p">(</span><span class="s1">&#39;seed&#39;</span><span class="p">,</span> <span class="mi">123</span><span class="p">)</span>
</pre></div>
</div>
<p>This will set the global seed to ‘123’.</p>
</dd></dl>

<dl class="py function">
<dt id="pycaret.nlp.setup">
<code class="sig-prename descclassname">pycaret.nlp.</code><code class="sig-name descname">setup</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">target</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">custom_stopwords</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">html</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">session_id</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">log_experiment</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">experiment_name</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">log_plots</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">log_data</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.nlp.setup" title="Permalink to this definition">¶</a></dt>
<dd><p>This function initializes the environment in pycaret. setup() must called before
executing any other function in pycaret. It takes one mandatory parameter:
dataframe {array-like, sparse matrix} or object of type list. If a dataframe is
passed, target column containing text must be specified. When data passed is of
type list, no target parameter is required. All other parameters are optional.
This module only supports English Language at this time.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pycaret.datasets</span> <span class="kn">import</span> <span class="n">get_data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">kiva</span> <span class="o">=</span> <span class="n">get_data</span><span class="p">(</span><span class="s1">&#39;kiva&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">experiment_name</span> <span class="o">=</span> <span class="n">setup</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">kiva</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="s1">&#39;en&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>‘kiva’ is a pandas Dataframe.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<em>{array-like</em><em>, </em><em>sparse matrix}</em>) – Shape (n_samples, n_features) where n_samples is the number of samples and n_features
is the number of features or object of type list with n length.</p></li>
<li><p><strong>target</strong> (<em>string</em>) – If data is of type DataFrame, name of column containing text values must be passed as
string.</p></li>
<li><p><strong>custom_stopwords</strong> (<em>list</em><em>, </em><em>default = None</em>) – List containing custom stopwords.</p></li>
<li><p><strong>html</strong> (<em>bool</em><em>, </em><em>default = True</em>) – If set to False, prevents runtime display of monitor. This must be set to False
when using environment that doesnt support HTML.</p></li>
<li><p><strong>session_id</strong> (<em>int</em><em>, </em><em>default = None</em>) – If None, a random seed is generated and returned in the Information grid. The
unique number is then distributed as a seed in all functions used during the
experiment. This can be used for later reproducibility of the entire experiment.</p></li>
<li><p><strong>log_experiment</strong> (<em>bool</em><em>, </em><em>default = True</em>) – When set to True, all metrics and parameters are logged on MLFlow server.</p></li>
<li><p><strong>experiment_name</strong> (<em>str</em><em>, </em><em>default = None</em>) – Name of experiment for logging. When set to None, ‘nlp’ is by default used as
alias for the experiment name.</p></li>
<li><p><strong>log_plots</strong> (<em>bool</em><em>, </em><em>default = False</em>) – When set to True, specific plots are logged in MLflow as a png file. By default,
it is set to False.</p></li>
<li><p><strong>log_data</strong> (<em>bool</em><em>, </em><em>default = False</em>) – When set to True, train and test dataset are logged as csv.</p></li>
<li><p><strong>verbose</strong> (<em>Boolean</em><em>, </em><em>default = True</em>) – Information grid is not printed when verbose is set to False.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><em>info_grid</em> – Information grid is printed.</p></li>
<li><p><em>environment</em> – This function returns various outputs that are stored in variable
as tuple. They are used by other functions in pycaret.</p></li>
</ul>
</p>
</dd>
</dl>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<ul>
<li><p>Some functionalities in pycaret.nlp requires you to have english language model.
The language model is not downloaded automatically when you install pycaret.
You will have to download two models using your Anaconda Prompt or python
command line interface. To download the model, please type the following in
your command line:</p>
<blockquote>
<div><p>python -m spacy download en_core_web_sm
python -m textblob.download_corpora</p>
</div></blockquote>
<p>Once downloaded, please restart your kernel and re-run the setup.</p>
</li>
</ul>
</div>
</dd></dl>

<dl class="py function">
<dt id="pycaret.nlp.tune_model">
<code class="sig-prename descclassname">pycaret.nlp.</code><code class="sig-name descname">tune_model</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">model</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">multi_core</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">supervised_target</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">estimator</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">optimize</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">custom_grid</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">auto_fe</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">fold</span><span class="o">=</span><span class="default_value">10</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.nlp.tune_model" title="Permalink to this definition">¶</a></dt>
<dd><p>This function tunes the num_topics model parameter using a predefined grid with
the objective of optimizing a supervised learning metric as defined in the optimize
param. You can choose the supervised estimator from a large library available in
pycaret. By default, supervised estimator is Linear.</p>
<p>This function returns the tuned model object.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pycaret.datasets</span> <span class="kn">import</span> <span class="n">get_data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">kiva</span> <span class="o">=</span> <span class="n">get_data</span><span class="p">(</span><span class="s1">&#39;kiva&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">experiment_name</span> <span class="o">=</span> <span class="n">setup</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">kiva</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="s1">&#39;en&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tuned_lda</span> <span class="o">=</span> <span class="n">tune_model</span><span class="p">(</span><span class="n">model</span> <span class="o">=</span> <span class="s1">&#39;lda&#39;</span><span class="p">,</span> <span class="n">supervised_target</span> <span class="o">=</span> <span class="s1">&#39;status&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>This will return trained Latent Dirichlet Allocation model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>string</em><em>, </em><em>default = None</em>) – <p>Enter ID of the models available in model library:</p>
<p>ID          Model
——      ———
‘lda’       Latent Dirichlet Allocation
‘lsi’       Latent Semantic Indexing
‘hdp’       Hierarchical Dirichlet Process
‘rp’        Random Projections
‘nmf’       Non-Negative Matrix Factorization</p>
</p></li>
<li><p><strong>multi_core</strong> (<em>Boolean</em><em>, </em><em>default = False</em>) – True would utilize all CPU cores to parallelize and speed up model training. Only
available for ‘lda’. For all other models, multi_core parameter is ignored.</p></li>
<li><p><strong>supervised_target</strong> (<em>string</em>) – Name of the target column for supervised learning. If None, the mdel coherence value
is used as the objective function.</p></li>
<li><p><strong>estimator</strong> (<em>string</em><em>, </em><em>default = None</em>) – <p>ID          Name                            Task
——–    ———-                      ———-
‘lr’        Logistic Regression             Classification
‘knn’       K Nearest Neighbour             Classification
‘nb’        Naive Bayes                     Classification
‘dt’        Decision Tree Classifier        Classification
‘svm’       SVM - Linear Kernel             Classification
‘rbfsvm’    SVM - Radial Kernel             Classification
‘gpc’       Gaussian Process Classifier     Classification
‘mlp’       Multi Level Perceptron          Classification
‘ridge’     Ridge Classifier                Classification
‘rf’        Random Forest Classifier        Classification
‘qda’       Quadratic Discriminant Analysis Classification
‘ada’       Ada Boost Classifier            Classification
‘gbc’       Gradient Boosting Classifier    Classification
‘lda’       Linear Discriminant Analysis    Classification
‘et’        Extra Trees Classifier          Classification
‘xgboost’   Extreme Gradient Boosting       Classification
‘lightgbm’  Light Gradient Boosting         Classification
‘catboost’  CatBoost Classifier             Classification
‘lr’        Linear Regression               Regression
‘lasso’     Lasso Regression                Regression
‘ridge’     Ridge Regression                Regression
‘en’        Elastic Net                     Regression
‘lar’       Least Angle Regression          Regression
‘llar’      Lasso Least Angle Regression    Regression
‘omp’       Orthogonal Matching Pursuit     Regression
‘br’        Bayesian Ridge                  Regression
‘ard’       Automatic Relevance Determ.     Regression
‘par’       Passive Aggressive Regressor    Regression
‘ransac’    Random Sample Consensus         Regression
‘tr’        TheilSen Regressor              Regression
‘huber’     Huber Regressor                 Regression
‘kr’        Kernel Ridge                    Regression
‘svm’       Support Vector Machine          Regression
‘knn’       K Neighbors Regressor           Regression
‘dt’        Decision Tree                   Regression
‘rf’        Random Forest                   Regression
‘et’        Extra Trees Regressor           Regression
‘ada’       AdaBoost Regressor              Regression
‘gbr’       Gradient Boosting               Regression
‘mlp’       Multi Level Perceptron          Regression
‘xgboost’   Extreme Gradient Boosting       Regression
‘lightgbm’  Light Gradient Boosting         Regression
‘catboost’  CatBoost Regressor              Regression</p>
<p>If set to None, Linear / Logistic model is used by default.</p>
</p></li>
<li><p><strong>optimize</strong> (<em>string</em><em>, </em><em>default = None</em>) – <dl class="simple">
<dt>For Classification tasks:</dt><dd><p>Accuracy, AUC, Recall, Precision, F1, Kappa</p>
</dd>
<dt>For Regression tasks:</dt><dd><p>MAE, MSE, RMSE, R2, RMSLE, MAPE</p>
</dd>
</dl>
<p>If set to None, default is ‘Accuracy’ for classification and ‘R2’ for
regression tasks.</p>
</p></li>
<li><p><strong>custom_grid</strong> (<em>list</em><em>, </em><em>default = None</em>) – By default, a pre-defined number of topics is iterated over to
optimize the supervised objective. To overwrite default iteration,
pass a list of num_topics to iterate over in custom_grid param.</p></li>
<li><p><strong>auto_fe</strong> (<em>boolean</em><em>, </em><em>default = True</em>) – Automatic text feature engineering. Only used when supervised_target is
passed. When set to true, it will generate text based features such as
polarity, subjectivity, wordcounts to be used in supervised learning.
Ignored when supervised_target is set to None.</p></li>
<li><p><strong>fold</strong> (<em>integer</em><em>, </em><em>default = 10</em>) – Number of folds to be used in Kfold CV. Must be at least 2.</p></li>
<li><p><strong>verbose</strong> (<em>Boolean</em><em>, </em><em>default = True</em>) – Status update is not printed when verbose is set to False.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><em>Visual_Plot</em> – Visual plot with k number of topics on x-axis with metric to
optimize on y-axis. Coherence is used when learning is
unsupervised. Also, prints the best model metric.</p></li>
<li><p><em>model</em> – trained model object with best K number of topics.</p></li>
</ul>
</p>
</dd>
</dl>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<ul class="simple">
<li><p>Random Projections (‘rp’) and Non Negative Matrix Factorization (‘nmf’)
is not available for unsupervised learning. Error is raised when ‘rp’ or
‘nmf’ is passed without supervised_target.</p></li>
<li><p>Estimators using kernel based methods such as Kernel Ridge Regressor,
Automatic Relevance Determinant, Gaussian Process Classifier, Radial Basis
Support Vector Machine and Multi Level Perceptron may have longer training
times.</p></li>
</ul>
</div>
</dd></dl>

</div>
<div class="section" id="module-pycaret.clustering">
<span id="clustering"></span><h1>Clustering<a class="headerlink" href="#module-pycaret.clustering" title="Permalink to this headline">¶</a></h1>
<dl class="py function">
<dt id="pycaret.clustering.assign_model">
<code class="sig-prename descclassname">pycaret.clustering.</code><code class="sig-name descname">assign_model</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">model</span></em>, <em class="sig-param"><span class="n">transformation</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.clustering.assign_model" title="Permalink to this definition">¶</a></dt>
<dd><p>This function assigns each of the data point in the dataset passed during setup
stage to one of the clusters using trained model object passed as model param.
create_model() function must be called before using assign_model().</p>
<p>This function returns a pandas Dataframe.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pycaret.datasets</span> <span class="kn">import</span> <span class="n">get_data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">jewellery</span> <span class="o">=</span> <span class="n">get_data</span><span class="p">(</span><span class="s1">&#39;jewellery&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">experiment_name</span> <span class="o">=</span> <span class="n">setup</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">jewellery</span><span class="p">,</span> <span class="n">normalize</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">kmeans</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">(</span><span class="s1">&#39;kmeans&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">kmeans_df</span> <span class="o">=</span> <span class="n">assign_model</span><span class="p">(</span><span class="n">kmeans</span><span class="p">)</span>
</pre></div>
</div>
<p>This will return a dataframe with inferred clusters using trained model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>trained model object</em><em>, </em><em>default = None</em>) – </p></li>
<li><p><strong>transformation</strong> (<em>bool</em><em>, </em><em>default = False</em>) – When set to True, assigned clusters are returned on transformed dataset instead
of original dataset passed during setup().</p></li>
<li><p><strong>verbose</strong> (<em>Boolean</em><em>, </em><em>default = True</em>) – Status update is not printed when verbose is set to False.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Returns a dataframe with assigned clusters using a trained model.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>pandas.DataFrame</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pycaret.clustering.create_model">
<code class="sig-prename descclassname">pycaret.clustering.</code><code class="sig-name descname">create_model</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">model</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">num_clusters</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">ground_truth</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">system</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.clustering.create_model" title="Permalink to this definition">¶</a></dt>
<dd><p>This function creates a model on the dataset passed as a data param during
the setup stage. setup() function must be called before using create_model().</p>
<p>This function returns a trained model object.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pycaret.datasets</span> <span class="kn">import</span> <span class="n">get_data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">jewellery</span> <span class="o">=</span> <span class="n">get_data</span><span class="p">(</span><span class="s1">&#39;jewellery&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">experiment_name</span> <span class="o">=</span> <span class="n">setup</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">jewellery</span><span class="p">,</span> <span class="n">normalize</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">kmeans</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">(</span><span class="s1">&#39;kmeans&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>This will return a trained K-Means clustering model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>string / object</em><em>, </em><em>default = None</em>) – <p>Enter ID of the models available in model library or pass an untrained model
object consistent with fit / predict API to train and evaluate model. List of
models available in model library:</p>
<p>ID              Model
——          ———–
‘kmeans’        K-Means Clustering
‘ap’            Affinity Propagation
‘meanshift’     Mean shift Clustering
‘sc’            Spectral Clustering
‘hclust’        Agglomerative Clustering
‘dbscan’        Density-Based Spatial Clustering
‘optics’        OPTICS Clustering
‘birch’         Birch Clustering
‘kmodes’        K-Modes Clustering</p>
</p></li>
<li><p><strong>num_clusters</strong> (<em>int</em><em>, </em><em>default = None</em>) – Number of clusters to be generated with the dataset. If None, num_clusters
is set to 4.</p></li>
<li><p><strong>ground_truth</strong> (<em>string</em><em>, </em><em>default = None</em>) – When ground_truth is provided, Homogeneity Score, Rand Index, and
Completeness Score is evaluated and printer along with other metrics.</p></li>
<li><p><strong>verbose</strong> (<em>Boolean</em><em>, </em><em>default = True</em>) – Status update is not printed when verbose is set to False.</p></li>
<li><p><strong>system</strong> (<em>Boolean</em><em>, </em><em>default = True</em>) – Must remain True all times. Only to be changed by internal functions.</p></li>
<li><p><strong>**kwargs</strong> – Additional keyword arguments to pass to the estimator.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><em>score_grid</em> – A table containing the Silhouette, Calinski-Harabasz,
Davies-Bouldin, Homogeneity Score, Rand Index, and
Completeness Score. Last 3 are only evaluated when
ground_truth param is provided.</p></li>
<li><p><em>model</em> – trained model object</p></li>
</ul>
</p>
</dd>
</dl>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<ul class="simple">
<li><p>num_clusters not required for Affinity Propagation (‘ap’), Mean shift
clustering (‘meanshift’), Density-Based Spatial Clustering (‘dbscan’)
and OPTICS Clustering (‘optics’). num_clusters param for these models
are automatically determined.</p></li>
<li><p>When fit doesn’t converge in Affinity Propagation (‘ap’) model, all
datapoints are labelled as -1.</p></li>
<li><p>Noisy samples are given the label -1, when using Density-Based Spatial
(‘dbscan’) or OPTICS Clustering (‘optics’).</p></li>
<li><p>OPTICS (‘optics’) clustering may take longer training times on large
datasets.</p></li>
</ul>
</div>
</dd></dl>

<dl class="py function">
<dt id="pycaret.clustering.deploy_model">
<code class="sig-prename descclassname">pycaret.clustering.</code><code class="sig-name descname">deploy_model</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">model</span></em>, <em class="sig-param"><span class="n">model_name</span></em>, <em class="sig-param"><span class="n">authentication</span></em>, <em class="sig-param"><span class="n">platform</span><span class="o">=</span><span class="default_value">'aws'</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.clustering.deploy_model" title="Permalink to this definition">¶</a></dt>
<dd><p>(In Preview)</p>
<p>This function deploys the transformation pipeline and trained model object for
production use. The platform of deployment can be defined under the platform
param along with the applicable authentication tokens which are passed as a
dictionary to the authentication param.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pycaret.datasets</span> <span class="kn">import</span> <span class="n">get_data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">jewellery</span> <span class="o">=</span> <span class="n">get_data</span><span class="p">(</span><span class="s1">&#39;jewellery&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">experiment_name</span> <span class="o">=</span> <span class="n">setup</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">jewellery</span><span class="p">,</span>  <span class="n">normalize</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">kmeans</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">(</span><span class="s1">&#39;kmeans&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">deploy_model</span><span class="p">(</span><span class="n">model</span> <span class="o">=</span> <span class="n">kmeans</span><span class="p">,</span> <span class="n">model_name</span> <span class="o">=</span> <span class="s1">&#39;deploy_kmeans&#39;</span><span class="p">,</span> <span class="n">platform</span> <span class="o">=</span> <span class="s1">&#39;aws&#39;</span><span class="p">,</span> <span class="n">authentication</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;bucket&#39;</span> <span class="p">:</span> <span class="s1">&#39;pycaret-test&#39;</span><span class="p">})</span>
</pre></div>
</div>
<p>This will deploy the model on an AWS S3 account under bucket ‘pycaret-test’</p>
<p class="rubric">Notes</p>
<p>For AWS users:
Before deploying a model to an AWS S3 (‘aws’), environment variables must be
configured using the command line interface. To configure AWS env. variables,
type aws configure in your python command line. The following information is
required which can be generated using the Identity and Access Management (IAM)
portal of your amazon console account:</p>
<ul class="simple">
<li><p>AWS Access Key ID</p></li>
<li><p>AWS Secret Key Access</p></li>
<li><p>Default Region Name (can be seen under Global settings on your AWS console)</p></li>
<li><p>Default output format (must be left blank)</p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>object</em>) – A trained model object should be passed as an estimator.</p></li>
<li><p><strong>model_name</strong> (<em>string</em>) – Name of model to be passed as a string.</p></li>
<li><p><strong>authentication</strong> (<em>dict</em>) – <p>Dictionary of applicable authentication tokens.</p>
<p>When platform = ‘aws’:
{‘bucket’ : ‘Name of Bucket on S3’}</p>
</p></li>
<li><p><strong>platform</strong> (<em>string</em><em>, </em><em>default = 'aws'</em>) – Name of platform for deployment. Current available options are: ‘aws’.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Success_Message</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pycaret.clustering.get_clusters">
<code class="sig-prename descclassname">pycaret.clustering.</code><code class="sig-name descname">get_clusters</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">model</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">num_clusters</span><span class="o">=</span><span class="default_value">4</span></em>, <em class="sig-param"><span class="n">ignore_features</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">normalize</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">transformation</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">pca</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">pca_components</span><span class="o">=</span><span class="default_value">0.99</span></em>, <em class="sig-param"><span class="n">ignore_low_variance</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">combine_rare_levels</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">rare_level_threshold</span><span class="o">=</span><span class="default_value">0.1</span></em>, <em class="sig-param"><span class="n">remove_multicollinearity</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">multicollinearity_threshold</span><span class="o">=</span><span class="default_value">0.9</span></em>, <em class="sig-param"><span class="n">n_jobs</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.clustering.get_clusters" title="Permalink to this definition">¶</a></dt>
<dd><p>Callable from any external environment without requiring setup initialization.</p>
</dd></dl>

<dl class="py function">
<dt id="pycaret.clustering.get_config">
<code class="sig-prename descclassname">pycaret.clustering.</code><code class="sig-name descname">get_config</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">variable</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.clustering.get_config" title="Permalink to this definition">¶</a></dt>
<dd><p>This function is used to access global environment variables.
Following variables can be accessed:</p>
<ul class="simple">
<li><p>X: Transformed dataset</p></li>
<li><p><a href="#id9"><span class="problematic" id="id10">data_</span></a>: Original dataset</p></li>
<li><p>seed: random state set through session_id</p></li>
<li><p>prep_pipe: Transformation pipeline configured through setup</p></li>
<li><p>prep_param: prep_param configured through setup</p></li>
<li><p>n_jobs_param: n_jobs parameter used in model training</p></li>
<li><p>html_param: html_param configured through setup</p></li>
<li><p>exp_name_log: Name of experiment set through setup</p></li>
<li><p>logging_param: log_experiment param set through setup</p></li>
<li><p>log_plots_param: log_plots param set through setup</p></li>
<li><p>USI: Unique session ID parameter set through setup</p></li>
</ul>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">get_config</span><span class="p">(</span><span class="s1">&#39;X&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>This will return transformed dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>variable</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pycaret.clustering.get_logs">
<code class="sig-prename descclassname">pycaret.clustering.</code><code class="sig-name descname">get_logs</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">experiment_name</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">save</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.clustering.get_logs" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a table with experiment logs consisting
run details, parameter, metrics and tags.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">logs</span> <span class="o">=</span> <span class="n">get_logs</span><span class="p">()</span>
</pre></div>
</div>
<p>This will return pandas dataframe.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>experiment_name</strong> (<em>string</em><em>, </em><em>default = None</em>) – When set to None current active run is used.</p></li>
<li><p><strong>save</strong> (<em>bool</em><em>, </em><em>default = False</em>) – When set to True, csv file is saved in current directory.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>pandas.DataFrame</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pycaret.clustering.get_system_logs">
<code class="sig-prename descclassname">pycaret.clustering.</code><code class="sig-name descname">get_system_logs</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.clustering.get_system_logs" title="Permalink to this definition">¶</a></dt>
<dd><p>Read and print ‘logs.log’ file from current active directory</p>
</dd></dl>

<dl class="py function">
<dt id="pycaret.clustering.load_model">
<code class="sig-prename descclassname">pycaret.clustering.</code><code class="sig-name descname">load_model</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">model_name</span></em>, <em class="sig-param"><span class="n">platform</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">authentication</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.clustering.load_model" title="Permalink to this definition">¶</a></dt>
<dd><p>This function loads a previously saved transformation pipeline and model
from the current active directory into the current python environment.
Load object must be a pickle file.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">saved_kmeans</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="s1">&#39;kmeans_model_23122019&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>This will load the previously saved model in saved_lr variable. The file
must be in the current directory.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_name</strong> (<em>string</em><em>, </em><em>default = none</em>) – Name of pickle file to be passed as a string.</p></li>
<li><p><strong>platform</strong> (<em>string</em><em>, </em><em>default = None</em>) – Name of platform, if loading model from cloud. Current available options are:
‘aws’.</p></li>
<li><p><strong>authentication</strong> (<em>dict</em>) – <p>Dictionary of applicable authentication tokens.</p>
<p>When platform = ‘aws’:
{‘bucket’ : ‘Name of Bucket on S3’}</p>
</p></li>
<li><p><strong>verbose</strong> (<em>Boolean</em><em>, </em><em>default = True</em>) – Success message is not printed when verbose is set to False.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Success_Message</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pycaret.clustering.models">
<code class="sig-prename descclassname">pycaret.clustering.</code><code class="sig-name descname">models</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.clustering.models" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns table of models available in model library.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">all_models</span> <span class="o">=</span> <span class="n">models</span><span class="p">()</span>
</pre></div>
</div>
<p>This will return pandas dataframe with all available
models and their metadata.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>pandas.DataFrame</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pycaret.clustering.plot_model">
<code class="sig-prename descclassname">pycaret.clustering.</code><code class="sig-name descname">plot_model</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">model</span></em>, <em class="sig-param"><span class="n">plot</span><span class="o">=</span><span class="default_value">'cluster'</span></em>, <em class="sig-param"><span class="n">feature</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">label</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">save</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">system</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.clustering.plot_model" title="Permalink to this definition">¶</a></dt>
<dd><p>This function takes a trained model object and returns a plot on the dataset
passed during setup stage. This function internally calls assign_model before
generating a plot.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pycaret.datasets</span> <span class="kn">import</span> <span class="n">get_data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">jewellery</span> <span class="o">=</span> <span class="n">get_data</span><span class="p">(</span><span class="s1">&#39;jewellery&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">experiment_name</span> <span class="o">=</span> <span class="n">setup</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">jewellery</span><span class="p">,</span> <span class="n">normalize</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">kmeans</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">(</span><span class="s1">&#39;kmeans&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">plot_model</span><span class="p">(</span><span class="n">kmeans</span><span class="p">)</span>
</pre></div>
</div>
<p>This will return a cluster scatter plot (by default).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>object</em><em>, </em><em>default = none</em>) – A trained model object can be passed. Model must be created using create_model().</p></li>
<li><p><strong>plot</strong> (<em>string</em><em>, </em><em>default = 'cluster'</em>) – <p>Enter abbreviation for type of plot. The current list of plots supported are:</p>
<p>Plot            Name
———       ———–
‘cluster’       Cluster PCA Plot (2d)
‘tsne’          Cluster TSnE (3d)
‘elbow’         Elbow Plot
‘silhouette’    Silhouette Plot
‘distance’      Distance Plot
‘distribution’  Distribution Plot</p>
</p></li>
<li><p><strong>feature</strong> (<em>string</em><em>, </em><em>default = None</em>) – Name of feature column for x-axis of when plot = ‘distribution’. When plot is
‘cluster’ or ‘tsne’ feature column is used as a hoverover tooltip and/or label
when label is set to True. If no feature name is passed in ‘cluster’ or ‘tsne’
by default the first of column of dataset is chosen as hoverover tooltip.</p></li>
<li><p><strong>label</strong> (<em>bool</em><em>, </em><em>default = False</em>) – When set to True, data labels are shown in ‘cluster’ and ‘tsne’ plot.</p></li>
<li><p><strong>save</strong> (<em>Boolean</em><em>, </em><em>default = False</em>) – Plot is saved as png file in local directory when save parameter set to True.</p></li>
<li><p><strong>system</strong> (<em>Boolean</em><em>, </em><em>default = True</em>) – Must remain True all times. Only to be changed by internal functions.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Prints the visual plot.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Visual_Plot</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pycaret.clustering.predict_model">
<code class="sig-prename descclassname">pycaret.clustering.</code><code class="sig-name descname">predict_model</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">model</span></em>, <em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">platform</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">authentication</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.clustering.predict_model" title="Permalink to this definition">¶</a></dt>
<dd><p>This function is used to predict new data using a trained model. It requires a
trained model object created using one of the function in pycaret that returns
a trained model object. New data must be passed to data param as pandas Dataframe.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pycaret.datasets</span> <span class="kn">import</span> <span class="n">get_data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">jewellery</span> <span class="o">=</span> <span class="n">get_data</span><span class="p">(</span><span class="s1">&#39;jewellery&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">experiment_name</span> <span class="o">=</span> <span class="n">setup</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">jewellery</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">kmeans</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">(</span><span class="s1">&#39;kmeans&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">kmeans_predictions</span> <span class="o">=</span> <span class="n">predict_model</span><span class="p">(</span><span class="n">model</span> <span class="o">=</span> <span class="n">kmeans</span><span class="p">,</span> <span class="n">data</span> <span class="o">=</span> <span class="n">jewellery</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>object / string</em><em>,  </em><em>default = None</em>) – When model is passed as string, load_model() is called internally to load the
pickle file from active directory or cloud platform when platform param is passed.</p></li>
<li><p><strong>data</strong> (<em>{array-like</em><em>, </em><em>sparse matrix}</em>) – Shape (n_samples, n_features) where n_samples is the number of samples and n_features is the number of features.
All features used during training must be present in the new dataset.</p></li>
<li><p><strong>platform</strong> (<em>string</em><em>, </em><em>default = None</em>) – Name of platform, if loading model from cloud. Current available options are:
‘aws’.</p></li>
<li><p><strong>authentication</strong> (<em>dict</em>) – <p>Dictionary of applicable authentication tokens.</p>
<p>When platform = ‘aws’:
{‘bucket’ : ‘Name of Bucket on S3’}</p>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Information grid is printed when data is None.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>info_grid</p>
</dd>
</dl>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<ul class="simple">
<li><p>Models that donot support ‘predict’ function cannot be used in predict_model().</p></li>
</ul>
</div>
</dd></dl>

<dl class="py function">
<dt id="pycaret.clustering.save_model">
<code class="sig-prename descclassname">pycaret.clustering.</code><code class="sig-name descname">save_model</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">model</span></em>, <em class="sig-param"><span class="n">model_name</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.clustering.save_model" title="Permalink to this definition">¶</a></dt>
<dd><p>This function saves the transformation pipeline and trained model object
into the current active directory as a pickle file for later use.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pycaret.datasets</span> <span class="kn">import</span> <span class="n">get_data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">jewellery</span> <span class="o">=</span> <span class="n">get_data</span><span class="p">(</span><span class="s1">&#39;jewellery&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">experiment_name</span> <span class="o">=</span> <span class="n">setup</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">jewellery</span><span class="p">,</span> <span class="n">normalize</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">kmeans</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">(</span><span class="s1">&#39;kmeans&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">save_model</span><span class="p">(</span><span class="n">kmeans</span><span class="p">,</span> <span class="s1">&#39;kmeans_model_23122019&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>This will save the transformation pipeline and model as a binary pickle
file in the current directory.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>object</em><em>, </em><em>default = none</em>) – A trained model object should be passed.</p></li>
<li><p><strong>model_name</strong> (<em>string</em><em>, </em><em>default = none</em>) – Name of pickle file to be passed as a string.</p></li>
<li><p><strong>verbose</strong> (<em>bool</em><em>, </em><em>default = True</em>) – When set to False, success message is not printed.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Success_Message</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pycaret.clustering.set_config">
<code class="sig-prename descclassname">pycaret.clustering.</code><code class="sig-name descname">set_config</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">variable</span></em>, <em class="sig-param"><span class="n">value</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.clustering.set_config" title="Permalink to this definition">¶</a></dt>
<dd><p>This function is used to reset global environment variables.
Following variables can be accessed:</p>
<ul class="simple">
<li><p>X: Transformed dataset</p></li>
<li><p><a href="#id11"><span class="problematic" id="id12">data_</span></a>: Original dataset</p></li>
<li><p>seed: random state set through session_id</p></li>
<li><p>prep_pipe: Transformation pipeline configured through setup</p></li>
<li><p>prep_param: prep_param configured through setup</p></li>
<li><p>n_jobs_param: n_jobs parameter used in model training</p></li>
<li><p>html_param: html_param configured through setup</p></li>
<li><p>exp_name_log: Name of experiment set through setup</p></li>
<li><p>logging_param: log_experiment param set through setup</p></li>
<li><p>log_plots_param: log_plots param set through setup</p></li>
<li><p>USI: Unique session ID parameter set through setup</p></li>
</ul>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">set_config</span><span class="p">(</span><span class="s1">&#39;seed&#39;</span><span class="p">,</span> <span class="mi">123</span><span class="p">)</span>
</pre></div>
</div>
<p>This will set the global seed to ‘123’.</p>
</dd></dl>

<dl class="py function">
<dt id="pycaret.clustering.setup">
<code class="sig-prename descclassname">pycaret.clustering.</code><code class="sig-name descname">setup</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">categorical_features</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">categorical_imputation</span><span class="o">=</span><span class="default_value">'constant'</span></em>, <em class="sig-param"><span class="n">ordinal_features</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">high_cardinality_features</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">numeric_features</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">numeric_imputation</span><span class="o">=</span><span class="default_value">'mean'</span></em>, <em class="sig-param"><span class="n">date_features</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">ignore_features</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">normalize</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">normalize_method</span><span class="o">=</span><span class="default_value">'zscore'</span></em>, <em class="sig-param"><span class="n">transformation</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">transformation_method</span><span class="o">=</span><span class="default_value">'yeo-johnson'</span></em>, <em class="sig-param"><span class="n">handle_unknown_categorical</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">unknown_categorical_method</span><span class="o">=</span><span class="default_value">'least_frequent'</span></em>, <em class="sig-param"><span class="n">pca</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">pca_method</span><span class="o">=</span><span class="default_value">'linear'</span></em>, <em class="sig-param"><span class="n">pca_components</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">ignore_low_variance</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">combine_rare_levels</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">rare_level_threshold</span><span class="o">=</span><span class="default_value">0.1</span></em>, <em class="sig-param"><span class="n">bin_numeric_features</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">remove_multicollinearity</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">multicollinearity_threshold</span><span class="o">=</span><span class="default_value">0.9</span></em>, <em class="sig-param"><span class="n">group_features</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">group_names</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">supervised</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">supervised_target</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">n_jobs</span><span class="o">=</span><span class="default_value">- 1</span></em>, <em class="sig-param"><span class="n">html</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">session_id</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">log_experiment</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">experiment_name</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">log_plots</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">log_profile</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">log_data</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">silent</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">profile</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.clustering.setup" title="Permalink to this definition">¶</a></dt>
<dd><p>This function initializes the environment in pycaret. setup() must called before
executing any other function in pycaret. It takes one mandatory parameter:
dataframe {array-like, sparse matrix}.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pycaret.datasets</span> <span class="kn">import</span> <span class="n">get_data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">jewellery</span> <span class="o">=</span> <span class="n">get_data</span><span class="p">(</span><span class="s1">&#39;jewellery&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">experiment_name</span> <span class="o">=</span> <span class="n">setup</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">jewellery</span><span class="p">,</span> <span class="n">normalize</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<p>‘jewellery’ is a pandas Dataframe.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<em>{array-like</em><em>, </em><em>sparse matrix}</em>) – Shape (n_samples, n_features) where n_samples is the number of samples and n_features is the number of features in dataframe.</p></li>
<li><p><strong>categorical_features</strong> (<em>string</em><em>, </em><em>default = None</em>) – If the inferred data types are not correct, categorical_features can be used to
overwrite the inferred type. If when running setup the type of ‘column1’ is
inferred as numeric instead of categorical, then this parameter can be used
to overwrite the type by passing categorical_features = [‘column1’].</p></li>
<li><p><strong>categorical_imputation</strong> (<em>string</em><em>, </em><em>default = 'constant'</em>) – If missing values are found in categorical features, they will be imputed with
a constant ‘not_available’ value. The other available option is ‘mode’ which
imputes the missing value using most frequent value in the training dataset.</p></li>
<li><p><strong>ordinal_features</strong> (<em>dictionary</em><em>, </em><em>default = None</em>) – When the data contains ordinal features, they must be encoded differently using
the ordinal_features param. If the data has a categorical variable with values
of ‘low’, ‘medium’, ‘high’ and it is known that low &lt; medium &lt; high, then it can
be passed as ordinal_features = { ‘column_name’ : [‘low’, ‘medium’, ‘high’] }.
The list sequence must be in increasing order from lowest to highest.</p></li>
<li><p><strong>high_cardinality_features</strong> (<em>string</em><em>, </em><em>default = None</em>) – When the data containts features with high cardinality, they can be compressed
into fewer levels by passing them as a list of column names with high cardinality.
Features are compressed using frequency distribution. As such original features
are replaced with the frequency distribution and converted into numeric variable.</p></li>
<li><p><strong>numeric_features</strong> (<em>string</em><em>, </em><em>default = None</em>) – If the inferred data types are not correct, numeric_features can be used to
overwrite the inferred type. If when running setup the type of ‘column1’ is
inferred as a categorical instead of numeric, then this parameter can be used
to overwrite by passing numeric_features = [‘column1’].</p></li>
<li><p><strong>numeric_imputation</strong> (<em>string</em><em>, </em><em>default = 'mean'</em>) – If missing values are found in numeric features, they will be imputed with the
mean value of the feature. The other available option is ‘median’ which imputes
the value using the median value in the training dataset.</p></li>
<li><p><strong>date_features</strong> (<em>string</em><em>, </em><em>default = None</em>) – If the data has a DateTime column that is not automatically detected when running
setup, this parameter can be used by passing date_features = ‘date_column_name’.
It can work with multiple date columns. Date columns are not used in modeling.
Instead, feature extraction is performed and date columns are dropped from the
dataset. If the date column includes a time stamp, features related to time will
also be extracted.</p></li>
<li><p><strong>ignore_features</strong> (<em>string</em><em>, </em><em>default = None</em>) – If any feature should be ignored for modeling, it can be passed to the param
ignore_features. The ID and DateTime columns when inferred, are automatically
set to ignore for modeling.</p></li>
<li><p><strong>normalize</strong> (<em>bool</em><em>, </em><em>default = False</em>) – When set to True, the feature space is transformed using the normalized_method
param. Generally, linear algorithms perform better with normalized data however,
the results may vary and it is advised to run multiple experiments to evaluate
the benefit of normalization.</p></li>
<li><p><strong>normalize_method</strong> (<em>string</em><em>, </em><em>default = 'zscore'</em>) – <p>Defines the method to be used for normalization. By default, normalize method
is set to ‘zscore’. The standard zscore is calculated as z = (x - u) / s. The
other available options are:</p>
<dl class="simple">
<dt>’minmax’<span class="classifier">scales and translates each feature individually such that it is in</span></dt><dd><p>the range of 0 - 1.</p>
</dd>
<dt>’maxabs’<span class="classifier">scales and translates each feature individually such that the maximal</span></dt><dd><p>absolute value of each feature will be 1.0. It does not shift/center
the data, and thus does not destroy any sparsity.</p>
</dd>
<dt>’robust’<span class="classifier">scales and translates each feature according to the Interquartile range.</span></dt><dd><p>When the dataset contains outliers, robust scaler often gives better
results.</p>
</dd>
</dl>
</p></li>
<li><p><strong>transformation</strong> (<em>bool</em><em>, </em><em>default = False</em>) – When set to True, a power transformation is applied to make the data more normal /
Gaussian-like. This is useful for modeling issues related to heteroscedasticity or
other situations where normality is desired. The optimal parameter for stabilizing
variance and minimizing skewness is estimated through maximum likelihood.</p></li>
<li><p><strong>transformation_method</strong> (<em>string</em><em>, </em><em>default = 'yeo-johnson'</em>) – Defines the method for transformation. By default, the transformation method is set
to ‘yeo-johnson’. The other available option is ‘quantile’ transformation. Both
the transformation transforms the feature set to follow a Gaussian-like or normal
distribution. Note that the quantile transformer is non-linear and may distort linear
correlations between variables measured at the same scale.</p></li>
<li><p><strong>handle_unknown_categorical</strong> (<em>bool</em><em>, </em><em>default = True</em>) – When set to True, unknown categorical levels in new / unseen data are replaced by
the most or least frequent level as learned in the training data. The method is
defined under the unknown_categorical_method param.</p></li>
<li><p><strong>unknown_categorical_method</strong> (<em>string</em><em>, </em><em>default = 'least_frequent'</em>) – Method used to replace unknown categorical levels in unseen data. Method can be
set to ‘least_frequent’ or ‘most_frequent’.</p></li>
<li><p><strong>pca</strong> (<em>bool</em><em>, </em><em>default = False</em>) – When set to True, dimensionality reduction is applied to project the data into
a lower dimensional space using the method defined in pca_method param. In
supervised learning pca is generally performed when dealing with high feature
space and memory is a constraint. Note that not all datasets can be decomposed
efficiently using a linear PCA technique and that applying PCA may result in loss
of information. As such, it is advised to run multiple experiments with different
pca_methods to evaluate the impact.</p></li>
<li><p><strong>pca_method</strong> (<em>string</em><em>, </em><em>default = 'linear'</em>) – <p>The ‘linear’ method performs Linear dimensionality reduction using Singular Value
Decomposition. The other available options are:</p>
<p>kernel      : dimensionality reduction through the use of RVF kernel.</p>
<dl class="simple">
<dt>incremental<span class="classifier">replacement for ‘linear’ pca when the dataset to be decomposed is</span></dt><dd><p>too large to fit in memory</p>
</dd>
</dl>
</p></li>
<li><p><strong>pca_components</strong> (<em>int/float</em><em>, </em><em>default = 0.99</em>) – Number of components to keep. if pca_components is a float, it is treated as a
target percentage for information retention. When pca_components is an integer
it is treated as the number of features to be kept. pca_components must be strictly
less than the original number of features in the dataset.</p></li>
<li><p><strong>ignore_low_variance</strong> (<em>bool</em><em>, </em><em>default = False</em>) – When set to True, all categorical features with statistically insignificant variances
are removed from the dataset. The variance is calculated using the ratio of unique
values to the number of samples, and the ratio of the most common value to the
frequency of the second most common value.</p></li>
<li><p><strong>combine_rare_levels</strong> (<em>bool</em><em>, </em><em>default = False</em>) – When set to True, all levels in categorical features below the threshold defined
in rare_level_threshold param are combined together as a single level. There must be
atleast two levels under the threshold for this to take effect. rare_level_threshold
represents the percentile distribution of level frequency. Generally, this technique
is applied to limit a sparse matrix caused by high numbers of levels in categorical
features.</p></li>
<li><p><strong>rare_level_threshold</strong> (<em>float</em><em>, </em><em>default = 0.1</em>) – Percentile distribution below which rare categories are combined. Only comes into
effect when combine_rare_levels is set to True.</p></li>
<li><p><strong>bin_numeric_features</strong> (<em>list</em><em>, </em><em>default = None</em>) – When a list of numeric features is passed they are transformed into categorical
features using KMeans, where values in each bin have the same nearest center of a
1D k-means cluster. The number of clusters are determined based on the ‘sturges’
method. It is only optimal for gaussian data and underestimates the number of bins
for large non-gaussian datasets.</p></li>
<li><p><strong>remove_multicollinearity</strong> (<em>bool</em><em>, </em><em>default = False</em>) – When set to True, the variables with inter-correlations higher than the threshold
defined under the multicollinearity_threshold param are dropped. When two features
are highly correlated with each other, the feature with higher average correlation
in the feature space is dropped.</p></li>
<li><p><strong>multicollinearity_threshold</strong> (<em>float</em><em>, </em><em>default = 0.9</em>) – Threshold used for dropping the correlated features. Only comes into effect when
remove_multicollinearity is set to True.</p></li>
<li><p><strong>group_features</strong> (<em>list</em><em> or </em><em>list of list</em><em>, </em><em>default = None</em>) – When a dataset contains features that have related characteristics, the group_features
param can be used for statistical feature extraction. For example, if a dataset has
numeric features that are related with each other (i.e ‘Col1’, ‘Col2’, ‘Col3’), a list
containing the column names can be passed under group_features to extract statistical
information such as the mean, median, mode and standard deviation.</p></li>
<li><p><strong>group_names</strong> (<em>list</em><em>, </em><em>default = None</em>) – When group_features is passed, a name of the group can be passed into the group_names
param as a list containing strings. The length of a group_names list must equal to the
length  of group_features. When the length doesn’t match or the name is not passed, new
features are sequentially named such as group_1, group_2 etc.</p></li>
<li><p><strong>supervised</strong> (<em>bool</em><em>, </em><em>default = False</em>) – When set to True, supervised_target column is ignored for transformation. This
param is only for internal use.</p></li>
<li><p><strong>supervised_target</strong> (<em>string</em><em>, </em><em>default = None</em>) – Name of supervised_target column that will be ignored for transformation. Only
applciable when tune_model() function is used. This param is only for internal use.</p></li>
<li><p><strong>n_jobs</strong> (<em>int</em><em>, </em><em>default = -1</em>) – The number of jobs to run in parallel (for functions that supports parallel
processing) -1 means using all processors. To run all functions on single processor
set n_jobs to None.</p></li>
<li><p><strong>html</strong> (<em>bool</em><em>, </em><em>default = True</em>) – If set to False, prevents runtime display of monitor. This must be set to False
when using environment that doesnt support HTML.</p></li>
<li><p><strong>session_id</strong> (<em>int</em><em>, </em><em>default = None</em>) – If None, a random seed is generated and returned in the Information grid. The
unique number is then distributed as a seed in all functions used during the
experiment. This can be used for later reproducibility of the entire experiment.</p></li>
<li><p><strong>log_experiment</strong> (<em>bool</em><em>, </em><em>default = True</em>) – When set to True, all metrics and parameters are logged on MLFlow server.</p></li>
<li><p><strong>experiment_name</strong> (<em>str</em><em>, </em><em>default = None</em>) – Name of experiment for logging. When set to None, ‘clu’ is by default used as
alias for the experiment name.</p></li>
<li><p><strong>log_plots</strong> (<em>bool</em><em>, </em><em>default = False</em>) – When set to True, specific plots are logged in MLflow as a png file. By default,
it is set to False.</p></li>
<li><p><strong>log_profile</strong> (<em>bool</em><em>, </em><em>default = False</em>) – When set to True, data profile is also logged on MLflow as a html file. By default,
it is set to False.</p></li>
<li><p><strong>log_data</strong> (<em>bool</em><em>, </em><em>default = False</em>) – When set to True, train and test dataset are logged as csv.</p></li>
<li><p><strong>silent</strong> (<em>bool</em><em>, </em><em>default = False</em>) – When set to True, confirmation of data types is not required. All preprocessing will
be performed assuming automatically inferred data types. Not recommended for direct use
except for established pipelines.</p></li>
<li><p><strong>verbose</strong> (<em>Boolean</em><em>, </em><em>default = True</em>) – Information grid is not printed when verbose is set to False.</p></li>
<li><p><strong>profile</strong> (<em>bool</em><em>, </em><em>default = False</em>) – If set to true, a data profile for Exploratory Data Analysis will be displayed
in an interactive HTML report.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><em>info_grid</em> – Information grid is printed.</p></li>
<li><p><em>environment</em> – This function returns various outputs that are stored in variable
as tuple. They are used by other functions in pycaret.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pycaret.clustering.tune_model">
<code class="sig-prename descclassname">pycaret.clustering.</code><code class="sig-name descname">tune_model</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">model</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">supervised_target</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">estimator</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">optimize</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">custom_grid</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">fold</span><span class="o">=</span><span class="default_value">10</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.clustering.tune_model" title="Permalink to this definition">¶</a></dt>
<dd><p>This function tunes the num_clusters model parameter using a predefined grid with
the objective of optimizing a supervised learning metric as defined in the optimize
param. You can choose the supervised estimator from a large library available in pycaret.
By default, supervised estimator is Linear.</p>
<p>This function returns the tuned model object.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pycaret.datasets</span> <span class="kn">import</span> <span class="n">get_data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">boston</span> <span class="o">=</span> <span class="n">get_data</span><span class="p">(</span><span class="s1">&#39;boston&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">experiment_name</span> <span class="o">=</span> <span class="n">setup</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">boston</span><span class="p">,</span> <span class="n">normalize</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tuned_kmeans</span> <span class="o">=</span> <span class="n">tune_model</span><span class="p">(</span><span class="n">model</span> <span class="o">=</span> <span class="s1">&#39;kmeans&#39;</span><span class="p">,</span> <span class="n">supervised_target</span> <span class="o">=</span> <span class="s1">&#39;medv&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>This will return tuned K-Means Clustering Model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>string</em><em>, </em><em>default = None</em>) – <p>Enter ID of the models available in model library:</p>
<p>ID              Name
——          ———–
‘kmeans’        K-Means Clustering
‘ap’            Affinity Propagation
‘meanshift’     Mean shift Clustering
‘sc’            Spectral Clustering
‘hclust’        Agglomerative Clustering
‘dbscan’        Density-Based Spatial Clustering
‘optics’        OPTICS Clustering
‘birch’         Birch Clustering
‘kmodes’        K-Modes Clustering</p>
</p></li>
<li><p><strong>supervised_target</strong> (<em>string</em>) – Name of the target column for supervised learning.</p></li>
<li><p><strong>estimator</strong> (<em>string</em><em>, </em><em>default = None</em>) – <p>ID          Name                            Task
——–    ———-                      ———-
‘lr’        Logistic Regression             Classification
‘knn’       K Nearest Neighbour             Classification
‘nb’        Naive Bayes                     Classification
‘dt’        Decision Tree Classifier        Classification
‘svm’       SVM - Linear Kernel             Classification
‘rbfsvm’    SVM - Radial Kernel             Classification
‘gpc’       Gaussian Process Classifier     Classification
‘mlp’       Multi Level Perceptron          Classification
‘ridge’     Ridge Classifier                Classification
‘rf’        Random Forest Classifier        Classification
‘qda’       Quadratic Discriminant Analysis Classification
‘ada’       Ada Boost Classifier            Classification
‘gbc’       Gradient Boosting Classifier    Classification
‘lda’       Linear Discriminant Analysis    Classification
‘et’        Extra Trees Classifier          Classification
‘xgboost’   Extreme Gradient Boosting       Classification
‘lightgbm’  Light Gradient Boosting         Classification
‘catboost’  CatBoost Classifier             Classification
‘lr’        Linear Regression               Regression
‘lasso’     Lasso Regression                Regression
‘ridge’     Ridge Regression                Regression
‘en’        Elastic Net                     Regression
‘lar’       Least Angle Regression          Regression
‘llar’      Lasso Least Angle Regression    Regression
‘omp’       Orthogonal Matching Pursuit     Regression
‘br’        Bayesian Ridge                  Regression
‘ard’       Automatic Relevance Determ.     Regression
‘par’       Passive Aggressive Regressor    Regression
‘ransac’    Random Sample Consensus         Regression
‘tr’        TheilSen Regressor              Regression
‘huber’     Huber Regressor                 Regression
‘kr’        Kernel Ridge                    Regression
‘svm’       Support Vector Machine          Regression
‘knn’       K Neighbors Regressor           Regression
‘dt’        Decision Tree                   Regression
‘rf’        Random Forest                   Regression
‘et’        Extra Trees Regressor           Regression
‘ada’       AdaBoost Regressor              Regression
‘gbr’       Gradient Boosting               Regression
‘mlp’       Multi Level Perceptron          Regression
‘xgboost’   Extreme Gradient Boosting       Regression
‘lightgbm’  Light Gradient Boosting         Regression
‘catboost’  CatBoost Regressor              Regression</p>
<p>If set to None, Linear / Logistic model is used by default.</p>
</p></li>
<li><p><strong>optimize</strong> (<em>string</em><em>, </em><em>default = None</em>) – <dl class="simple">
<dt>For Classification tasks:</dt><dd><p>Accuracy, AUC, Recall, Precision, F1, Kappa</p>
</dd>
<dt>For Regression tasks:</dt><dd><p>MAE, MSE, RMSE, R2, RMSLE, MAPE</p>
</dd>
</dl>
</p></li>
<li><p><strong>set to None</strong><strong>, </strong><strong>default is 'Accuracy' for classification and 'R2' for</strong> (<em>If</em>) – </p></li>
<li><p><strong>tasks.</strong> (<em>regression</em>) – </p></li>
<li><p><strong>custom_grid</strong> (<em>list</em><em>, </em><em>default = None</em>) – By default, a pre-defined number of clusters is iterated over to
optimize the supervised objective. To overwrite default iteration,
pass a list of num_clusters to iterate over in custom_grid param.</p></li>
<li><p><strong>fold</strong> (<em>integer</em><em>, </em><em>default = 10</em>) – Number of folds to be used in Kfold CV. Must be at least 2.</p></li>
<li><p><strong>verbose</strong> (<em>Boolean</em><em>, </em><em>default = True</em>) – Status update is not printed when verbose is set to False.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><em>Visual_Plot</em> – Visual plot with num_clusters param on x-axis with metric to
optimize on y-axis. Also, prints the best model metric.</p></li>
<li><p><em>model</em> – trained model object with best num_clusters param.</p></li>
</ul>
</p>
</dd>
</dl>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<ul class="simple">
<li><p>Affinity Propagation, Mean shift clustering, Density-Based Spatial Clustering
and OPTICS Clustering cannot be used in this function since they donot support
num_clusters param.</p></li>
</ul>
</div>
</dd></dl>

</div>
<div class="section" id="module-pycaret.anomaly">
<span id="anomaly"></span><h1>Anomaly<a class="headerlink" href="#module-pycaret.anomaly" title="Permalink to this headline">¶</a></h1>
<dl class="py function">
<dt id="pycaret.anomaly.assign_model">
<code class="sig-prename descclassname">pycaret.anomaly.</code><code class="sig-name descname">assign_model</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">model</span></em>, <em class="sig-param"><span class="n">transformation</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">score</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.anomaly.assign_model" title="Permalink to this definition">¶</a></dt>
<dd><p>This function flags each of the data point in the dataset passed during setup
stage as either outlier or inlier (1 = outlier, 0 = inlier) using trained model
object passed as model param. create_model() function must be called before using
assign_model().</p>
<p>This function returns dataframe with Outlier flag (1 = outlier, 0 = inlier) and
decision score, when score is set to True.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pycaret.datasets</span> <span class="kn">import</span> <span class="n">get_data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">anomaly</span> <span class="o">=</span> <span class="n">get_data</span><span class="p">(</span><span class="s1">&#39;anomaly&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">experiment_name</span> <span class="o">=</span> <span class="n">setup</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">anomaly</span><span class="p">,</span> <span class="n">normalize</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">knn</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">(</span><span class="s1">&#39;knn&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">knn_df</span> <span class="o">=</span> <span class="n">assign_model</span><span class="p">(</span><span class="n">knn</span><span class="p">)</span>
</pre></div>
</div>
<p>This will return a dataframe with inferred outliers using trained model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>trained model object</em><em>, </em><em>default = None</em>) – </p></li>
<li><p><strong>transformation</strong> (<em>bool</em><em>, </em><em>default = False</em>) – When set to True, assigned outliers are returned on transformed dataset instead
of original dataset passed during setup().</p></li>
<li><p><strong>score</strong> (<em>Boolean</em><em>, </em><em>default = True</em>) – The outlier scores of the training data. The higher, the more abnormal.
Outliers tend to have higher scores. This value is available once the model
is fitted. If set to False, it will only return the flag (1 = outlier, 0 = inlier).</p></li>
<li><p><strong>verbose</strong> (<em>Boolean</em><em>, </em><em>default = True</em>) – Status update is not printed when verbose is set to False.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Returns a dataframe with inferred outliers using a trained model.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>pandas.DataFrame</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pycaret.anomaly.create_model">
<code class="sig-prename descclassname">pycaret.anomaly.</code><code class="sig-name descname">create_model</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">model</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">fraction</span><span class="o">=</span><span class="default_value">0.05</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">system</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.anomaly.create_model" title="Permalink to this definition">¶</a></dt>
<dd><p>This function creates a model on the dataset passed as a data param during
the setup stage. setup() function must be called before using create_model().</p>
<p>This function returns a trained model object.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pycaret.datasets</span> <span class="kn">import</span> <span class="n">get_data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">anomaly</span> <span class="o">=</span> <span class="n">get_data</span><span class="p">(</span><span class="s1">&#39;anomaly&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">experiment_name</span> <span class="o">=</span> <span class="n">setup</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">anomaly</span><span class="p">,</span> <span class="n">normalize</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">knn</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">(</span><span class="s1">&#39;knn&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>This will return trained k-Nearest Neighbors model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>string / object</em><em>, </em><em>default = None</em>) – <p>Enter ID of the models available in model library or pass an untrained model
object consistent with fit / predict API to train and evaluate model. List of
models available in model library:</p>
<p>ID          Model
——-     ———
‘abod’      Angle-base Outlier Detection
‘cluster’   Clustering-Based Local Outlier
‘cof’       Connectivity-Based Outlier Factor
‘histogram’ Histogram-based Outlier Detection
‘knn’       k-Nearest Neighbors Detector
‘lof’       Local Outlier Factor
‘svm’       One-class SVM detector
‘pca’       Principal Component Analysis
‘mcd’       Minimum Covariance Determinant
‘sod’       Subspace Outlier Detection
‘sos’       Stochastic Outlier Selection</p>
</p></li>
<li><p><strong>fraction</strong> (<em>float</em><em>, </em><em>default = 0.05</em>) – The percentage / proportion of outliers in the dataset.</p></li>
<li><p><strong>verbose</strong> (<em>Boolean</em><em>, </em><em>default = True</em>) – Status update is not printed when verbose is set to False.</p></li>
<li><p><strong>system</strong> (<em>Boolean</em><em>, </em><em>default = True</em>) – Must remain True all times. Only to be changed by internal functions.</p></li>
<li><p><strong>**kwargs</strong> – Additional keyword arguments to pass to the estimator.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Trained model object.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>model</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pycaret.anomaly.deploy_model">
<code class="sig-prename descclassname">pycaret.anomaly.</code><code class="sig-name descname">deploy_model</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">model</span></em>, <em class="sig-param"><span class="n">model_name</span></em>, <em class="sig-param"><span class="n">authentication</span></em>, <em class="sig-param"><span class="n">platform</span><span class="o">=</span><span class="default_value">'aws'</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.anomaly.deploy_model" title="Permalink to this definition">¶</a></dt>
<dd><p>(In Preview)</p>
<p>This function deploys the transformation pipeline and trained model object for
production use. The platform of deployment can be defined under the platform
param along with the applicable authentication tokens which are passed as a
dictionary to the authentication param.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pycaret.datasets</span> <span class="kn">import</span> <span class="n">get_data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">anomaly</span> <span class="o">=</span> <span class="n">get_data</span><span class="p">(</span><span class="s1">&#39;anomaly&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">experiment_name</span> <span class="o">=</span> <span class="n">setup</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">anomaly</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">knn</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">(</span><span class="s1">&#39;knn&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">deploy_model</span><span class="p">(</span><span class="n">model</span> <span class="o">=</span> <span class="n">knn</span><span class="p">,</span> <span class="n">model_name</span> <span class="o">=</span> <span class="s1">&#39;deploy_knn&#39;</span><span class="p">,</span> <span class="n">platform</span> <span class="o">=</span> <span class="s1">&#39;aws&#39;</span><span class="p">,</span> <span class="n">authentication</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;bucket&#39;</span> <span class="p">:</span> <span class="s1">&#39;pycaret-test&#39;</span><span class="p">})</span>
</pre></div>
</div>
<p>This will deploy the model on an AWS S3 account under bucket ‘pycaret-test’</p>
<p class="rubric">Notes</p>
<p>For AWS users:
Before deploying a model to an AWS S3 (‘aws’), environment variables must be
configured using the command line interface. To configure AWS env. variables,
type aws configure in your python command line. The following information is
required which can be generated using the Identity and Access Management (IAM)
portal of your amazon console account:</p>
<ul class="simple">
<li><p>AWS Access Key ID</p></li>
<li><p>AWS Secret Key Access</p></li>
<li><p>Default Region Name (can be seen under Global settings on your AWS console)</p></li>
<li><p>Default output format (must be left blank)</p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>object</em>) – A trained model object should be passed as an estimator.</p></li>
<li><p><strong>model_name</strong> (<em>string</em>) – Name of model to be passed as a string.</p></li>
<li><p><strong>authentication</strong> (<em>dict</em>) – <p>Dictionary of applicable authentication tokens.</p>
<p>When platform = ‘aws’:
{‘bucket’ : ‘Name of Bucket on S3’}</p>
</p></li>
<li><p><strong>platform</strong> (<em>string</em><em>, </em><em>default = 'aws'</em>) – Name of platform for deployment. Current available options are: ‘aws’.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Success_Message</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pycaret.anomaly.get_config">
<code class="sig-prename descclassname">pycaret.anomaly.</code><code class="sig-name descname">get_config</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">variable</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.anomaly.get_config" title="Permalink to this definition">¶</a></dt>
<dd><p>This function is used to access global environment variables.
Following variables can be accessed:</p>
<ul class="simple">
<li><p>X: Transformed dataset</p></li>
<li><p><a href="#id13"><span class="problematic" id="id14">data_</span></a>: Original dataset</p></li>
<li><p>seed: random state set through session_id</p></li>
<li><p>prep_pipe: Transformation pipeline configured through setup</p></li>
<li><p>prep_param: prep_param configured through setup</p></li>
<li><p>n_jobs_param: n_jobs parameter used in model training</p></li>
<li><p>html_param: html_param configured through setup</p></li>
<li><p>exp_name_log: Name of experiment set through setup</p></li>
<li><p>logging_param: log_experiment param set through setup</p></li>
<li><p>log_plots_param: log_plots param set through setup</p></li>
<li><p>USI: Unique session ID parameter set through setup</p></li>
</ul>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">get_config</span><span class="p">(</span><span class="s1">&#39;X&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>This will return transformed dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>variable</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pycaret.anomaly.get_logs">
<code class="sig-prename descclassname">pycaret.anomaly.</code><code class="sig-name descname">get_logs</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">experiment_name</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">save</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.anomaly.get_logs" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a table with experiment logs consisting
run details, parameter, metrics and tags.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">logs</span> <span class="o">=</span> <span class="n">get_logs</span><span class="p">()</span>
</pre></div>
</div>
<p>This will return pandas dataframe.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>experiment_name</strong> (<em>string</em><em>, </em><em>default = None</em>) – When set to None current active run is used.</p></li>
<li><p><strong>save</strong> (<em>bool</em><em>, </em><em>default = False</em>) – When set to True, csv file is saved in current directory.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>pandas.DataFrame</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pycaret.anomaly.get_outliers">
<code class="sig-prename descclassname">pycaret.anomaly.</code><code class="sig-name descname">get_outliers</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">model</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">fraction</span><span class="o">=</span><span class="default_value">0.05</span></em>, <em class="sig-param"><span class="n">ignore_features</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">normalize</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">transformation</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">pca</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">pca_components</span><span class="o">=</span><span class="default_value">0.99</span></em>, <em class="sig-param"><span class="n">ignore_low_variance</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">combine_rare_levels</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">rare_level_threshold</span><span class="o">=</span><span class="default_value">0.1</span></em>, <em class="sig-param"><span class="n">remove_multicollinearity</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">multicollinearity_threshold</span><span class="o">=</span><span class="default_value">0.9</span></em>, <em class="sig-param"><span class="n">n_jobs</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.anomaly.get_outliers" title="Permalink to this definition">¶</a></dt>
<dd><p>Magic function to get outliers in Power Query / Power BI.</p>
</dd></dl>

<dl class="py function">
<dt id="pycaret.anomaly.get_system_logs">
<code class="sig-prename descclassname">pycaret.anomaly.</code><code class="sig-name descname">get_system_logs</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.anomaly.get_system_logs" title="Permalink to this definition">¶</a></dt>
<dd><p>Read and print ‘logs.log’ file from current active directory</p>
</dd></dl>

<dl class="py function">
<dt id="pycaret.anomaly.load_model">
<code class="sig-prename descclassname">pycaret.anomaly.</code><code class="sig-name descname">load_model</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">model_name</span></em>, <em class="sig-param"><span class="n">platform</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">authentication</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.anomaly.load_model" title="Permalink to this definition">¶</a></dt>
<dd><p>This function loads a previously saved transformation pipeline and model
from the current active directory into the current python environment.
Load object must be a pickle file.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">saved_knn</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="s1">&#39;knn_model_23122019&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>This will load the previously saved model in saved_lr variable. The file
must be in the current directory.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_name</strong> (<em>string</em><em>, </em><em>default = none</em>) – Name of pickle file to be passed as a string.</p></li>
<li><p><strong>platform</strong> (<em>string</em><em>, </em><em>default = None</em>) – Name of platform, if loading model from cloud. Current available options are:
‘aws’.</p></li>
<li><p><strong>authentication</strong> (<em>dict</em>) – <p>Dictionary of applicable authentication tokens.</p>
<p>When platform = ‘aws’:
{‘bucket’ : ‘Name of Bucket on S3’}</p>
</p></li>
<li><p><strong>verbose</strong> (<em>Boolean</em><em>, </em><em>default = True</em>) – Success message is not printed when verbose is set to False.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Success_Message</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pycaret.anomaly.models">
<code class="sig-prename descclassname">pycaret.anomaly.</code><code class="sig-name descname">models</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.anomaly.models" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns table of models available in model library.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">all_models</span> <span class="o">=</span> <span class="n">models</span><span class="p">()</span>
</pre></div>
</div>
<p>This will return pandas dataframe with all available
models and their metadata.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>pandas.DataFrame</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pycaret.anomaly.plot_model">
<code class="sig-prename descclassname">pycaret.anomaly.</code><code class="sig-name descname">plot_model</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">model</span></em>, <em class="sig-param"><span class="n">plot</span><span class="o">=</span><span class="default_value">'tsne'</span></em>, <em class="sig-param"><span class="n">feature</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">save</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">system</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.anomaly.plot_model" title="Permalink to this definition">¶</a></dt>
<dd><p>This function takes a trained model object and returns a plot on the dataset
passed during setup stage. This function internally calls assign_model before
generating a plot.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pycaret.datasets</span> <span class="kn">import</span> <span class="n">get_data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">anomaly</span> <span class="o">=</span> <span class="n">get_data</span><span class="p">(</span><span class="s1">&#39;anomaly&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">experiment_name</span> <span class="o">=</span> <span class="n">setup</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">anomaly</span><span class="p">,</span> <span class="n">normalize</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">knn</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">(</span><span class="s1">&#39;knn&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">plot_model</span><span class="p">(</span><span class="n">knn</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>object</em>) – A trained model object can be passed. Model must be created using create_model().</p></li>
<li><p><strong>plot</strong> (<em>string</em><em>, </em><em>default = 'tsne'</em>) – <p>Enter abbreviation of type of plot. The current list of plots supported are:</p>
<p>Plot        Name
——-     ———-
‘tsne’      t-SNE (3d) Dimension Plot
‘umap’      UMAP Dimensionality Plot</p>
</p></li>
<li><p><strong>feature</strong> (<em>string</em><em>, </em><em>default = None</em>) – Feature column is used as a hoverover tooltip. By default, first of column of the
dataset is chosen as hoverover tooltip, when no feature is passed.</p></li>
<li><p><strong>save</strong> (<em>Boolean</em><em>, </em><em>default = False</em>) – Plot is saved as png file in local directory when save parameter set to True.</p></li>
<li><p><strong>system</strong> (<em>Boolean</em><em>, </em><em>default = True</em>) – Must remain True all times. Only to be changed by internal functions.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Prints the visual plot.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Visual_Plot</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pycaret.anomaly.predict_model">
<code class="sig-prename descclassname">pycaret.anomaly.</code><code class="sig-name descname">predict_model</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">model</span></em>, <em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">platform</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">authentication</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.anomaly.predict_model" title="Permalink to this definition">¶</a></dt>
<dd><p>This function is used to predict new data using a trained model. It requires a
trained model object created using one of the function in pycaret that returns
a trained model object. New data must be passed to data param as pandas Dataframe.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pycaret.datasets</span> <span class="kn">import</span> <span class="n">get_data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">anomaly</span> <span class="o">=</span> <span class="n">get_data</span><span class="p">(</span><span class="s1">&#39;anomaly&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">experiment_name</span> <span class="o">=</span> <span class="n">setup</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">anomaly</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">knn</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">(</span><span class="s1">&#39;knn&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">knn_predictions</span> <span class="o">=</span> <span class="n">predict_model</span><span class="p">(</span><span class="n">model</span> <span class="o">=</span> <span class="n">knn</span><span class="p">,</span> <span class="n">data</span> <span class="o">=</span> <span class="n">anomaly</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>object / string</em><em>,  </em><em>default = None</em>) – When model is passed as string, load_model() is called internally to load the
pickle file from active directory or cloud platform when platform param is passed.</p></li>
<li><p><strong>data</strong> (<em>{array-like</em><em>, </em><em>sparse matrix}</em>) – Shape (n_samples, n_features) where n_samples is the number of samples and n_features is the number of features.
All features used during training must be present in the new dataset.</p></li>
<li><p><strong>platform</strong> (<em>string</em><em>, </em><em>default = None</em>) – Name of platform, if loading model from cloud. Current available options are:
‘aws’.</p></li>
<li><p><strong>authentication</strong> (<em>dict</em>) – <p>Dictionary of applicable authentication tokens.</p>
<p>When platform = ‘aws’:
{‘bucket’ : ‘Name of Bucket on S3’}</p>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Information grid is printed when data is None.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>info_grid</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pycaret.anomaly.save_model">
<code class="sig-prename descclassname">pycaret.anomaly.</code><code class="sig-name descname">save_model</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">model</span></em>, <em class="sig-param"><span class="n">model_name</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.anomaly.save_model" title="Permalink to this definition">¶</a></dt>
<dd><p>This function saves the transformation pipeline and trained model object
into the current active directory as a pickle file for later use.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pycaret.datasets</span> <span class="kn">import</span> <span class="n">get_data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">anomaly</span> <span class="o">=</span> <span class="n">get_data</span><span class="p">(</span><span class="s1">&#39;anomaly&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">experiment_name</span> <span class="o">=</span> <span class="n">setup</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">anomaly</span><span class="p">,</span> <span class="n">normalize</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">knn</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">(</span><span class="s1">&#39;knn&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">save_model</span><span class="p">(</span><span class="n">knn</span><span class="p">,</span> <span class="s1">&#39;knn_model_23122019&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>This will save the transformation pipeline and model as a binary pickle
file in the current directory.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>object</em><em>, </em><em>default = none</em>) – A trained model object should be passed.</p></li>
<li><p><strong>model_name</strong> (<em>string</em><em>, </em><em>default = none</em>) – Name of pickle file to be passed as a string.</p></li>
<li><p><strong>verbose</strong> (<em>bool</em><em>, </em><em>default = True</em>) – When set to False, success message is not printed.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Success_Message</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pycaret.anomaly.set_config">
<code class="sig-prename descclassname">pycaret.anomaly.</code><code class="sig-name descname">set_config</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">variable</span></em>, <em class="sig-param"><span class="n">value</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.anomaly.set_config" title="Permalink to this definition">¶</a></dt>
<dd><p>This function is used to reset global environment variables.
Following variables can be accessed:</p>
<ul class="simple">
<li><p>X: Transformed dataset</p></li>
<li><p><a href="#id15"><span class="problematic" id="id16">data_</span></a>: Original dataset</p></li>
<li><p>seed: random state set through session_id</p></li>
<li><p>prep_pipe: Transformation pipeline configured through setup</p></li>
<li><p>prep_param: prep_param configured through setup</p></li>
<li><p>n_jobs_param: n_jobs parameter used in model training</p></li>
<li><p>html_param: html_param configured through setup</p></li>
<li><p>exp_name_log: Name of experiment set through setup</p></li>
<li><p>logging_param: log_experiment param set through setup</p></li>
<li><p>log_plots_param: log_plots param set through setup</p></li>
<li><p>USI: Unique session ID parameter set through setup</p></li>
</ul>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">set_config</span><span class="p">(</span><span class="s1">&#39;seed&#39;</span><span class="p">,</span> <span class="mi">123</span><span class="p">)</span>
</pre></div>
</div>
<p>This will set the global seed to ‘123’.</p>
</dd></dl>

<dl class="py function">
<dt id="pycaret.anomaly.setup">
<code class="sig-prename descclassname">pycaret.anomaly.</code><code class="sig-name descname">setup</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">categorical_features</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">categorical_imputation</span><span class="o">=</span><span class="default_value">'constant'</span></em>, <em class="sig-param"><span class="n">ordinal_features</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">high_cardinality_features</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">numeric_features</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">numeric_imputation</span><span class="o">=</span><span class="default_value">'mean'</span></em>, <em class="sig-param"><span class="n">date_features</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">ignore_features</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">normalize</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">normalize_method</span><span class="o">=</span><span class="default_value">'zscore'</span></em>, <em class="sig-param"><span class="n">transformation</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">transformation_method</span><span class="o">=</span><span class="default_value">'yeo-johnson'</span></em>, <em class="sig-param"><span class="n">handle_unknown_categorical</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">unknown_categorical_method</span><span class="o">=</span><span class="default_value">'least_frequent'</span></em>, <em class="sig-param"><span class="n">pca</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">pca_method</span><span class="o">=</span><span class="default_value">'linear'</span></em>, <em class="sig-param"><span class="n">pca_components</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">ignore_low_variance</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">combine_rare_levels</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">rare_level_threshold</span><span class="o">=</span><span class="default_value">0.1</span></em>, <em class="sig-param"><span class="n">bin_numeric_features</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">remove_multicollinearity</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">multicollinearity_threshold</span><span class="o">=</span><span class="default_value">0.9</span></em>, <em class="sig-param"><span class="n">group_features</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">group_names</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">supervised</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">supervised_target</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">n_jobs</span><span class="o">=</span><span class="default_value">- 1</span></em>, <em class="sig-param"><span class="n">html</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">session_id</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">log_experiment</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">experiment_name</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">log_plots</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">log_profile</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">log_data</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">silent</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">profile</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.anomaly.setup" title="Permalink to this definition">¶</a></dt>
<dd><p>This function initializes the environment in pycaret. setup() must called before
executing any other function in pycaret. It takes one mandatory parameter:
dataframe {array-like, sparse matrix}.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pycaret.datasets</span> <span class="kn">import</span> <span class="n">get_data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">anomaly</span> <span class="o">=</span> <span class="n">get_data</span><span class="p">(</span><span class="s1">&#39;anomaly&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">experiment_name</span> <span class="o">=</span> <span class="n">setup</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">anomaly</span><span class="p">,</span> <span class="n">normalize</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<p>‘anomaly’ is a pandas Dataframe.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<em>{array-like</em><em>, </em><em>sparse matrix}</em>) – Shape (n_samples, n_features) where n_samples is the number of samples and n_features is the number of features in dataframe.</p></li>
<li><p><strong>categorical_features</strong> (<em>string</em><em>, </em><em>default = None</em>) – If the inferred data types are not correct, categorical_features can be used to
overwrite the inferred type. If when running setup the type of ‘column1’ is
inferred as numeric instead of categorical, then this parameter can be used
to overwrite the type by passing categorical_features = [‘column1’].</p></li>
<li><p><strong>categorical_imputation</strong> (<em>string</em><em>, </em><em>default = 'constant'</em>) – If missing values are found in categorical features, they will be imputed with
a constant ‘not_available’ value. The other available option is ‘mode’ which
imputes the missing value using most frequent value in the training dataset.</p></li>
<li><p><strong>ordinal_features</strong> (<em>dictionary</em><em>, </em><em>default = None</em>) – When the data contains ordinal features, they must be encoded differently using
the ordinal_features param. If the data has a categorical variable with values
of ‘low’, ‘medium’, ‘high’ and it is known that low &lt; medium &lt; high, then it can
be passed as ordinal_features = { ‘column_name’ : [‘low’, ‘medium’, ‘high’] }.
The list sequence must be in increasing order from lowest to highest.</p></li>
<li><p><strong>high_cardinality_features</strong> (<em>string</em><em>, </em><em>default = None</em>) – When the data containts features with high cardinality, they can be compressed
into fewer levels by passing them as a list of column names with high cardinality.
Features are compressed using frequency distribution. As such original features
are replaced with the frequency distribution and converted into numeric variable.</p></li>
<li><p><strong>numeric_features</strong> (<em>string</em><em>, </em><em>default = None</em>) – If the inferred data types are not correct, numeric_features can be used to
overwrite the inferred type. If when running setup the type of ‘column1’ is
inferred as a categorical instead of numeric, then this parameter can be used
to overwrite by passing numeric_features = [‘column1’].</p></li>
<li><p><strong>numeric_imputation</strong> (<em>string</em><em>, </em><em>default = 'mean'</em>) – If missing values are found in numeric features, they will be imputed with the
mean value of the feature. The other available option is ‘median’ which imputes
the value using the median value in the training dataset.</p></li>
<li><p><strong>date_features</strong> (<em>string</em><em>, </em><em>default = None</em>) – If the data has a DateTime column that is not automatically detected when running
setup, this parameter can be used by passing date_features = ‘date_column_name’.
It can work with multiple date columns. Date columns are not used in modeling.
Instead, feature extraction is performed and date columns are dropped from the
dataset. If the date column includes a time stamp, features related to time will
also be extracted.</p></li>
<li><p><strong>ignore_features</strong> (<em>string</em><em>, </em><em>default = None</em>) – If any feature should be ignored for modeling, it can be passed to the param
ignore_features. The ID and DateTime columns when inferred, are automatically
set to ignore for modeling.</p></li>
<li><p><strong>normalize</strong> (<em>bool</em><em>, </em><em>default = False</em>) – When set to True, the feature space is transformed using the normalized_method
param. Generally, linear algorithms perform better with normalized data however,
the results may vary and it is advised to run multiple experiments to evaluate
the benefit of normalization.</p></li>
<li><p><strong>normalize_method</strong> (<em>string</em><em>, </em><em>default = 'zscore'</em>) – <p>Defines the method to be used for normalization. By default, normalize method
is set to ‘zscore’. The standard zscore is calculated as z = (x - u) / s. The
other available options are:</p>
<dl class="simple">
<dt>’minmax’<span class="classifier">scales and translates each feature individually such that it is in</span></dt><dd><p>the range of 0 - 1.</p>
</dd>
<dt>’maxabs’<span class="classifier">scales and translates each feature individually such that the maximal</span></dt><dd><p>absolute value of each feature will be 1.0. It does not shift/center
the data, and thus does not destroy any sparsity.</p>
</dd>
<dt>’robust’<span class="classifier">scales and translates each feature according to the Interquartile range.</span></dt><dd><p>When the dataset contains outliers, robust scaler often gives better
results.</p>
</dd>
</dl>
</p></li>
<li><p><strong>transformation</strong> (<em>bool</em><em>, </em><em>default = False</em>) – When set to True, a power transformation is applied to make the data more normal /
Gaussian-like. This is useful for modeling issues related to heteroscedasticity or
other situations where normality is desired. The optimal parameter for stabilizing
variance and minimizing skewness is estimated through maximum likelihood.</p></li>
<li><p><strong>transformation_method</strong> (<em>string</em><em>, </em><em>default = 'yeo-johnson'</em>) – Defines the method for transformation. By default, the transformation method is set
to ‘yeo-johnson’. The other available option is ‘quantile’ transformation. Both
the transformation transforms the feature set to follow a Gaussian-like or normal
distribution. Note that the quantile transformer is non-linear and may distort linear
correlations between variables measured at the same scale.</p></li>
<li><p><strong>handle_unknown_categorical</strong> (<em>bool</em><em>, </em><em>default = True</em>) – When set to True, unknown categorical levels in new / unseen data are replaced by
the most or least frequent level as learned in the training data. The method is
defined under the unknown_categorical_method param.</p></li>
<li><p><strong>unknown_categorical_method</strong> (<em>string</em><em>, </em><em>default = 'least_frequent'</em>) – Method used to replace unknown categorical levels in unseen data. Method can be
set to ‘least_frequent’ or ‘most_frequent’.</p></li>
<li><p><strong>pca</strong> (<em>bool</em><em>, </em><em>default = False</em>) – When set to True, dimensionality reduction is applied to project the data into
a lower dimensional space using the method defined in pca_method param. In
supervised learning pca is generally performed when dealing with high feature
space and memory is a constraint. Note that not all datasets can be decomposed
efficiently using a linear PCA technique and that applying PCA may result in loss
of information. As such, it is advised to run multiple experiments with different
pca_methods to evaluate the impact.</p></li>
<li><p><strong>pca_method</strong> (<em>string</em><em>, </em><em>default = 'linear'</em>) – <p>The ‘linear’ method performs Linear dimensionality reduction using Singular Value
Decomposition. The other available options are:</p>
<p>kernel      : dimensionality reduction through the use of RVF kernel.</p>
<dl class="simple">
<dt>incremental<span class="classifier">replacement for ‘linear’ pca when the dataset to be decomposed is</span></dt><dd><p>too large to fit in memory</p>
</dd>
</dl>
</p></li>
<li><p><strong>pca_components</strong> (<em>int/float</em><em>, </em><em>default = 0.99</em>) – <p>Number of components to keep. if pca_components is a float, it is treated as a
target percentage for information retention. When pca_components is an integer
it is treated as the number of features to be kept. pca_components must be strictly
less than the original number of features in the dataset.</p>
<p>ignore_low_variance: bool, default = False
When set to True, all categorical features with statistically insignificant variances
are removed from the dataset. The variance is calculated using the ratio of unique
values to the number of samples, and the ratio of the most common value to the
frequency of the second most common value.</p>
</p></li>
<li><p><strong>combine_rare_levels</strong> (<em>bool</em><em>, </em><em>default = False</em>) – <p>When set to True, all levels in categorical features below the threshold defined
in rare_level_threshold param are combined together as a single level. There must be
atleast two levels under the threshold for this to take effect. rare_level_threshold
represents the percentile distribution of level frequency. Generally, this technique
is applied to limit a sparse matrix caused by high numbers of levels in categorical
features.</p>
<p>rare_level_threshold: float, default = 0.1
Percentile distribution below which rare categories are combined. Only comes into
effect when combine_rare_levels is set to True.</p>
</p></li>
<li><p><strong>bin_numeric_features</strong> (<em>list</em><em>, </em><em>default = None</em>) – When a list of numeric features is passed they are transformed into categorical
features using KMeans, where values in each bin have the same nearest center of a
1D k-means cluster. The number of clusters are determined based on the ‘sturges’
method. It is only optimal for gaussian data and underestimates the number of bins
for large non-gaussian datasets.</p></li>
<li><p><strong>remove_multicollinearity</strong> (<em>bool</em><em>, </em><em>default = False</em>) – When set to True, the variables with inter-correlations higher than the threshold
defined under the multicollinearity_threshold param are dropped. When two features
are highly correlated with each other, the feature with higher average correlation
in the feature space is dropped.</p></li>
<li><p><strong>multicollinearity_threshold</strong> (<em>float</em><em>, </em><em>default = 0.9</em>) – Threshold used for dropping the correlated features. Only comes into effect when
remove_multicollinearity is set to True.</p></li>
<li><p><strong>group_features</strong> (<em>list</em><em> or </em><em>list of list</em><em>, </em><em>default = None</em>) – When a dataset contains features that have related characteristics, the group_features
param can be used for statistical feature extraction. For example, if a dataset has
numeric features that are related with each other (i.e ‘Col1’, ‘Col2’, ‘Col3’), a list
containing the column names can be passed under group_features to extract statistical
information such as the mean, median, mode and standard deviation.</p></li>
<li><p><strong>group_names</strong> (<em>list</em><em>, </em><em>default = None</em>) – When group_features is passed, a name of the group can be passed into the group_names
param as a list containing strings. The length of a group_names list must equal to the
length  of group_features. When the length doesn’t match or the name is not passed, new
features are sequentially named such as group_1, group_2 etc.</p></li>
<li><p><strong>supervised</strong> (<em>bool</em><em>, </em><em>default = False</em>) – When set to True, supervised_target column is ignored for transformation. This
param is only for internal use.</p></li>
<li><p><strong>supervised_target</strong> (<em>string</em><em>, </em><em>default = None</em>) – Name of supervised_target column that will be ignored for transformation. Only
applicable when tune_model() function is used. This param is only for internal use.</p></li>
<li><p><strong>n_jobs</strong> (<em>int</em><em>, </em><em>default = -1</em>) – The number of jobs to run in parallel (for functions that supports parallel
processing) -1 means using all processors. To run all functions on single processor
set n_jobs to None.</p></li>
<li><p><strong>html</strong> (<em>bool</em><em>, </em><em>default = True</em>) – If set to False, prevents runtime display of monitor. This must be set to False
when using environment that doesnt support HTML.</p></li>
<li><p><strong>session_id</strong> (<em>int</em><em>, </em><em>default = None</em>) – If None, a random seed is generated and returned in the Information grid. The
unique number is then distributed as a seed in all functions used during the
experiment. This can be used for later reproducibility of the entire experiment.</p></li>
<li><p><strong>log_experiment</strong> (<em>bool</em><em>, </em><em>default = True</em>) – When set to True, all metrics and parameters are logged on MLFlow server.</p></li>
<li><p><strong>experiment_name</strong> (<em>str</em><em>, </em><em>default = None</em>) – Name of experiment for logging. When set to None, ‘clf’ is by default used as
alias for the experiment name.</p></li>
<li><p><strong>log_plots</strong> (<em>bool</em><em>, </em><em>default = False</em>) – When set to True, specific plots are logged in MLflow as a png file. By default,
it is set to False.</p></li>
<li><p><strong>log_profile</strong> (<em>bool</em><em>, </em><em>default = False</em>) – When set to True, data profile is also logged on MLflow as a html file. By default,
it is set to False.</p></li>
<li><p><strong>silent</strong> (<em>bool</em><em>, </em><em>default = False</em>) – When set to True, confirmation of data types is not required. All preprocessing will
be performed assuming automatically inferred data types. Not recommended for direct use
except for established pipelines.</p></li>
<li><p><strong>verbose</strong> (<em>Boolean</em><em>, </em><em>default = True</em>) – Information grid is not printed when verbose is set to False.</p></li>
<li><p><strong>profile</strong> (<em>bool</em><em>, </em><em>default = False</em>) – If set to true, a data profile for Exploratory Data Analysis will be displayed
in an interactive HTML report.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><em>info_grid</em> – Information grid is printed.</p></li>
<li><p><em>environment</em> – This function returns various outputs that are stored in variable
as tuple. They are used by other functions in pycaret.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pycaret.anomaly.tune_model">
<code class="sig-prename descclassname">pycaret.anomaly.</code><code class="sig-name descname">tune_model</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">model</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">supervised_target</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">method</span><span class="o">=</span><span class="default_value">'drop'</span></em>, <em class="sig-param"><span class="n">estimator</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">optimize</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">custom_grid</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">fold</span><span class="o">=</span><span class="default_value">10</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.anomaly.tune_model" title="Permalink to this definition">¶</a></dt>
<dd><p>This function tunes the fraction parameter using a predefined grid with
the objective of optimizing a supervised learning metric as defined in
the optimize param. You can choose the supervised estimator from a large
library available in pycaret. By default, supervised estimator is Linear.</p>
<p>This function returns the tuned model object.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pycaret.datasets</span> <span class="kn">import</span> <span class="n">get_data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">boston</span> <span class="o">=</span> <span class="n">get_data</span><span class="p">(</span><span class="s1">&#39;boston&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">experiment_name</span> <span class="o">=</span> <span class="n">setup</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">boston</span><span class="p">,</span> <span class="n">normalize</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tuned_knn</span> <span class="o">=</span> <span class="n">tune_model</span><span class="p">(</span><span class="n">model</span> <span class="o">=</span> <span class="s1">&#39;knn&#39;</span><span class="p">,</span> <span class="n">supervised_target</span> <span class="o">=</span> <span class="s1">&#39;medv&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>This will return tuned k-Nearest Neighbors model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>string</em><em>, </em><em>default = None</em>) – <p>Enter ID of the models available in model library:</p>
<p>ID          Model
——-     ———
‘abod’      Angle-base Outlier Detection
‘cluster’   Clustering-Based Local Outlier
‘cof’       Connectivity-Based Outlier Factor
‘histogram’ Histogram-based Outlier Detection
‘knn’       k-Nearest Neighbors Detector
‘lof’       Local Outlier Factor
‘svm’       One-class SVM detector
‘pca’       Principal Component Analysis
‘mcd’       Minimum Covariance Determinant
‘sod’       Subspace Outlier Detection
‘sos’       Stochastic Outlier Selection</p>
</p></li>
<li><p><strong>supervised_target</strong> (<em>string</em>) – Name of the target column for supervised learning.</p></li>
<li><p><strong>method</strong> (<em>string</em><em>, </em><em>default = 'drop'</em>) – When method set to drop, it will drop the outlier rows from training dataset
of supervised estimator, when method set to ‘surrogate’, it will use the
decision function and label as a feature without dropping the outliers from
training dataset.</p></li>
<li><p><strong>estimator</strong> (<em>string</em><em>, </em><em>default = None</em>) – <p>ID          Name                            Task
——–    ———-                      ———-
‘lr’        Logistic Regression             Classification
‘knn’       K Nearest Neighbour             Classification
‘nb’        Naive Bayes                     Classification
‘dt’        Decision Tree Classifier        Classification
‘svm’       SVM - Linear Kernel             Classification
‘rbfsvm’    SVM - Radial Kernel             Classification
‘gpc’       Gaussian Process Classifier     Classification
‘mlp’       Multi Level Perceptron          Classification
‘ridge’     Ridge Classifier                Classification
‘rf’        Random Forest Classifier        Classification
‘qda’       Quadratic Discriminant Analysis Classification
‘ada’       Ada Boost Classifier            Classification
‘gbc’       Gradient Boosting Classifier    Classification
‘lda’       Linear Discriminant Analysis    Classification
‘et’        Extra Trees Classifier          Classification
‘xgboost’   Extreme Gradient Boosting       Classification
‘lightgbm’  Light Gradient Boosting         Classification
‘catboost’  CatBoost Classifier             Classification
‘lr’        Linear Regression               Regression
‘lasso’     Lasso Regression                Regression
‘ridge’     Ridge Regression                Regression
‘en’        Elastic Net                     Regression
‘lar’       Least Angle Regression          Regression
‘llar’      Lasso Least Angle Regression    Regression
‘omp’       Orthogonal Matching Pursuit     Regression
‘br’        Bayesian Ridge                  Regression
‘ard’       Automatic Relevance Determ.     Regression
‘par’       Passive Aggressive Regressor    Regression
‘ransac’    Random Sample Consensus         Regression
‘tr’        TheilSen Regressor              Regression
‘huber’     Huber Regressor                 Regression
‘kr’        Kernel Ridge                    Regression
‘svm’       Support Vector Machine          Regression
‘knn’       K Neighbors Regressor           Regression
‘dt’        Decision Tree                   Regression
‘rf’        Random Forest                   Regression
‘et’        Extra Trees Regressor           Regression
‘ada’       AdaBoost Regressor              Regression
‘gbr’       Gradient Boosting               Regression
‘mlp’       Multi Level Perceptron          Regression
‘xgboost’   Extreme Gradient Boosting       Regression
‘lightgbm’  Light Gradient Boosting         Regression
‘catboost’  CatBoost Regressor              Regression</p>
<p>If set to None, Linear model is used by default for both classification
and regression tasks.</p>
</p></li>
<li><p><strong>optimize</strong> (<em>string</em><em>, </em><em>default = None</em>) – <dl class="simple">
<dt>For Classification tasks:</dt><dd><p>Accuracy, AUC, Recall, Precision, F1, Kappa</p>
</dd>
<dt>For Regression tasks:</dt><dd><p>MAE, MSE, RMSE, R2, RMSLE, MAPE</p>
</dd>
</dl>
<p>If set to None, default is ‘Accuracy’ for classification and ‘R2’ for
regression tasks.</p>
</p></li>
<li><p><strong>custom_grid</strong> (<em>list</em><em>, </em><em>default = None</em>) – By default, a pre-defined list of fraction values is iterated over to
optimize the supervised objective. To overwrite default iteration,
pass a list of fraction value to iterate over in custom_grid param.</p></li>
<li><p><strong>fold</strong> (<em>integer</em><em>, </em><em>default = 10</em>) – Number of folds to be used in Kfold CV. Must be at least 2.</p></li>
<li><p><strong>verbose</strong> (<em>Boolean</em><em>, </em><em>default = True</em>) – Status update is not printed when verbose is set to False.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><em>Visual_Plot</em> – Visual plot with fraction param on x-axis with metric to
optimize on y-axis. Also, prints the best model metric.</p></li>
<li><p><em>model</em> – trained model object with best fraction param.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-pycaret.datasets">
<span id="datasets"></span><h1>Datasets<a class="headerlink" href="#module-pycaret.datasets" title="Permalink to this headline">¶</a></h1>
<dl class="py function">
<dt id="pycaret.datasets.get_data">
<code class="sig-prename descclassname">pycaret.datasets.</code><code class="sig-name descname">get_data</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">dataset</span></em>, <em class="sig-param"><span class="n">save_copy</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">profile</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.datasets.get_data" title="Permalink to this definition">¶</a></dt>
<dd><p>This function loads sample datasets that are available in the pycaret git
repository. The full list of available datasets and their descriptions can
be viewed by calling index.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">get_data</span><span class="p">(</span><span class="s1">&#39;index&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>This will display the list of available datasets that can be loaded
using the get_data() function. For example, to load the credit dataset:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">credit</span> <span class="o">=</span> <span class="n">get_data</span><span class="p">(</span><span class="s1">&#39;credit&#39;</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dataset</strong> (<em>string</em>) – Index value of dataset</p></li>
<li><p><strong>save_copy</strong> (<em>bool</em><em>, </em><em>default = False</em>) – When set to true, it saves a copy of the dataset to your local active directory.</p></li>
<li><p><strong>profile</strong> (<em>bool</em><em>, </em><em>default = False</em>) – If set to true, a data profile for Exploratory Data Analysis will be displayed
in an interactive HTML report.</p></li>
<li><p><strong>verbose</strong> (<em>bool</em><em>, </em><em>default = True</em>) – When set to False, head of data is not displayed.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Pandas dataframe is returned.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>pandas.DataFrame</p>
</dd>
</dl>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<ul class="simple">
<li><p>Use of get_data() requires internet connection.</p></li>
</ul>
</div>
</dd></dl>

</div>
<div class="section" id="module-pycaret.arules">
<span id="arules"></span><h1>Arules<a class="headerlink" href="#module-pycaret.arules" title="Permalink to this headline">¶</a></h1>
<dl class="py function">
<dt id="pycaret.arules.create_model">
<code class="sig-prename descclassname">pycaret.arules.</code><code class="sig-name descname">create_model</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">metric</span><span class="o">=</span><span class="default_value">'confidence'</span></em>, <em class="sig-param"><span class="n">threshold</span><span class="o">=</span><span class="default_value">0.5</span></em>, <em class="sig-param"><span class="n">min_support</span><span class="o">=</span><span class="default_value">0.05</span></em>, <em class="sig-param"><span class="n">round</span><span class="o">=</span><span class="default_value">4</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.arules.create_model" title="Permalink to this definition">¶</a></dt>
<dd><p>This function creates an association rules model using data and identifiers
passed at setup stage. This function internally transforms the data for
association rule mining.</p>
<p>setup() function must be called before using create_model()</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pycaret.datasets</span> <span class="kn">import</span> <span class="n">get_data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">france</span> <span class="o">=</span> <span class="n">get_data</span><span class="p">(</span><span class="s1">&#39;france&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">experiment_name</span> <span class="o">=</span> <span class="n">setup</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="p">,</span> <span class="n">transaction_id</span> <span class="o">=</span> <span class="s1">&#39;InvoiceNo&#39;</span><span class="p">,</span> <span class="n">item_id</span> <span class="o">=</span> <span class="s1">&#39;ProductName&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>This will return dataframe containing rules sorted by metric param.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>metric</strong> (<em>string</em><em>, </em><em>default = 'confidence'</em>) – <p>Metric to evaluate if a rule is of interest. Default is set to confidence.
Other available metrics include ‘support’, ‘lift’, ‘leverage’, ‘conviction’.
These metrics are computed as follows:</p>
<ul>
<li><p>support(A-&gt;C) = support(A+C) [aka ‘support’], range: [0, 1]</p></li>
<li><p>confidence(A-&gt;C) = support(A+C) / support(A), range: [0, 1]</p></li>
<li><p>lift(A-&gt;C) = confidence(A-&gt;C) / support(C), range: [0, inf]</p></li>
<li><p>leverage(A-&gt;C) = support(A-&gt;C) - support(A)*support(C), range: [-1, 1]</p></li>
<li><p>conviction = [1 - support(C)] / [1 - confidence(A-&gt;C)], range: [0, inf]</p></li>
</ul>
</p></li>
<li><p><strong>threshold</strong> (<em>float</em><em>, </em><em>default = 0.5</em>) – Minimal threshold for the evaluation metric, via the <cite>metric</cite> parameter,
to decide whether a candidate rule is of interest.</p></li>
<li><p><strong>min_support</strong> (<em>float</em><em>, </em><em>default = 0.05</em>) – A float between 0 and 1 for minumum support of the itemsets returned.
The support is computed as the fraction <cite>transactions_where_item(s)_occur /
total_transactions</cite>.</p></li>
<li><p><strong>round</strong> (<em>integer</em><em>, </em><em>default = 4</em>) – Number of decimal places metrics in score grid will be rounded to.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Dataframe containing rules of interest with all metrics
including antecedents, consequents, antecedent support,
consequent support, support, confidence, lift, leverage,
conviction.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>pandas.DataFrame</p>
</dd>
</dl>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<ul class="simple">
<li><p>Setting low values for min_support may increase training time.</p></li>
</ul>
</div>
</dd></dl>

<dl class="py function">
<dt id="pycaret.arules.get_rules">
<code class="sig-prename descclassname">pycaret.arules.</code><code class="sig-name descname">get_rules</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">transaction_id</span></em>, <em class="sig-param"><span class="n">item_id</span></em>, <em class="sig-param"><span class="n">ignore_items</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">metric</span><span class="o">=</span><span class="default_value">'confidence'</span></em>, <em class="sig-param"><span class="n">threshold</span><span class="o">=</span><span class="default_value">0.5</span></em>, <em class="sig-param"><span class="n">min_support</span><span class="o">=</span><span class="default_value">0.05</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.arules.get_rules" title="Permalink to this definition">¶</a></dt>
<dd><p>Magic function to get Association Rules in Power Query / Power BI.</p>
</dd></dl>

<dl class="py function">
<dt id="pycaret.arules.plot_model">
<code class="sig-prename descclassname">pycaret.arules.</code><code class="sig-name descname">plot_model</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">model</span></em>, <em class="sig-param"><span class="n">plot</span><span class="o">=</span><span class="default_value">'2d'</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.arules.plot_model" title="Permalink to this definition">¶</a></dt>
<dd><p>This function takes a model dataframe returned by create_model() function.
‘2d’ and ‘3d’ plots are available.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">rule1</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">(</span><span class="n">metric</span><span class="o">=</span><span class="s1">&#39;confidence&#39;</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">min_support</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">plot_model</span><span class="p">(</span><span class="n">rule1</span><span class="p">,</span> <span class="n">plot</span><span class="o">=</span><span class="s1">&#39;2d&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">plot_model</span><span class="p">(</span><span class="n">rule1</span><span class="p">,</span> <span class="n">plot</span><span class="o">=</span><span class="s1">&#39;3d&#39;</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>DataFrame</em><em>, </em><em>default = none</em>) – DataFrame returned by trained model using create_model().</p></li>
<li><p><strong>plot</strong> (<em>string</em><em>, </em><em>default = '2d'</em>) – <p>Enter abbreviation of type of plot. The current list of plots supported are:</p>
<p>Name                                 Abbreviated String
———                            ——————
Support, Confidence and Lift (2d)    ‘2d’
Support, Confidence and Lift (3d)    ‘3d’</p>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Prints the visual plot.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Visual_Plot</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pycaret.arules.setup">
<code class="sig-prename descclassname">pycaret.arules.</code><code class="sig-name descname">setup</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">transaction_id</span></em>, <em class="sig-param"><span class="n">item_id</span></em>, <em class="sig-param"><span class="n">ignore_items</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">session_id</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.arules.setup" title="Permalink to this definition">¶</a></dt>
<dd><p>This function initializes the environment in pycaret. setup() must called before
executing any other function in pycaret. It takes three mandatory parameters:
(i) dataframe {array-like, sparse matrix}, (ii) transaction_id param identifying
basket and (iii) item_id param used to create rules. These three params are
normally found in any transactional dataset. pycaret will internally convert the
dataframe into a sparse matrix which is required for association rules mining.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pycaret.datasets</span> <span class="kn">import</span> <span class="n">get_data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">france</span> <span class="o">=</span> <span class="n">get_data</span><span class="p">(</span><span class="s1">&#39;france&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">experiment_name</span> <span class="o">=</span> <span class="n">setup</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="p">,</span> <span class="n">transaction_id</span> <span class="o">=</span> <span class="s1">&#39;InvoiceNo&#39;</span><span class="p">,</span> <span class="n">item_id</span> <span class="o">=</span> <span class="s1">&#39;ProductName&#39;</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<em>{array-like</em><em>, </em><em>sparse matrix}</em>) – Shape (n_samples, n_features) where n_samples is the number of samples and n_features is the number of features.</p></li>
<li><p><strong>transaction_id</strong> (<em>string</em>) – Name of column representing transaction id. This will be used to pivot the matrix.</p></li>
<li><p><strong>item_id</strong> (<em>string</em>) – Name of column used for creation of rules. Normally, this will be the variable of
interest.</p></li>
<li><p><strong>ignore_items</strong> (<em>list</em><em>, </em><em>default = None</em>) – List of strings to be ignored when considering rule mining.</p></li>
<li><p><strong>session_id</strong> (<em>int</em><em>, </em><em>default = None</em>) – If None, a random seed is generated and returned in the Information grid. The
unique number is then distributed as a seed in all functions used during the
experiment. This can be used for later reproducibility of the entire experiment.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><em>info_grid</em> – Information grid is printed.</p></li>
<li><p><em>environment</em> – This function returns various outputs that are stored in variable
as tuple. They are used by other functions in pycaret.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="indices-and-tables">
<h1>Indices and tables<a class="headerlink" href="#indices-and-tables" title="Permalink to this headline">¶</a></h1>
<ul class="simple">
<li><p><a class="reference internal" href="genindex.html"><span class="std std-ref">Index</span></a></p></li>
<li><p><a class="reference internal" href="py-modindex.html"><span class="std std-ref">Module Index</span></a></p></li>
<li><p><a class="reference internal" href="search.html"><span class="std std-ref">Search Page</span></a></p></li>
</ul>
</div>


           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        
        &copy; Copyright 2020, Moez Ali

    </p>
  </div>
    
    
    
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>