

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Welcome to pycaret’s documentation! &mdash; pycaret 1.0.1 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/language_data.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="#" class="icon icon-home"> pycaret
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <!-- Local TOC -->
              <div class="local-toc"><ul>
<li><a class="reference internal" href="#">Welcome to pycaret’s documentation!</a></li>
<li><a class="reference internal" href="#module-pycaret.regression">Regression</a></li>
<li><a class="reference internal" href="#module-pycaret.nlp">NLP</a></li>
<li><a class="reference internal" href="#module-pycaret.preprocess">Preprocess</a></li>
<li><a class="reference internal" href="#module-pycaret.datasets">Datasets</a></li>
<li><a class="reference internal" href="#clustering">Clustering</a></li>
<li><a class="reference internal" href="#classification">Classification</a></li>
<li><a class="reference internal" href="#module-pycaret.arules">Arules</a></li>
<li><a class="reference internal" href="#module-pycaret.anomaly">Anomaly</a></li>
<li><a class="reference internal" href="#indices-and-tables">Indices and tables</a></li>
</ul>
</div>
            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="#">pycaret</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="#">Docs</a> &raquo;</li>
        
      <li>Welcome to pycaret’s documentation!</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/index.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="welcome-to-pycaret-s-documentation">
<h1>Welcome to pycaret’s documentation!<a class="headerlink" href="#welcome-to-pycaret-s-documentation" title="Permalink to this headline">¶</a></h1>
<p>PyCaret is an open source low-code machine learning library in Python that aims to reduce the hypothesis to insights cycle time in a ML experiment. It enables data scientists to perform end-to-end experiments quickly and efficiently. In comparison with the other open source machine learning libraries, PyCaret is an alternate low-code library that can be used to perform complex machine learning tasks with only few lines of code. PyCaret is essentially a Python wrapper around several machine learning libraries and frameworks such as scikit-learn, XGBoost, Microsoft LightGBM, spaCy and many more.</p>
<p>The design and simplicity of PyCaret is inspired by the emerging role of citizen data scientists, a term first used by Gartner. Citizen Data Scientists are power users who can perform both simple and moderately sophisticated analytical tasks that would previously have required more expertise. Seasoned data scientists are often difficult to find and expensive to hire but citizen data scientists can be an effective way to mitigate this gap and address data related challenges in business setting.</p>
<p>PyCaret is simple, easy to use and deployment ready. All the steps performed in a ML experiment can be reproduced using a pipeline that is automatically developed and orchestrated in PyCaret as you progress through the experiment. A pipeline can be saved in a binary file format that is transferable across environments.</p>
<p>For more information on PyCaret, please visit our official website <a class="reference external" href="https://www.pycaret.org">https://www.pycaret.org</a></p>
<div class="toctree-wrapper compound">
</div>
</div>
<div class="section" id="module-pycaret.regression">
<span id="regression"></span><h1>Regression<a class="headerlink" href="#module-pycaret.regression" title="Permalink to this headline">¶</a></h1>
<dl class="py function">
<dt id="pycaret.regression.automl">
<code class="sig-prename descclassname">pycaret.regression.</code><code class="sig-name descname">automl</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">optimize</span><span class="o">=</span><span class="default_value">'r2'</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.regression.automl" title="Permalink to this definition">¶</a></dt>
<dd><p>space reserved for docstring</p>
</dd></dl>

<dl class="py function">
<dt id="pycaret.regression.blend_models">
<code class="sig-prename descclassname">pycaret.regression.</code><code class="sig-name descname">blend_models</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">estimator_list</span><span class="o">=</span><span class="default_value">'All'</span></em>, <em class="sig-param"><span class="n">fold</span><span class="o">=</span><span class="default_value">10</span></em>, <em class="sig-param"><span class="n">round</span><span class="o">=</span><span class="default_value">4</span></em>, <em class="sig-param"><span class="n">turbo</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">improve_only</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">optimize</span><span class="o">=</span><span class="default_value">'r2'</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.regression.blend_models" title="Permalink to this definition">¶</a></dt>
<dd><p>This function creates an ensemble meta-estimator that fits a base regressor on
the whole dataset. It then averages the predictions to form a final prediction.
By default, this function will use all estimators in the model library (excl.
the few estimators when turbo is True) or a specific trained estimator passed
as a list in estimator_list param. It scores it using Kfold Cross Validation.
The output prints the score grid that shows MAE, MSE, RMSE, R2, RMSLE and MAPE
by fold (default = 10 Fold).</p>
<p>This function returns a trained model object.</p>
<blockquote>
<div><p>from pycaret.datasets import get_data
boston = get_data(‘boston’)
experiment_name = setup(data = boston,  target = ‘medv’)</p>
<p>blend_all = blend_models()</p>
<p>This will result in VotingRegressor for all models in the library except ‘ard’,
‘kr’ and ‘mlp’.</p>
<p>For specific models, you can use:</p>
<p>lr = create_model(‘lr’)
rf = create_model(‘rf’)
knn = create_model(‘knn’)</p>
<p>blend_three = blend_models(estimator_list = [lr,rf,knn])</p>
<p>This will create a VotingRegressor of lr, rf and knn.</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>estimator_list</strong> (<em>string</em><em> (</em><em>'All'</em><em>) or </em><em>list of object</em><em>, </em><em>default = 'All'</em>) – </p></li>
<li><p><strong>fold</strong> (<em>integer</em><em>, </em><em>default = 10</em>) – </p></li>
<li><p><strong>of folds to be used in Kfold CV. Must be at least 2.</strong> (<em>Number</em>) – </p></li>
<li><p><strong>round</strong> (<em>integer</em><em>, </em><em>default = 4</em>) – </p></li>
<li><p><strong>of decimal places the metrics in the score grid will be rounded to.</strong> (<em>Number</em>) – </p></li>
<li><p><strong>turbo</strong> (<em>Boolean</em><em>, </em><em>default = True</em>) – </p></li>
<li><p><strong>turbo is set to True</strong><strong>, </strong><strong>it blacklists estimator that uses Radial Kernel.</strong> (<em>When</em>) – </p></li>
<li><p><strong>improve_only</strong> (<em>Boolean</em><em>, </em><em>default = True</em>) – </p></li>
<li><p><strong>set to True</strong><strong>, </strong><strong>base estimator is returned when the metric doesn't</strong> (<em>When</em>) – </p></li>
<li><p><strong>by ensemble_model. This gurantees the returned object would perform</strong> (<em>improve</em>) – </p></li>
<li><p><strong>equivalent to base estimator created using create_model</strong><strong> or </strong><strong>model</strong> (<em>atleast</em>) – </p></li>
<li><p><strong>by compare_models.</strong> (<em>returned</em>) – </p></li>
<li><p><strong>optimize</strong> (<em>string</em><em>, </em><em>default = 'r2'</em>) – </p></li>
<li><p><strong>used when improve_only is set to True. optimize parameter is used</strong> (<em>Only</em>) – </p></li>
<li><p><strong>compare emsembled model with base estimator. Values accepted in</strong> (<em>to</em>) – </p></li>
<li><p><strong>parameter are 'mae'</strong><strong>, </strong><strong>'mse'</strong><strong>, </strong><strong>'rmse'</strong><strong>, </strong><strong>'r2'</strong><strong>, </strong><strong>'rmsle'</strong><strong>, </strong><strong>'mape'.</strong> (<em>optimize</em>) – </p></li>
<li><p><strong>verbose</strong> (<em>Boolean</em><em>, </em><em>default = True</em>) – </p></li>
<li><p><strong>grid is not printed when verbose is set to False.</strong> (<em>Score</em>) – </p></li>
<li><p><strong>Returns</strong> – </p></li>
<li><p><strong>--------</strong> – </p></li>
<li><p><strong>grid</strong> (<em>score</em>) – </p></li>
<li><p><strong>Scoring metrics used are MAE</strong><strong>, </strong><strong>MSE</strong><strong>, </strong><strong>RMSE</strong><strong>, </strong><strong>R2</strong><strong>, </strong><strong>RMSLE and MAPE.</strong> (<em>-----------</em>) – Mean and standard deviation of the scores across the folds are
also returned.</p></li>
<li><p><strong>model</strong> (<em>trained Voting Regressor model object.</em>) – </p></li>
<li><p><strong>-----------</strong> – </p></li>
<li><p><strong>Warnings</strong> – </p></li>
<li><p><strong>---------</strong> – </p></li>
<li><p><strong>None</strong> – </p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pycaret.regression.compare_models">
<code class="sig-prename descclassname">pycaret.regression.</code><code class="sig-name descname">compare_models</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">blacklist</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">fold</span><span class="o">=</span><span class="default_value">10</span></em>, <em class="sig-param"><span class="n">round</span><span class="o">=</span><span class="default_value">4</span></em>, <em class="sig-param"><span class="n">sort</span><span class="o">=</span><span class="default_value">'R2'</span></em>, <em class="sig-param"><span class="n">n_select</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">turbo</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.regression.compare_models" title="Permalink to this definition">¶</a></dt>
<dd><p>This function uses all models in the model library and scores them using
Kfold Cross Validation. The output prints a score grid that shows MAE, MSE,
RMSE, R2, RMSLE and MAPE by fold (default CV = 10 Folds) of all the available
models in model library.</p>
<p>When turbo is set to True (‘kr’, ‘ard’ and ‘mlp’) are excluded due to longer
training times. By default turbo param is set to True.</p>
<p>List of models in Model Library</p>
<p>Estimator                     Abbreviated String     Original Implementation
———                     ——————     ———————–
Linear Regression             ‘lr’                   linear_model.LinearRegression
Lasso Regression              ‘lasso’                linear_model.Lasso
Ridge Regression              ‘ridge’                linear_model.Ridge
Elastic Net                   ‘en’                   linear_model.ElasticNet
Least Angle Regression        ‘lar’                  linear_model.Lars
Lasso Least Angle Regression  ‘llar’                 linear_model.LassoLars
Orthogonal Matching Pursuit   ‘omp’                  linear_model.OMP
Bayesian Ridge                ‘br’                   linear_model.BayesianRidge
Automatic Relevance Determ.   ‘ard’                  linear_model.ARDRegression
Passive Aggressive Regressor  ‘par’                  linear_model.PAR
Random Sample Consensus       ‘ransac’               linear_model.RANSACRegressor
TheilSen Regressor            ‘tr’                   linear_model.TheilSenRegressor
Huber Regressor               ‘huber’                linear_model.HuberRegressor
Kernel Ridge                  ‘kr’                   kernel_ridge.KernelRidge
Support Vector Machine        ‘svm’                  svm.SVR
K Neighbors Regressor         ‘knn’                  neighbors.KNeighborsRegressor
Decision Tree                 ‘dt’                   tree.DecisionTreeRegressor
Random Forest                 ‘rf’                   ensemble.RandomForestRegressor
Extra Trees Regressor         ‘et’                   ensemble.ExtraTreesRegressor
AdaBoost Regressor            ‘ada’                  ensemble.AdaBoostRegressor
Gradient Boosting             ‘gbr’                  ensemble.GradientBoostingRegressor
Multi Level Perceptron        ‘mlp’                  neural_network.MLPRegressor
Extreme Gradient Boosting     ‘xgboost’              xgboost.readthedocs.io
Light Gradient Boosting       ‘lightgbm’             github.com/microsoft/LightGBM
CatBoost Regressor            ‘catboost’             <a class="reference external" href="https://catboost.ai">https://catboost.ai</a></p>
<blockquote>
<div><p>from pycaret.datasets import get_data
boston = get_data(‘boston’)
experiment_name = setup(data = boston,  target = ‘medv’)</p>
<p>compare_models()</p>
<p>This will return the averaged score grid of all models except ‘kr’, ‘ard’
and ‘mlp’. When turbo param is set to False, all models including ‘kr’,
‘ard’ and ‘mlp’ are used, but this may result in longer training times.</p>
<p>compare_models(blacklist = [‘knn’,’gbr’], turbo = False)</p>
<p>This will return a comparison of all models except K Nearest Neighbour and
Gradient Boosting Regressor.</p>
<p>compare_models(blacklist = [‘knn’,’gbr’] , turbo = True)</p>
<p>This will return a comparison of all models except K Nearest Neighbour,
Gradient Boosting Regressor, Kernel Ridge Regressor, Automatic Relevance
Determinant and Multi Level Perceptron.</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>blacklist</strong> (<em>string</em><em>, </em><em>default = None</em>) – </p></li>
<li><p><strong>order to omit certain models from the comparison</strong><strong>, </strong><strong>the abbreviation string</strong> (<em>In</em>) – </p></li>
<li><p><strong>above list</strong><strong>) </strong><strong>can be passed as list in blacklist param. This is normally</strong> (<em>(</em><em>see</em>) – </p></li>
<li><p><strong>to be more efficient with time.</strong> (<em>done</em>) – </p></li>
<li><p><strong>fold</strong> (<em>integer</em><em>, </em><em>default = 10</em>) – </p></li>
<li><p><strong>of folds to be used in Kfold CV. Must be at least 2.</strong> (<em>Number</em>) – </p></li>
<li><p><strong>round</strong> (<em>integer</em><em>, </em><em>default = 4</em>) – </p></li>
<li><p><strong>of decimal places the metrics in the score grid will be rounded to.</strong> (<em>Number</em>) – </p></li>
<li><p><strong>sort</strong> (<em>string</em><em>, </em><em>default = 'MAE'</em>) – </p></li>
<li><p><strong>scoring measure specified is used for sorting the average score grid</strong> (<em>The</em>) – </p></li>
<li><p><strong>options are 'MAE'</strong><strong>, </strong><strong>'MSE'</strong><strong>, </strong><strong>'RMSE'</strong><strong>, </strong><strong>'R2'</strong><strong>, </strong><strong>'RMSLE' and 'MAPE'.</strong> (<em>Other</em>) – </p></li>
<li><p><strong>n_select</strong> (<em>int</em><em>, </em><em>default = 3</em>) – </p></li>
<li><p><strong>of top_n models to return. use negative argument for bottom selection.</strong> (<em>Number</em>) – </p></li>
<li><p><strong>example</strong><strong>, </strong><strong>n_select = -3 means bottom 3 models.</strong> (<em>for</em>) – </p></li>
<li><p><strong>turbo</strong> (<em>Boolean</em><em>, </em><em>default = True</em>) – </p></li>
<li><p><strong>turbo is set to True</strong><strong>, </strong><strong>it blacklists estimators that have longer</strong> (<em>When</em>) – </p></li>
<li><p><strong>times.</strong> (<em>training</em>) – </p></li>
<li><p><strong>verbose</strong> (<em>Boolean</em><em>, </em><em>default = True</em>) – </p></li>
<li><p><strong>grid is not printed when verbose is set to False.</strong> (<em>Score</em>) – </p></li>
<li><p><strong>Returns</strong> – </p></li>
<li><p><strong>--------</strong> – </p></li>
<li><p><strong>grid</strong> (<em>score</em>) – </p></li>
<li><p><strong>Scoring metrics used are MAE</strong><strong>, </strong><strong>MSE</strong><strong>, </strong><strong>RMSE</strong><strong>, </strong><strong>R2</strong><strong>, </strong><strong>RMSLE and MAPE</strong> (<em>-----------</em>) – Mean and standard deviation of the scores across the folds is
also returned.</p></li>
<li><p><strong>Warnings</strong> – </p></li>
<li><p><strong>---------</strong> – </p></li>
<li><p><strong>compare_models</strong><strong>(</strong><strong>) </strong><strong>though attractive</strong><strong>, </strong><strong>might be time consuming with large</strong> (<em>-</em>) – datasets. By default turbo is set to True, which blacklists models that
have longer training times. Changing turbo parameter to False may result
in very high training times with datasets where number of samples exceed
10,000.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pycaret.regression.create_model">
<code class="sig-prename descclassname">pycaret.regression.</code><code class="sig-name descname">create_model</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">estimator</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">ensemble</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">method</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">fold</span><span class="o">=</span><span class="default_value">10</span></em>, <em class="sig-param"><span class="n">round</span><span class="o">=</span><span class="default_value">4</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.regression.create_model" title="Permalink to this definition">¶</a></dt>
<dd><p>This function creates a model and scores it using Kfold Cross Validation.
(default = 10 Fold). The output prints a score grid that shows MAE, MSE,
RMSE, RMSLE, R2 and MAPE.</p>
<p>This function returns a trained model object.</p>
<p>setup() function must be called before using create_model()</p>
<blockquote>
<div><p>from pycaret.datasets import get_data
boston = get_data(‘boston’)
experiment_name = setup(data = boston,  target = ‘medv’)</p>
<p>lr = create_model(‘lr’)</p>
<p>This will create a trained Linear Regression model.</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>estimator</strong> (<em>string</em><em>, </em><em>default = None</em>) – </p></li>
<li><p><strong>abbreviated string of the estimator class. List of estimators supported</strong> (<em>Enter</em>) – </p></li>
<li><p><strong>Abbreviated String     Original Implementation</strong> (<em>Estimator</em>) – </p></li>
<li><p><strong>------------------     -----------------------</strong> (<em>---------</em>) – </p></li>
<li><p><strong>Regression             'lr'                   linear_model.LinearRegression</strong> (<em>Linear</em>) – </p></li>
<li><p><strong>Regression              'lasso'                linear_model.Lasso</strong> (<em>Lasso</em>) – </p></li>
<li><p><strong>Regression              'ridge'                linear_model.Ridge</strong> (<em>Ridge</em>) – </p></li>
<li><p><strong>Net                   'en'                   linear_model.ElasticNet</strong> (<em>Elastic</em>) – </p></li>
<li><p><strong>Angle Regression        'lar'                  linear_model.Lars</strong> (<em>Least</em>) – </p></li>
<li><p><strong>Least Angle Regression  'llar'                 linear_model.LassoLars</strong> (<em>Lasso</em>) – </p></li>
<li><p><strong>Matching Pursuit   'omp'                  linear_model.OMP</strong> (<em>Orthogonal</em>) – </p></li>
<li><p><strong>Ridge                'br'                   linear_model.BayesianRidge</strong> (<em>Bayesian</em>) – </p></li>
<li><p><strong>Relevance Determ.   'ard'                  linear_model.ARDRegression</strong> (<em>Automatic</em>) – </p></li>
<li><p><strong>Aggressive Regressor  'par'                  linear_model.PAR</strong> (<em>Passive</em>) – </p></li>
<li><p><strong>Sample Consensus       'ransac'               linear_model.RANSACRegressor</strong> (<em>Random</em>) – </p></li>
<li><p><strong>Regressor            'tr'                   linear_model.TheilSenRegressor</strong> (<em>TheilSen</em>) – </p></li>
<li><p><strong>Regressor               'huber'                linear_model.HuberRegressor</strong> (<em>Huber</em>) – </p></li>
<li><p><strong>Ridge                  'kr'                   kernel_ridge.KernelRidge</strong> (<em>Kernel</em>) – </p></li>
<li><p><strong>Vector Machine        'svm'                  svm.SVR</strong> (<em>Support</em>) – </p></li>
<li><p><strong>Neighbors Regressor         'knn'                  neighbors.KNeighborsRegressor</strong> (<em>K</em>) – </p></li>
<li><p><strong>Tree                 'dt'                   tree.DecisionTreeRegressor</strong> (<em>Decision</em>) – </p></li>
<li><p><strong>Forest                 'rf'                   ensemble.RandomForestRegressor</strong> (<em>Random</em>) – </p></li>
<li><p><strong>Trees Regressor         'et'                   ensemble.ExtraTreesRegressor</strong> (<em>Extra</em>) – </p></li>
<li><p><strong>Regressor            'ada'                  ensemble.AdaBoostRegressor</strong> (<em>AdaBoost</em>) – </p></li>
<li><p><strong>Boosting             'gbr'                  ensemble.GradientBoostingRegressor</strong> (<em>Gradient</em>) – </p></li>
<li><p><strong>Level Perceptron        'mlp'                  neural_network.MLPRegressor</strong> (<em>Multi</em>) – </p></li>
<li><p><strong>Gradient Boosting     'xgboost'              xgboost.readthedocs.io</strong> (<em>Extreme</em>) – </p></li>
<li><p><strong>Gradient Boosting       'lightgbm'             github.com/microsoft/LightGBM</strong> (<em>Light</em>) – </p></li>
<li><p><strong>Regressor            'catboost'             https</strong> (<em>CatBoost</em>) – </p></li>
<li><p><strong>ensemble</strong> (<em>Boolean</em><em>, </em><em>default = False</em>) – </p></li>
<li><p><strong>would result in an ensemble of estimator using the method parameter defined.</strong> (<em>True</em>) – </p></li>
<li><p><strong>method</strong> (<em>String</em><em>, </em><em>'Bagging'</em><em> or </em><em>'Boosting'</em><em>, </em><em>default = None.</em>) – </p></li>
<li><p><strong>must be defined when ensemble is set to True. Default method is set to None.</strong> (<em>method</em>) – </p></li>
<li><p><strong>fold</strong> (<em>integer</em><em>, </em><em>default = 10</em>) – </p></li>
<li><p><strong>of folds to be used in Kfold CV. Must be at least 2.</strong> (<em>Number</em>) – </p></li>
<li><p><strong>round</strong> (<em>integer</em><em>, </em><em>default = 4</em>) – </p></li>
<li><p><strong>of decimal places the metrics in the score grid will be rounded to.</strong> (<em>Number</em>) – </p></li>
<li><p><strong>verbose</strong> (<em>Boolean</em><em>, </em><em>default = True</em>) – </p></li>
<li><p><strong>grid is not printed when verbose is set to False.</strong> (<em>Score</em>) – </p></li>
<li><p><strong>**kwargs</strong> – </p></li>
<li><p><strong>keyword arguments to pass to the estimator</strong> (<em>Additional</em>) – </p></li>
<li><p><strong>Returns</strong> – </p></li>
<li><p><strong>--------</strong> – </p></li>
<li><p><strong>grid</strong> (<em>score</em>) – </p></li>
<li><p><strong>Scoring metrics used are MAE</strong><strong>, </strong><strong>MSE</strong><strong>, </strong><strong>RMSE</strong><strong>, </strong><strong>RMSLE</strong><strong>, </strong><strong>R2 and MAPE.</strong> (<em>-----------</em>) – Mean and standard deviation of the scores across the folds are
also returned.</p></li>
<li><p><strong>model</strong> (<em>trained model object</em>) – </p></li>
<li><p><strong>-----------</strong> – </p></li>
<li><p><strong>Warnings</strong> – </p></li>
<li><p><strong>---------</strong> – </p></li>
<li><p><strong>None</strong> – </p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pycaret.regression.create_stacknet">
<code class="sig-prename descclassname">pycaret.regression.</code><code class="sig-name descname">create_stacknet</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">estimator_list</span></em>, <em class="sig-param"><span class="n">meta_model</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">fold</span><span class="o">=</span><span class="default_value">10</span></em>, <em class="sig-param"><span class="n">round</span><span class="o">=</span><span class="default_value">4</span></em>, <em class="sig-param"><span class="n">restack</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">improve_only</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">optimize</span><span class="o">=</span><span class="default_value">'r2'</span></em>, <em class="sig-param"><span class="n">finalize</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.regression.create_stacknet" title="Permalink to this definition">¶</a></dt>
<dd><p>This function creates a sequential stack net using cross validated predictions
at each layer. The final score grid contains predictions from the meta model
using Kfold Cross Validation. Base level models can be passed as estimator_list
param, the layers can be organized as a sub list within the estimator_list object.
Restacking param controls the ability to expose raw features to meta model.</p>
<blockquote>
<div><p>from pycaret.datasets import get_data
boston = get_data(‘boston’)
experiment_name = setup(data = boston,  target = ‘medv’)
dt = create_model(‘dt’)
rf = create_model(‘rf’)
ada = create_model(‘ada’)
ridge = create_model(‘ridge’)
knn = create_model(‘knn’)</p>
<p>stacknet = create_stacknet(estimator_list =[[dt,rf],[ada,ridge,knn]])</p>
<p>This will result in the stacking of models in multiple layers. The first layer
contains dt and rf, the predictions of which are used by models in the second
layer to generate predictions which are then used by the meta model to generate
final predictions. By default, the meta model is Linear Regression but can be
changed with meta_model param.</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>estimator_list</strong> (<em>nested list of objects</em>) – </p></li>
<li><p><strong>meta_model</strong> (<em>object</em><em>, </em><em>default = None</em>) – </p></li>
<li><p><strong>set to None</strong><strong>, </strong><strong>Linear Regression is used as a meta model.</strong> (<em>if</em>) – </p></li>
<li><p><strong>fold</strong> (<em>integer</em><em>, </em><em>default = 10</em>) – </p></li>
<li><p><strong>of folds to be used in Kfold CV. Must be at least 2.</strong> (<em>Number</em>) – </p></li>
<li><p><strong>round</strong> (<em>integer</em><em>, </em><em>default = 4</em>) – </p></li>
<li><p><strong>of decimal places the metrics in the score grid will be rounded to.</strong> (<em>Number</em>) – </p></li>
<li><p><strong>restack</strong> (<em>Boolean</em><em>, </em><em>default = True</em>) – </p></li>
<li><p><strong>restack is set to True</strong><strong>, </strong><strong>raw data and prediction of all layers will be</strong> (<em>When</em>) – </p></li>
<li><p><strong>to the meta model when making predictions. When set to False</strong><strong>, </strong><strong>only</strong> (<em>exposed</em>) – </p></li>
<li><p><strong>predicted label of last layer is passed to meta model when making final</strong> (<em>the</em>) – </p></li>
<li><p><strong>predictions.</strong> – </p></li>
<li><p><strong>improve_only</strong> (<em>Boolean</em><em>, </em><em>default = True</em>) – </p></li>
<li><p><strong>set to True</strong><strong>, </strong><strong>base estimator is returned when the metric doesn't</strong> (<em>When</em>) – </p></li>
<li><p><strong>by ensemble_model. This gurantees the returned object would perform</strong> (<em>improve</em>) – </p></li>
<li><p><strong>equivalent to base estimator created using create_model</strong><strong> or </strong><strong>model</strong> (<em>atleast</em>) – </p></li>
<li><p><strong>by compare_models.</strong> (<em>returned</em>) – </p></li>
<li><p><strong>optimize</strong> (<em>string</em><em>, </em><em>default = 'r2'</em>) – </p></li>
<li><p><strong>used when improve_only is set to True. optimize parameter is used</strong> (<em>Only</em>) – </p></li>
<li><p><strong>compare emsembled model with base estimator. Values accepted in</strong> (<em>to</em>) – </p></li>
<li><p><strong>parameter are 'mae'</strong><strong>, </strong><strong>'mse'</strong><strong>, </strong><strong>'rmse'</strong><strong>, </strong><strong>'r2'</strong><strong>, </strong><strong>'rmsle'</strong><strong>, </strong><strong>'mape'.</strong> (<em>optimize</em>) – </p></li>
<li><p><strong>finalize</strong> (<em>Boolean</em><em>, </em><em>default = False</em>) – </p></li>
<li><p><strong>finalize is set to True</strong><strong>, </strong><strong>it will fit the stacker on entire dataset</strong> (<em>When</em>) – </p></li>
<li><p><strong>the hold-out sample created during the setup</strong><strong>(</strong><strong>) </strong><strong>stage. It is not</strong> (<em>including</em>) – </p></li>
<li><p><strong>to set this to True here</strong><strong>, </strong><strong>if you would like to fit the stacker</strong> (<em>recommended</em>) – </p></li>
<li><p><strong>the entire dataset including the hold-out</strong><strong>, </strong><strong>use finalize_model</strong><strong>(</strong><strong>)</strong><strong></strong> (<em>on</em>) – </p></li>
<li><p><strong>verbose</strong> (<em>Boolean</em><em>, </em><em>default = True</em>) – </p></li>
<li><p><strong>grid is not printed when verbose is set to False.</strong> (<em>Score</em>) – </p></li>
<li><p><strong>Returns</strong> – </p></li>
<li><p><strong>--------</strong> – </p></li>
<li><p><strong>grid</strong> (<em>score</em>) – </p></li>
<li><p><strong>Scoring metrics used are MAE</strong><strong>, </strong><strong>MSE</strong><strong>, </strong><strong>RMSE</strong><strong>, </strong><strong>R2</strong><strong>, </strong><strong>RMSLE and MAPE.</strong> (<em>-----------</em>) – Mean and standard deviation of the scores across the folds are
also returned.</p></li>
<li><p><strong>container</strong> (<em>list of all models where the last element is the meta model.</em>) – </p></li>
<li><p><strong>----------</strong> – </p></li>
<li><p><strong>Warnings</strong> – </p></li>
<li><p><strong>---------</strong> – </p></li>
<li><p><strong>None</strong> – </p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pycaret.regression.deploy_model">
<code class="sig-prename descclassname">pycaret.regression.</code><code class="sig-name descname">deploy_model</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">model</span></em>, <em class="sig-param"><span class="n">model_name</span></em>, <em class="sig-param"><span class="n">authentication</span></em>, <em class="sig-param"><span class="n">platform</span><span class="o">=</span><span class="default_value">'aws'</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.regression.deploy_model" title="Permalink to this definition">¶</a></dt>
<dd><p>(In Preview)</p>
<p>This function deploys the transformation pipeline and trained model object for
production use. The platform of deployment can be defined under the platform
param along with the applicable authentication tokens which are passed as a
dictionary to the authentication param.</p>
<blockquote>
<div><p>from pycaret.datasets import get_data
boston = get_data(‘boston’)
experiment_name = setup(data = boston,  target = ‘medv’)
lr = create_model(‘lr’)</p>
<dl class="simple">
<dt>deploy_model(model = lr, model_name = ‘deploy_lr’, platform = ‘aws’,</dt><dd><p>authentication = {‘bucket’ : ‘pycaret-test’})</p>
</dd>
</dl>
<p>This will deploy the model on AWS S3 account under bucket ‘pycaret-test’</p>
<p>Before deploying a model to an AWS S3 (‘aws’), environment variables must be
configured using the command line interface. To configure AWS env. variables,
type aws configure in your python command line. The following information is
required which can be generated using the Identity and Access Management (IAM)
portal of your amazon console account:</p>
<blockquote>
<div><ul class="simple">
<li><p>AWS Access Key ID</p></li>
<li><p>AWS Secret Key Access</p></li>
<li><p>Default Region Name (can be seen under Global settings on your AWS console)</p></li>
<li><p>Default output format (must be left blank)</p></li>
</ul>
</div></blockquote>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>object</em>) – </p></li>
<li><p><strong>trained model object should be passed as an estimator.</strong> (<em>A</em>) – </p></li>
<li><p><strong>model_name</strong> (<em>string</em>) – </p></li>
<li><p><strong>of model to be passed as a string.</strong> (<em>Name</em>) – </p></li>
<li><p><strong>authentication</strong> (<em>dict</em>) – </p></li>
<li><p><strong>of applicable authentication tokens.</strong> (<em>dictionary</em>) – When platform = ‘aws’:
{‘bucket’ : ‘Name of Bucket on S3’}</p></li>
<li><p><strong>platform</strong> (<em>string</em><em>, </em><em>default = 'aws'</em>) – </p></li>
<li><p><strong>of platform for deployment. Current available options are</strong> (<em>Name</em>) – </p></li>
<li><p><strong>Returns</strong> – </p></li>
<li><p><strong>--------</strong> – </p></li>
<li><p><strong>Message</strong> (<em>Success</em>) – </p></li>
<li><p><strong>Warnings</strong> – </p></li>
<li><p><strong>---------</strong> – </p></li>
<li><p><strong>This function uses file storage services to deploy the model on cloud platform.</strong> (<em>-</em>) – As such, this is efficient for batch-use. Where the production objective is to
obtain prediction at an instance level, this may not be the efficient choice as
it transmits the binary pickle file between your local python environment and
the platform.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pycaret.regression.ensemble_model">
<code class="sig-prename descclassname">pycaret.regression.</code><code class="sig-name descname">ensemble_model</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">estimator</span></em>, <em class="sig-param"><span class="n">method</span><span class="o">=</span><span class="default_value">'Bagging'</span></em>, <em class="sig-param"><span class="n">fold</span><span class="o">=</span><span class="default_value">10</span></em>, <em class="sig-param"><span class="n">n_estimators</span><span class="o">=</span><span class="default_value">10</span></em>, <em class="sig-param"><span class="n">round</span><span class="o">=</span><span class="default_value">4</span></em>, <em class="sig-param"><span class="n">improve_only</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">optimize</span><span class="o">=</span><span class="default_value">'r2'</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.regression.ensemble_model" title="Permalink to this definition">¶</a></dt>
<dd><p>This function ensembles the trained base estimator using the method defined
in ‘method’ param (default = ‘Bagging’). The output prints a score grid that
shows MAE, MSE, RMSE, R2, RMSLE and MAPE by fold (default CV = 10 Folds).</p>
<p>This function returns a trained model object.</p>
<p>Model must be created using create_model() or tune_model().</p>
<blockquote>
<div><p>from pycaret.datasets import get_data
boston = get_data(‘boston’)
experiment_name = setup(data = boston,  target = ‘medv’)
dt = create_model(‘dt’)</p>
<p>ensembled_dt = ensemble_model(dt)</p>
<p>This will return an ensembled Decision Tree model using ‘Bagging’.</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>estimator</strong> (<em>object</em><em>, </em><em>default = None</em>) – </p></li>
<li><p><strong>method</strong> (<em>String</em><em>, </em><em>default = 'Bagging'</em>) – </p></li>
<li><p><strong>method will create an ensemble meta-estimator that fits base</strong> (<em>Bagging</em>) – </p></li>
<li><p><strong>each on random subsets of the original dataset. The other</strong> (<em>regressor</em>) – </p></li>
<li><p><strong>method is 'Boosting' that fits a regressor on the original</strong> (<em>available</em>) – </p></li>
<li><p><strong>and then fits additional copies of the regressor on the same</strong> (<em>dataset</em>) – </p></li>
<li><p><strong>but where the weights of instances are adjusted according to</strong> (<em>dataset</em>) – </p></li>
<li><p><strong>error of the current prediction. As such</strong><strong>, </strong><strong>subsequent regressors</strong> (<em>the</em>) – </p></li>
<li><p><strong>more on difficult cases.</strong> (<em>focus</em>) – </p></li>
<li><p><strong>fold</strong> (<em>integer</em><em>, </em><em>default = 10</em>) – </p></li>
<li><p><strong>of folds to be used in Kfold CV. Must be at least 2.</strong> (<em>Number</em>) – </p></li>
<li><p><strong>n_estimators</strong> (<em>integer</em><em>, </em><em>default = 10</em>) – </p></li>
<li><p><strong>number of base estimators in the ensemble.</strong> (<em>The</em>) – </p></li>
<li><p><strong>case of perfect fit</strong><strong>, </strong><strong>the learning procedure is stopped early.</strong> (<em>In</em>) – </p></li>
<li><p><strong>round</strong> (<em>integer</em><em>, </em><em>default = 4</em>) – </p></li>
<li><p><strong>of decimal places the metrics in the score grid will be rounded to.</strong> (<em>Number</em>) – </p></li>
<li><p><strong>improve_only</strong> (<em>Boolean</em><em>, </em><em>default = True</em>) – </p></li>
<li><p><strong>set to set to True</strong><strong>, </strong><strong>base estimator is returned when the metric doesn't</strong> (<em>When</em>) – </p></li>
<li><p><strong>by ensemble_model. This gurantees the returned object would perform</strong> (<em>improve</em>) – </p></li>
<li><p><strong>equivalent to base estimator created using create_model</strong><strong> or </strong><strong>model</strong> (<em>atleast</em>) – </p></li>
<li><p><strong>by compare_models.</strong> (<em>returned</em>) – </p></li>
<li><p><strong>optimize</strong> (<em>string</em><em>, </em><em>default = 'r2'</em>) – </p></li>
<li><p><strong>used when improve_only is set to True. optimize parameter is used</strong> (<em>Only</em>) – </p></li>
<li><p><strong>compare emsembled model with base estimator. Values accepted in</strong> (<em>to</em>) – </p></li>
<li><p><strong>parameter are 'mae'</strong><strong>, </strong><strong>'mse'</strong><strong>, </strong><strong>'rmse'</strong><strong>, </strong><strong>'r2'</strong><strong>, </strong><strong>'rmsle'</strong><strong>, </strong><strong>'mape'.</strong> (<em>optimize</em>) – </p></li>
<li><p><strong>verbose</strong> (<em>Boolean</em><em>, </em><em>default = True</em>) – </p></li>
<li><p><strong>grid is not printed when verbose is set to False.</strong> (<em>Score</em>) – </p></li>
</ul>
</dd>
</dl>
<p>score grid:   A table containing the scores of the model across the kfolds.
———–   Scoring metrics used are MAE, MSE, RMSE, R2, RMSLE and MAPE.</p>
<blockquote>
<div><p>Mean and standard deviation of the scores across the folds are
also returned.</p>
</div></blockquote>
<p>None</p>
</dd></dl>

<dl class="py function">
<dt id="pycaret.regression.evaluate_model">
<code class="sig-prename descclassname">pycaret.regression.</code><code class="sig-name descname">evaluate_model</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">estimator</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.regression.evaluate_model" title="Permalink to this definition">¶</a></dt>
<dd><p>This function displays a user interface for all of the available plots for
a given estimator. It internally uses the plot_model() function.</p>
<blockquote>
<div><p>from pycaret.datasets import get_data
boston = get_data(‘boston’)
experiment_name = setup(data = boston,  target = ‘medv’)
lr = create_model(‘lr’)</p>
<p>evaluate_model(lr)</p>
<p>This will display the User Interface for all of the plots for a given
estimator.</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>estimator</strong> (<em>object</em><em>, </em><em>default = none</em>) – </p></li>
<li><p><strong>trained model object should be passed as an estimator.</strong> (<em>A</em>) – </p></li>
<li><p><strong>Returns</strong> – </p></li>
<li><p><strong>--------</strong> – </p></li>
<li><p><strong>Interface</strong> (<em>User</em>) – </p></li>
<li><p><strong>--------------</strong> – </p></li>
<li><p><strong>Warnings</strong> – </p></li>
<li><p><strong>---------</strong> – </p></li>
<li><p><strong>None</strong> – </p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pycaret.regression.finalize_model">
<code class="sig-prename descclassname">pycaret.regression.</code><code class="sig-name descname">finalize_model</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">estimator</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.regression.finalize_model" title="Permalink to this definition">¶</a></dt>
<dd><p>This function fits the estimator onto the complete dataset passed during the
setup() stage. The purpose of this function is to prepare for final model
deployment after experimentation.</p>
<blockquote>
<div><p>from pycaret.datasets import get_data
boston = get_data(‘boston’)
experiment_name = setup(data = boston,  target = ‘medv’)
lr = create_model(‘lr’)</p>
<p>final_lr = finalize_model(lr)</p>
<p>This will return the final model object fitted to complete dataset.</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>estimator</strong> (<em>object</em><em>, </em><em>default = none</em>) – </p></li>
<li><p><strong>trained model object should be passed as an estimator.</strong> (<em>A</em>) – </p></li>
<li><p><strong>Returns</strong> – </p></li>
<li><p><strong>--------</strong> – </p></li>
<li><p><strong>Model</strong> (<em>Trained model object fitted on complete dataset.</em>) – </p></li>
<li><p><strong>------</strong> – </p></li>
<li><p><strong>Warnings</strong> – </p></li>
<li><p><strong>---------</strong> – </p></li>
<li><p><strong>If the model returned by finalize_model</strong><strong>(</strong><strong>)</strong><strong>, </strong><strong>is used on predict_model</strong><strong>(</strong><strong>) </strong><strong>without</strong> (<em>-</em>) – passing a new unseen dataset, then the information grid printed is misleading
as the model is trained on the complete dataset including test / hold-out sample.
Once finalize_model() is used, the model is considered ready for deployment and
should be used on new unseens dataset only.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pycaret.regression.interpret_model">
<code class="sig-prename descclassname">pycaret.regression.</code><code class="sig-name descname">interpret_model</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">estimator</span></em>, <em class="sig-param"><span class="n">plot</span><span class="o">=</span><span class="default_value">'summary'</span></em>, <em class="sig-param"><span class="n">feature</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">observation</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.regression.interpret_model" title="Permalink to this definition">¶</a></dt>
<dd><p>This function takes a trained model object and returns an interpretation plot
based on the test / hold-out set. It only supports tree based algorithms.</p>
<p>This function is implemented based on the SHAP (SHapley Additive exPlanations),
which is a unified approach to explain the output of any machine learning model.
SHAP connects game theory with local explanations.</p>
<p>For more information : <a class="reference external" href="https://shap.readthedocs.io/en/latest/">https://shap.readthedocs.io/en/latest/</a></p>
<blockquote>
<div><p>from pycaret.datasets import get_data
boston = get_data(‘boston’)
experiment_name = setup(data = boston,  target = ‘medv’)
dt = create_model(‘dt’)</p>
<p>interpret_model(dt)</p>
<p>This will return a summary interpretation plot of Decision Tree model.</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>estimator</strong> (<em>object</em><em>, </em><em>default = none</em>) – </p></li>
<li><p><strong>trained tree based model object should be passed as an estimator.</strong> (<em>A</em>) – </p></li>
<li><p><strong>plot</strong> (<em>string</em><em>, </em><em>default = 'summary'</em>) – </p></li>
<li><p><strong>available options are 'correlation' and 'reason'.</strong> (<em>other</em>) – </p></li>
<li><p><strong>feature</strong> (<em>string</em><em>, </em><em>default = None</em>) – </p></li>
<li><p><strong>parameter is only needed when plot = 'correlation'. By default feature is</strong> (<em>This</em>) – </p></li>
<li><p><strong>to None which means the first column of the dataset will be used as a variable.</strong> (<em>set</em>) – </p></li>
<li><p><strong>feature parameter must be passed to change this.</strong> (<em>A</em>) – </p></li>
<li><p><strong>observation</strong> (<em>integer</em><em>, </em><em>default = None</em>) – </p></li>
<li><p><strong>parameter only comes into effect when plot is set to 'reason'. If no observation</strong> (<em>This</em>) – </p></li>
<li><p><strong>is provided</strong><strong>, </strong><strong>it will return an analysis of all observations with the option</strong> (<em>number</em>) – </p></li>
<li><p><strong>select the feature on x and y axes through drop down interactivity. For analysis at</strong> (<em>to</em>) – </p></li>
<li><p><strong>sample level</strong><strong>, </strong><strong>an observation parameter must be passed with the index value of the</strong> (<em>the</em>) – </p></li>
<li><p><strong>in test / hold-out set.</strong> (<em>observation</em>) – </p></li>
<li><p><strong>Returns</strong> – </p></li>
<li><p><strong>--------</strong> – </p></li>
<li><p><strong>Plot</strong> (<em>Visual</em>) – </p></li>
<li><p><strong>Returns the interactive JS plot when plot = 'reason'.</strong> (<em>-----------</em>) – </p></li>
<li><p><strong>Warnings</strong> – </p></li>
<li><p><strong>---------</strong> – </p></li>
<li><p><strong>None</strong> – </p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pycaret.regression.load_experiment">
<code class="sig-prename descclassname">pycaret.regression.</code><code class="sig-name descname">load_experiment</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">experiment_name</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.regression.load_experiment" title="Permalink to this definition">¶</a></dt>
<dd><p>This function loads a previously saved experiment from the current active
directory into current python environment. Load object must be a pickle file.</p>
<blockquote>
<div><p>saved_experiment = load_experiment(‘experiment_23122019’)</p>
<p>This will load the entire experiment pipeline into the object saved_experiment.
The experiment file must be in current directory.</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>experiment_name</strong> (<em>string</em><em>, </em><em>default = none</em>) – </p></li>
<li><p><strong>of pickle file to be passed as a string.</strong> (<em>Name</em>) – </p></li>
<li><p><strong>Returns</strong> – </p></li>
<li><p><strong>--------</strong> – </p></li>
<li><p><strong>Grid containing details of saved objects in experiment pipeline.</strong> (<em>Information</em>) – </p></li>
<li><p><strong>Warnings</strong> – </p></li>
<li><p><strong>---------</strong> – </p></li>
<li><p><strong>None</strong> – </p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pycaret.regression.load_model">
<code class="sig-prename descclassname">pycaret.regression.</code><code class="sig-name descname">load_model</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">model_name</span></em>, <em class="sig-param"><span class="n">platform</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">authentication</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.regression.load_model" title="Permalink to this definition">¶</a></dt>
<dd><p>This function loads a previously saved transformation pipeline and model
from the current active directory into the current python environment.
Load object must be a pickle file.</p>
<blockquote>
<div><p>saved_lr = load_model(‘lr_model_23122019’)</p>
<p>This will load the previously saved model in saved_lr variable. The file
must be in the current directory.</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_name</strong> (<em>string</em><em>, </em><em>default = none</em>) – </p></li>
<li><p><strong>of pickle file to be passed as a string.</strong> (<em>Name</em>) – </p></li>
<li><p><strong>platform</strong> (<em>string</em><em>, </em><em>default = None</em>) – </p></li>
<li><p><strong>of platform</strong><strong>, </strong><strong>if loading model from cloud. Current available options are</strong> (<em>Name</em>) – </p></li>
<li><p><strong>'aws'.</strong> – </p></li>
<li><p><strong>authentication</strong> (<em>dict</em>) – </p></li>
<li><p><strong>of applicable authentication tokens.</strong> (<em>dictionary</em>) – When platform = ‘aws’:
{‘bucket’ : ‘Name of Bucket on S3’}</p></li>
<li><p><strong>verbose</strong> (<em>Boolean</em><em>, </em><em>default = True</em>) – </p></li>
<li><p><strong>message is not printed when verbose is set to False.</strong> (<em>Success</em>) – </p></li>
<li><p><strong>Returns</strong> – </p></li>
<li><p><strong>--------</strong> – </p></li>
<li><p><strong>Message</strong> (<em>Success</em>) – </p></li>
<li><p><strong>Warnings</strong> – </p></li>
<li><p><strong>---------</strong> – </p></li>
<li><p><strong>None</strong> – </p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pycaret.regression.plot_model">
<code class="sig-prename descclassname">pycaret.regression.</code><code class="sig-name descname">plot_model</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">estimator</span></em>, <em class="sig-param"><span class="n">plot</span><span class="o">=</span><span class="default_value">'residuals'</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.regression.plot_model" title="Permalink to this definition">¶</a></dt>
<dd><p>This function takes a trained model object and returns a plot based on the
test / hold-out set. The process may require the model to be re-trained in
certain cases. See list of plots supported below.</p>
<p>Model must be created using create_model() or tune_model().</p>
<blockquote>
<div><p>from pycaret.datasets import get_data
boston = get_data(‘boston’)
experiment_name = setup(data = boston,  target = ‘medv’)
lr = create_model(‘lr’)</p>
<p>plot_model(lr)</p>
<p>This will return an residuals plot of a trained Linear Regression model.</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>estimator</strong> (<em>object</em><em>, </em><em>default = none</em>) – </p></li>
<li><p><strong>trained model object should be passed as an estimator.</strong> (<em>A</em>) – </p></li>
<li><p><strong>plot</strong> (<em>string</em><em>, </em><em>default = residual</em>) – </p></li>
<li><p><strong>abbreviation of type of plot. The current list of plots supported are</strong> (<em>Enter</em>) – </p></li>
<li><p><strong>Abbreviated String     Original Implementation</strong> (<em>Name</em>) – </p></li>
<li><p><strong>------------------     -----------------------</strong> (<em>---------</em>) – </p></li>
<li><p><strong>Plot               'residuals'           .. / residuals.html</strong> (<em>Residuals</em>) – </p></li>
<li><p><strong>Error Plot        'error'               .. / peplot.html</strong> (<em>Prediction</em>) – </p></li>
<li><p><strong>Distance Plot          'cooks'               .. / influence.html</strong> (<em>Cooks</em>) – </p></li>
<li><p><strong>Feat. Selection    'rfe'                 .. / rfecv.html</strong> (<em>Recursive</em>) – </p></li>
<li><p><strong>Curve               'learning'            .. / learning_curve.html</strong> (<em>Learning</em>) – </p></li>
<li><p><strong>Curve             'vc'                  .. / validation_curve.html</strong> (<em>Validation</em>) – </p></li>
<li><p><strong>Learning            'manifold'            .. / manifold.html</strong> (<em>Manifold</em>) – </p></li>
<li><p><strong>Importance           'feature'                   N/A</strong> (<em>Feature</em>) – </p></li>
<li><p><strong>Hyperparameter         'parameter'                 N/A</strong> (<em>Model</em>) – </p></li>
<li><p><strong>https</strong> (<em>**</em>) – </p></li>
<li><p><strong>Returns</strong> – </p></li>
<li><p><strong>--------</strong> – </p></li>
<li><p><strong>Plot</strong> (<em>Visual</em>) – </p></li>
<li><p><strong>------------</strong> – </p></li>
<li><p><strong>Warnings</strong> – </p></li>
<li><p><strong>---------</strong> – </p></li>
<li><p><strong>None</strong> – </p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pycaret.regression.predict_model">
<code class="sig-prename descclassname">pycaret.regression.</code><code class="sig-name descname">predict_model</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">estimator</span></em>, <em class="sig-param"><span class="n">data</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">platform</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">authentication</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">round</span><span class="o">=</span><span class="default_value">4</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.regression.predict_model" title="Permalink to this definition">¶</a></dt>
<dd><p>This function is used to predict new data using a trained estimator. It accepts
an estimator created using one of the function in pycaret that returns a trained
model object or a list of trained model objects created using stack_models() or
create_stacknet(). New unseen data can be passed to data param as pandas Dataframe.
If data is not passed, the test / hold-out set separated at the time of setup() is
used to generate predictions.</p>
<blockquote>
<div><p>from pycaret.datasets import get_data
boston = get_data(‘boston’)
experiment_name = setup(data = boston,  target = ‘medv’)
lr = create_model(‘lr’)</p>
<p>lr_predictions_holdout = predict_model(lr)</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>estimator</strong> (<em>object</em><em> or </em><em>list of objects / string</em><em>,  </em><em>default = None</em>) – </p></li>
<li><p><strong>estimator is passed as string</strong><strong>, </strong><strong>load_model</strong><strong>(</strong><strong>) </strong><strong>is called internally to load the</strong> (<em>When</em>) – </p></li>
<li><p><strong>file from active directory</strong><strong> or </strong><strong>cloud platform when platform param is passed.</strong> (<em>pickle</em>) – </p></li>
<li><p><strong>data</strong> (<em>{array-like</em><em>, </em><em>sparse matrix}</em><em>, </em><em>shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>) </em><em>where n_samples</em>) – </p></li>
<li><p><strong>the number of samples and n_features is the number of features. All features</strong> (<em>is</em>) – </p></li>
<li><p><strong>during training must be present in the new dataset.</strong> (<em>used</em>) – </p></li>
<li><p><strong>platform</strong> (<em>string</em><em>, </em><em>default = None</em>) – </p></li>
<li><p><strong>of platform</strong><strong>, </strong><strong>if loading model from cloud. Current available options are</strong> (<em>Name</em>) – </p></li>
<li><p><strong>'aws'.</strong> – </p></li>
<li><p><strong>authentication</strong> (<em>dict</em>) – </p></li>
<li><p><strong>of applicable authentication tokens.</strong> (<em>dictionary</em>) – When platform = ‘aws’:
{‘bucket’ : ‘Name of Bucket on S3’}</p></li>
<li><p><strong>round</strong> (<em>integer</em><em>, </em><em>default = 4</em>) – </p></li>
<li><p><strong>of decimal places the predicted labels will be rounded to.</strong> (<em>Number</em>) – </p></li>
<li><p><strong>Returns</strong> – </p></li>
<li><p><strong>--------</strong> – </p></li>
<li><p><strong>grid</strong> (<em>info</em>) – </p></li>
<li><p><strong>----------</strong> – </p></li>
<li><p><strong>Warnings</strong> – </p></li>
<li><p><strong>---------</strong> – </p></li>
<li><p><strong>if the estimator passed is created using finalize_model</strong><strong>(</strong><strong>) </strong><strong>then the metrics</strong> (<em>-</em>) – printed in the information grid maybe misleading as the model is trained on
the complete dataset including the test / hold-out set. Once finalize_model()
is used, the model is considered ready for deployment and should be used on new
unseen datasets only.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pycaret.regression.save_experiment">
<code class="sig-prename descclassname">pycaret.regression.</code><code class="sig-name descname">save_experiment</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">experiment_name</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.regression.save_experiment" title="Permalink to this definition">¶</a></dt>
<dd><p>This function saves the entire experiment into the current active directory.
All outputs using pycaret are internally saved into a binary list which is
pickilized when save_experiment() is used.</p>
<blockquote>
<div><p>save_experiment()</p>
<p>This will save the entire experiment into the current active directory. By
default, the name of the experiment will use the session_id generated during
setup(). To use a custom name, a string must be passed to the experiment_name
param. For example:</p>
<p>save_experiment(‘experiment_23122019’)</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>experiment_name</strong> (<em>string</em><em>, </em><em>default = none</em>) – </p></li>
<li><p><strong>of pickle file to be passed as a string.</strong> (<em>Name</em>) – </p></li>
<li><p><strong>Returns</strong> – </p></li>
<li><p><strong>--------</strong> – </p></li>
<li><p><strong>Message</strong> (<em>Success</em>) – </p></li>
<li><p><strong>Warnings</strong> – </p></li>
<li><p><strong>---------</strong> – </p></li>
<li><p><strong>None</strong> – </p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pycaret.regression.save_model">
<code class="sig-prename descclassname">pycaret.regression.</code><code class="sig-name descname">save_model</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">model</span></em>, <em class="sig-param"><span class="n">model_name</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.regression.save_model" title="Permalink to this definition">¶</a></dt>
<dd><p>This function saves the transformation pipeline and trained model object
into the current active directory as a pickle file for later use.</p>
<blockquote>
<div><p>from pycaret.datasets import get_data
boston = get_data(‘boston’)
experiment_name = setup(data = boston,  target = ‘medv’)
lr = create_model(‘lr’)</p>
<p>save_model(lr, ‘lr_model_23122019’)</p>
<p>This will save the transformation pipeline and model as a binary pickle
file in the current directory.</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>object</em><em>, </em><em>default = none</em>) – </p></li>
<li><p><strong>trained model object should be passed as an estimator.</strong> (<em>A</em>) – </p></li>
<li><p><strong>model_name</strong> (<em>string</em><em>, </em><em>default = none</em>) – </p></li>
<li><p><strong>of pickle file to be passed as a string.</strong> (<em>Name</em>) – </p></li>
<li><p><strong>verbose</strong> (<em>Boolean</em><em>, </em><em>default = True</em>) – </p></li>
<li><p><strong>message is not printed when verbose is set to False.</strong> (<em>Success</em>) – </p></li>
<li><p><strong>Returns</strong> – </p></li>
<li><p><strong>--------</strong> – </p></li>
<li><p><strong>Message</strong> (<em>Success</em>) – </p></li>
<li><p><strong>Warnings</strong> – </p></li>
<li><p><strong>---------</strong> – </p></li>
<li><p><strong>None</strong> – </p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pycaret.regression.setup">
<code class="sig-prename descclassname">pycaret.regression.</code><code class="sig-name descname">setup</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">target</span></em>, <em class="sig-param"><span class="n">train_size</span><span class="o">=</span><span class="default_value">0.7</span></em>, <em class="sig-param"><span class="n">sampling</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">sample_estimator</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">categorical_features</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">categorical_imputation</span><span class="o">=</span><span class="default_value">'constant'</span></em>, <em class="sig-param"><span class="n">ordinal_features</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">high_cardinality_features</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">high_cardinality_method</span><span class="o">=</span><span class="default_value">'frequency'</span></em>, <em class="sig-param"><span class="n">numeric_features</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">numeric_imputation</span><span class="o">=</span><span class="default_value">'mean'</span></em>, <em class="sig-param"><span class="n">date_features</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">ignore_features</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">normalize</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">normalize_method</span><span class="o">=</span><span class="default_value">'zscore'</span></em>, <em class="sig-param"><span class="n">transformation</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">transformation_method</span><span class="o">=</span><span class="default_value">'yeo-johnson'</span></em>, <em class="sig-param"><span class="n">handle_unknown_categorical</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">unknown_categorical_method</span><span class="o">=</span><span class="default_value">'least_frequent'</span></em>, <em class="sig-param"><span class="n">pca</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">pca_method</span><span class="o">=</span><span class="default_value">'linear'</span></em>, <em class="sig-param"><span class="n">pca_components</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">ignore_low_variance</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">combine_rare_levels</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">rare_level_threshold</span><span class="o">=</span><span class="default_value">0.1</span></em>, <em class="sig-param"><span class="n">bin_numeric_features</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">remove_outliers</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">outliers_threshold</span><span class="o">=</span><span class="default_value">0.05</span></em>, <em class="sig-param"><span class="n">remove_multicollinearity</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">multicollinearity_threshold</span><span class="o">=</span><span class="default_value">0.9</span></em>, <em class="sig-param"><span class="n">create_clusters</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">cluster_iter</span><span class="o">=</span><span class="default_value">20</span></em>, <em class="sig-param"><span class="n">polynomial_features</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">polynomial_degree</span><span class="o">=</span><span class="default_value">2</span></em>, <em class="sig-param"><span class="n">trigonometry_features</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">polynomial_threshold</span><span class="o">=</span><span class="default_value">0.1</span></em>, <em class="sig-param"><span class="n">group_features</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">group_names</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">feature_selection</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">feature_selection_threshold</span><span class="o">=</span><span class="default_value">0.8</span></em>, <em class="sig-param"><span class="n">feature_interaction</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">feature_ratio</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">interaction_threshold</span><span class="o">=</span><span class="default_value">0.01</span></em>, <em class="sig-param"><span class="n">transform_target</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">transform_target_method</span><span class="o">=</span><span class="default_value">'box-cox'</span></em>, <em class="sig-param"><span class="n">data_split_shuffle</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">folds_shuffle</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">n_jobs</span><span class="o">=</span><span class="default_value">- 1</span></em>, <em class="sig-param"><span class="n">html</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">session_id</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">silent</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">profile</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.regression.setup" title="Permalink to this definition">¶</a></dt>
<dd><p>This function initializes the environment in pycaret and creates the transformation
pipeline to prepare the data for modeling and deployment. setup() must called before
executing any other function in pycaret. It takes two mandatory parameters:
dataframe {array-like, sparse matrix} and name of the target column.</p>
<p>All other parameters are optional.</p>
<blockquote>
<div><p>from pycaret.datasets import get_data
boston = get_data(‘boston’)</p>
<p>experiment_name = setup(data = boston,  target = ‘medv’)</p>
<p>‘boston’ is a pandas DataFrame and ‘medv’ is the name of target column.</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<em>{array-like</em><em>, </em><em>sparse matrix}</em><em>, </em><em>shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>) </em><em>where n_samples</em>) – </p></li>
<li><p><strong>the number of samples and n_features is the number of features.</strong> (<em>is</em>) – </p></li>
<li><p><strong>target</strong> (<em>string</em>) – </p></li>
<li><p><strong>of target column to be passed in as string.</strong> (<em>Name</em>) – </p></li>
<li><p><strong>train_size</strong> (<em>float</em><em>, </em><em>default = 0.7</em>) – </p></li>
<li><p><strong>of the training set. By default</strong><strong>, </strong><strong>70% of the data will be used for training</strong> (<em>Size</em>) – </p></li>
<li><p><strong>validation. The remaining data will be used for test / hold-out set.</strong> (<em>and</em>) – </p></li>
<li><p><strong>sampling</strong> (<em>bool</em><em>, </em><em>default = True</em>) – </p></li>
<li><p><strong>the sample size exceeds 25</strong><strong>,</strong><strong>000 samples</strong><strong>, </strong><strong>pycaret will build a base estimator</strong> (<em>When</em>) – </p></li>
<li><p><strong>various sample sizes from the original dataset. This will return a performance</strong> (<em>at</em>) – </p></li>
<li><p><strong>of R2 values at various sample levels</strong><strong>, </strong><strong>that will assist in deciding the</strong> (<em>plot</em>) – </p></li>
<li><p><strong>sample size for modeling.  The desired sample size must then be entered</strong> (<em>preferred</em>) – </p></li>
<li><p><strong>training and validation in the  pycaret environment. When sample_size entered</strong> (<em>for</em>) – </p></li>
<li><p><strong>less than 1</strong><strong>, </strong><strong>the remaining dataset</strong><strong> (</strong><strong>1 - sample</strong><strong>) </strong><strong>is used for fitting the model</strong> (<em>is</em>) – </p></li>
<li><p><strong>when finalize_model</strong><strong>(</strong><strong>) </strong><strong>is called.</strong> (<em>only</em>) – </p></li>
<li><p><strong>sample_estimator</strong> (<em>object</em><em>, </em><em>default = None</em>) – </p></li>
<li><p><strong>None</strong><strong>, </strong><strong>Linear Regression is used by default.</strong> (<em>If</em>) – </p></li>
<li><p><strong>categorical_features</strong> (<em>string</em><em>, </em><em>default = None</em>) – </p></li>
<li><p><strong>the inferred data types are not correct</strong><strong>, </strong><strong>categorical_features can be used to</strong> (<em>If</em>) – </p></li>
<li><p><strong>the inferred type. If when running setup the type of 'column1' is</strong> (<em>overwrite</em>) – </p></li>
<li><p><strong>as numeric instead of categorical</strong><strong>, </strong><strong>then this parameter can be used</strong> (<em>inferred</em>) – </p></li>
<li><p><strong>overwrite the type by passing categorical_features =</strong><strong> [</strong><strong>'column1'</strong><strong>]</strong><strong></strong> (<em>to</em>) – </p></li>
<li><p><strong>categorical_imputation</strong> (<em>string</em><em>, </em><em>default = 'constant'</em>) – </p></li>
<li><p><strong>missing values are found in categorical features</strong><strong>, </strong><strong>they will be imputed with</strong> (<em>If</em>) – </p></li>
<li><p><strong>constant 'not_available' value. The other available option is 'mode' which</strong> (<em>a</em>) – </p></li>
<li><p><strong>the missing value using most frequent value in the training dataset.</strong> (<em>imputes</em>) – </p></li>
<li><p><strong>ordinal_features</strong> (<em>dictionary</em><em>, </em><em>default = None</em>) – </p></li>
<li><p><strong>the data contains ordinal features</strong><strong>, </strong><strong>they must be encoded differently using</strong> (<em>When</em>) – </p></li>
<li><p><strong>ordinal_features param. If the data has a categorical variable with values</strong> (<em>the</em>) – </p></li>
<li><p><strong>'low'</strong><strong>, </strong><strong>'medium'</strong><strong>, </strong><strong>'high' and it is known that low &lt; medium &lt; high</strong><strong>, </strong><strong>then it can</strong> (<em>of</em>) – </p></li>
<li><p><strong>passed as ordinal_features = { 'column_name'</strong> (<em>be</em>) – </p></li>
<li><p><strong>list sequence must be in increasing order from lowest to highest.</strong> (<em>The</em>) – </p></li>
<li><p><strong>high_cardinality_features</strong> (<em>string</em><em>, </em><em>default = None</em>) – </p></li>
<li><p><strong>the data containts features with high cardinality</strong><strong>, </strong><strong>they can be compressed</strong> (<em>When</em>) – </p></li>
<li><p><strong>fewer levels by passing them as a list of column names with high cardinality.</strong> (<em>into</em>) – </p></li>
<li><p><strong>are compressed using method defined in high_cardinality_method param.</strong> (<em>Features</em>) – </p></li>
<li><p><strong>high_cardinality_method</strong> (<em>string</em><em>, </em><em>default = 'frequency'</em>) – </p></li>
<li><p><strong>method set to 'frequency' it will replace the original value of feature</strong> (<em>When</em>) – </p></li>
<li><p><strong>the frequency distribution and convert the feature into numeric. Other</strong> (<em>with</em>) – </p></li>
<li><p><strong>method is 'clustering' which performs the clustering on statistical</strong> (<em>available</em>) – </p></li>
<li><p><strong>of data and replaces the original value of feature with cluster label.</strong> (<em>attribute</em>) – </p></li>
<li><p><strong>number of clusters is determined using a combination of Calinski-Harabasz and</strong> (<em>The</em>) – </p></li>
<li><p><strong>criterion.</strong> (<em>Silhouette</em>) – </p></li>
<li><p><strong>numeric_features</strong> (<em>string</em><em>, </em><em>default = None</em>) – </p></li>
<li><p><strong>the inferred data types are not correct</strong><strong>, </strong><strong>numeric_features can be used to</strong> (<em>If</em>) – </p></li>
<li><p><strong>the inferred type. If when running setup the type of 'column1' is</strong> – </p></li>
<li><p><strong>as a categorical instead of numeric</strong><strong>, </strong><strong>then this parameter can be used</strong> (<em>inferred</em>) – </p></li>
<li><p><strong>overwrite by passing numeric_features =</strong><strong> [</strong><strong>'column1'</strong><strong>]</strong><strong></strong> (<em>to</em>) – </p></li>
<li><p><strong>numeric_imputation</strong> (<em>string</em><em>, </em><em>default = 'mean'</em>) – </p></li>
<li><p><strong>missing values are found in numeric features</strong><strong>, </strong><strong>they will be imputed with the</strong> (<em>If</em>) – </p></li>
<li><p><strong>value of the feature. The other available option is 'median' which imputes</strong> (<em>mean</em>) – </p></li>
<li><p><strong>value using the median value in the training dataset.</strong> (<em>the</em>) – </p></li>
<li><p><strong>date_features</strong> (<em>string</em><em>, </em><em>default = None</em>) – </p></li>
<li><p><strong>the data has a DateTime column that is not automatically detected when running</strong> (<em>If</em>) – </p></li>
<li><p><strong>this parameter can be used by passing date_features = 'date_column_name'.</strong> (<em>setup</em><em>,</em>) – </p></li>
<li><p><strong>can work with multiple date columns. Date columns are not used in modeling.</strong> (<em>It</em>) – </p></li>
<li><p><strong>feature extraction is performed and date columns are dropped from the</strong> (<em>Instead</em><em>,</em>) – </p></li>
<li><p><strong>If the date column includes a time stamp</strong><strong>, </strong><strong>features related to time will</strong> (<em>dataset.</em>) – </p></li>
<li><p><strong>be extracted.</strong> (<em>also</em>) – </p></li>
<li><p><strong>ignore_features</strong> (<em>string</em><em>, </em><em>default = None</em>) – </p></li>
<li><p><strong>any feature should be ignored for modeling</strong><strong>, </strong><strong>it can be passed to the param</strong> (<em>If</em>) – </p></li>
<li><p><strong>The ID and DateTime columns when inferred</strong><strong>, </strong><strong>are automatically</strong> (<em>ignore_features.</em>) – </p></li>
<li><p><strong>to ignore for modeling.</strong> (<em>set</em>) – </p></li>
<li><p><strong>normalize</strong> (<em>bool</em><em>, </em><em>default = False</em>) – </p></li>
<li><p><strong>set to True</strong><strong>, </strong><strong>the feature space is transformed using the normalized_method</strong> (<em>When</em>) – </p></li>
<li><p><strong>Generally</strong><strong>, </strong><strong>linear algorithms perform better with normalized data however</strong><strong>,</strong> (<em>param.</em>) – </p></li>
<li><p><strong>results may vary and it is advised to run multiple experiments to evaluate</strong> (<em>the</em>) – </p></li>
<li><p><strong>benefit of normalization.</strong> (<em>the</em>) – </p></li>
<li><p><strong>normalize_method</strong> (<em>string</em><em>, </em><em>default = 'zscore'</em>) – </p></li>
<li><p><strong>the method to be used for normalization. By default</strong><strong>, </strong><strong>normalize method</strong> (<em>Defines</em>) – </p></li>
<li><p><strong>set to 'zscore'. The standard zscore is calculated as z =</strong><strong> (</strong><strong>x - u</strong><strong>) </strong><strong>/ s. The</strong> (<em>is</em>) – </p></li>
<li><p><strong>available options are</strong> (<em>other</em>) – </p></li>
<li><p><strong>'minmax'</strong> (<em>scales and translates each feature individually such that it is in</em>) – the range of 0 - 1.</p></li>
<li><p><strong>'maxabs'</strong> (<em>scales and translates each feature individually such that the maximal</em>) – absolute value of each feature will be 1.0. It does not shift/center
the data, and thus does not destroy any sparsity.</p></li>
<li><p><strong>'robust'</strong> (<em>scales and translates each feature according to the Interquartile range.</em>) – When the dataset contains outliers, robust scaler often gives better
results.</p></li>
<li><p><strong>transformation</strong> (<em>bool</em><em>, </em><em>default = False</em>) – </p></li>
<li><p><strong>set to True</strong><strong>, </strong><strong>a power transformation is applied to make the data more normal /</strong> (<em>When</em>) – </p></li>
<li><p><strong>This is useful for modeling issues related to heteroscedasticity or</strong> (<em>Gaussian-like.</em>) – </p></li>
<li><p><strong>situations where normality is desired. The optimal parameter for stabilizing</strong> (<em>other</em>) – </p></li>
<li><p><strong>and minimizing skewness is estimated through maximum likelihood.</strong> (<em>variance</em>) – </p></li>
<li><p><strong>transformation_method</strong> (<em>string</em><em>, </em><em>default = 'yeo-johnson'</em>) – </p></li>
<li><p><strong>the method for transformation. By default</strong><strong>, </strong><strong>the transformation method is set</strong> (<em>Defines</em>) – </p></li>
<li><p><strong>'yeo-johnson'. The other available option is 'quantile' transformation. Both</strong> (<em>to</em>) – </p></li>
<li><p><strong>transformation transforms the feature set to follow a Gaussian-like</strong><strong> or </strong><strong>normal</strong> (<em>the</em>) – </p></li>
<li><p><strong>Note that the quantile transformer is non-linear and may distort linear</strong> (<em>distribution.</em>) – </p></li>
<li><p><strong>between variables measured at the same scale.</strong> (<em>correlations</em>) – </p></li>
<li><p><strong>handle_unknown_categorical</strong> (<em>bool</em><em>, </em><em>default = True</em>) – </p></li>
<li><p><strong>set to True</strong><strong>, </strong><strong>unknown categorical levels in new / unseen data are replaced by</strong> (<em>When</em>) – </p></li>
<li><p><strong>most</strong><strong> or </strong><strong>least frequent level as learned in the training data. The method is</strong> (<em>the</em>) – </p></li>
<li><p><strong>under the unknown_categorical_method param.</strong> (<em>defined</em>) – </p></li>
<li><p><strong>unknown_categorical_method</strong> (<em>string</em><em>, </em><em>default = 'least_frequent'</em>) – </p></li>
<li><p><strong>used to replace unknown categorical levels in unseen data. Method can be</strong> (<em>Method</em>) – </p></li>
<li><p><strong>to 'least_frequent'</strong><strong> or </strong><strong>'most_frequent'.</strong> (<em>set</em>) – </p></li>
<li><p><strong>pca</strong> (<em>bool</em><em>, </em><em>default = False</em>) – </p></li>
<li><p><strong>set to True</strong><strong>, </strong><strong>dimensionality reduction is applied to project the data into</strong> (<em>When</em>) – </p></li>
<li><p><strong>lower dimensional space using the method defined in pca_method param. In</strong> (<em>a</em>) – </p></li>
<li><p><strong>learning pca is generally performed when dealing with high feature</strong> (<em>supervised</em>) – </p></li>
<li><p><strong>and memory is a constraint. Note that not all datasets can be decomposed</strong> (<em>space</em>) – </p></li>
<li><p><strong>using a linear PCA technique and that applying PCA may result in loss</strong> (<em>efficiently</em>) – </p></li>
<li><p><strong>information. As such</strong><strong>, </strong><strong>it is advised to run multiple experiments with different</strong> (<em>of</em>) – </p></li>
<li><p><strong>to evaluate the impact.</strong> (<em>pca_methods</em>) – </p></li>
<li><p><strong>pca_method</strong> (<em>string</em><em>, </em><em>default = 'linear'</em>) – </p></li>
<li><p><strong>'linear' method performs Linear dimensionality reduction using Singular Value</strong> (<em>The</em>) – </p></li>
<li><p><strong>The other available options are</strong> (<em>Decomposition.</em>) – </p></li>
<li><p><strong>kernel</strong> (<em>dimensionality reduction through the use of RVF kernel.</em>) – </p></li>
<li><p><strong>incremental</strong> (<em>replacement for 'linear' pca when the dataset to be decomposed is</em>) – too large to fit in memory</p></li>
<li><p><strong>pca_components</strong> (<em>int/float</em><em>, </em><em>default = 0.99</em>) – </p></li>
<li><p><strong>of components to keep. if pca_components is a float</strong><strong>, </strong><strong>it is treated as a</strong> (<em>Number</em>) – </p></li>
<li><p><strong>percentage for information retention. When pca_components is an integer</strong> (<em>target</em>) – </p></li>
<li><p><strong>is treated as the number of features to be kept. pca_components must be strictly</strong> (<em>it</em>) – </p></li>
<li><p><strong>than the original number of features in the dataset.</strong> (<em>less</em>) – </p></li>
<li><p><strong>ignore_low_variance</strong> (<em>bool</em><em>, </em><em>default = False</em>) – </p></li>
<li><p><strong>set to True</strong><strong>, </strong><strong>all categorical features with statistically insignificant variances</strong> (<em>When</em>) – </p></li>
<li><p><strong>removed from the dataset. The variance is calculated using the ratio of unique</strong> (<em>are</em>) – </p></li>
<li><p><strong>to the number of samples</strong><strong>, </strong><strong>and the ratio of the most common value to the</strong> (<em>values</em>) – </p></li>
<li><p><strong>of the second most common value.</strong> (<em>frequency</em>) – </p></li>
<li><p><strong>combine_rare_levels</strong> (<em>bool</em><em>, </em><em>default = False</em>) – </p></li>
<li><p><strong>set to True</strong><strong>, </strong><strong>all levels in categorical features below the threshold defined</strong> (<em>When</em>) – </p></li>
<li><p><strong>rare_level_threshold param are combined together as a single level. There must be</strong> (<em>in</em>) – </p></li>
<li><p><strong>two levels under the threshold for this to take effect. rare_level_threshold</strong> (<em>atleast</em>) – </p></li>
<li><p><strong>the percentile distribution of level frequency. Generally</strong><strong>, </strong><strong>this technique</strong> (<em>represents</em>) – </p></li>
<li><p><strong>applied to limit a sparse matrix caused by high numbers of levels in categorical</strong> (<em>is</em>) – </p></li>
<li><p><strong>features.</strong> – </p></li>
<li><p><strong>rare_level_threshold</strong> (<em>float</em><em>, </em><em>default = 0.1</em>) – </p></li>
<li><p><strong>distribution below which rare categories are combined. Only comes into</strong> (<em>Percentile</em>) – </p></li>
<li><p><strong>when combine_rare_levels is set to True.</strong> (<em>effect</em>) – </p></li>
<li><p><strong>bin_numeric_features</strong> (<em>list</em><em>, </em><em>default = None</em>) – </p></li>
<li><p><strong>a list of numeric features is passed they are transformed into categorical</strong> (<em>When</em>) – </p></li>
<li><p><strong>using KMeans</strong><strong>, </strong><strong>where values in each bin have the same nearest center of a</strong> (<em>features</em>) – </p></li>
<li><p><strong>k-means cluster. The number of clusters are determined based on the 'sturges'</strong> (<em>1D</em>) – </p></li>
<li><p><strong>It is only optimal for gaussian data and underestimates the number of bins</strong> (<em>method.</em>) – </p></li>
<li><p><strong>large non-gaussian datasets.</strong> (<em>for</em>) – </p></li>
<li><p><strong>remove_outliers</strong> (<em>bool</em><em>, </em><em>default = False</em>) – </p></li>
<li><p><strong>set to True</strong><strong>, </strong><strong>outliers from the training data are removed using PCA linear</strong> (<em>When</em>) – </p></li>
<li><p><strong>reduction using the Singular Value Decomposition technique.</strong> (<em>dimensionality</em>) – </p></li>
<li><p><strong>outliers_threshold</strong> (<em>float</em><em>, </em><em>default = 0.05</em>) – </p></li>
<li><p><strong>percentage / proportion of outliers in the dataset can be defined using</strong> (<em>The</em>) – </p></li>
<li><p><strong>outliers_threshold param. By default</strong><strong>, </strong><strong>0.05 is used which means 0.025 of the</strong> (<em>the</em>) – </p></li>
<li><p><strong>on each side of the distribution's tail are dropped from training data.</strong> (<em>values</em>) – </p></li>
<li><p><strong>remove_multicollinearity</strong> (<em>bool</em><em>, </em><em>default = False</em>) – </p></li>
<li><p><strong>set to True</strong><strong>, </strong><strong>the variables with inter-correlations higher than the threshold</strong> (<em>When</em>) – </p></li>
<li><p><strong>under the multicollinearity_threshold param are dropped. When two features</strong> (<em>defined</em>) – </p></li>
<li><p><strong>highly correlated with each other</strong><strong>, </strong><strong>the feature that is less correlated with</strong> (<em>are</em>) – </p></li>
<li><p><strong>target variable is dropped.</strong> (<em>the</em>) – </p></li>
<li><p><strong>multicollinearity_threshold</strong> (<em>float</em><em>, </em><em>default = 0.9</em>) – </p></li>
<li><p><strong>used for dropping the correlated features. Only comes into effect when</strong> (<em>Threshold</em>) – </p></li>
<li><p><strong>is set to True.</strong> (<em>remove_multicollinearity</em>) – </p></li>
<li><p><strong>create_clusters</strong> (<em>bool</em><em>, </em><em>default = False</em>) – </p></li>
<li><p><strong>set to True</strong><strong>, </strong><strong>an additional feature is created where each instance is assigned</strong> (<em>When</em>) – </p></li>
<li><p><strong>a cluster. The number of clusters is determined using a combination of</strong> (<em>to</em>) – </p></li>
<li><p><strong>and Silhouette criterion.</strong> (<em>Calinski-Harabasz</em>) – </p></li>
<li><p><strong>cluster_iter</strong> (<em>int</em><em>, </em><em>default = 20</em>) – </p></li>
<li><p><strong>of iterations used to create a cluster. Each iteration represents cluster</strong> (<em>Number</em>) – </p></li>
<li><p><strong>Only comes into effect when create_clusters param is set to True.</strong> (<em>size.</em>) – </p></li>
<li><p><strong>polynomial_features</strong> (<em>bool</em><em>, </em><em>default = False</em>) – </p></li>
<li><p><strong>set to True</strong><strong>, </strong><strong>new features are created based on all polynomial combinations</strong> (<em>When</em>) – </p></li>
<li><p><strong>exist within the numeric features in a dataset to the degree defined in</strong> (<em>that</em>) – </p></li>
<li><p><strong>param.</strong> (<em>polynomial_degree</em>) – </p></li>
<li><p><strong>polynomial_degree</strong> (<em>int</em><em>, </em><em>default = 2</em>) – </p></li>
<li><p><strong>of polynomial features. For example</strong><strong>, </strong><strong>if an input sample is two dimensional</strong> (<em>Degree</em>) – </p></li>
<li><p><strong>of the form</strong><strong> [</strong><strong>a</strong><strong>, </strong><strong>b</strong><strong>]</strong><strong>, </strong><strong>the polynomial features with degree = 2 are</strong> (<em>and</em>) – </p></li>
<li><p><strong>a</strong><strong>, </strong><strong>b</strong><strong>, </strong><strong>a^2</strong><strong>, </strong><strong>ab</strong><strong>, </strong><strong>b^2</strong><strong>]</strong><strong></strong> (<em>[</em><em>1</em><em>,</em>) – </p></li>
<li><p><strong>trigonometry_features</strong> (<em>bool</em><em>, </em><em>default = False</em>) – </p></li>
<li><p><strong>set to True</strong><strong>, </strong><strong>new features are created based on all trigonometric combinations</strong> (<em>When</em>) – </p></li>
<li><p><strong>exist within the numeric features in a dataset to the degree defined in the</strong> (<em>that</em>) – </p></li>
<li><p><strong>param.</strong> – </p></li>
<li><p><strong>polynomial_threshold</strong> (<em>float</em><em>, </em><em>default = 0.1</em>) – </p></li>
<li><p><strong>is used to compress a sparse matrix of polynomial and trigonometric features.</strong> (<em>This</em>) – </p></li>
<li><p><strong>and trigonometric features whose feature importance based on the</strong> (<em>Polynomial</em>) – </p></li>
<li><p><strong>of Random Forest</strong><strong>, </strong><strong>AdaBoost and Linear correlation falls within the</strong> (<em>combination</em>) – </p></li>
<li><p><strong>of the defined threshold are kept in the dataset. Remaining features</strong> (<em>percentile</em>) – </p></li>
<li><p><strong>dropped before further processing.</strong> (<em>are</em>) – </p></li>
<li><p><strong>group_features</strong> (<em>list</em><em> or </em><em>list of list</em><em>, </em><em>default = None</em>) – </p></li>
<li><p><strong>a dataset contains features that have related characteristics</strong><strong>, </strong><strong>the group_features</strong> (<em>When</em>) – </p></li>
<li><p><strong>can be used for statistical feature extraction. For example</strong><strong>, </strong><strong>if a dataset has</strong> (<em>param</em>) – </p></li>
<li><p><strong>features that are related with each other</strong><strong> (</strong><strong>i.e 'Col1'</strong><strong>, </strong><strong>'Col2'</strong><strong>, </strong><strong>'Col3'</strong><strong>)</strong><strong>, </strong><strong>a list</strong> (<em>numeric</em>) – </p></li>
<li><p><strong>the column names can be passed under group_features to extract statistical</strong> (<em>containing</em>) – </p></li>
<li><p><strong>such as the mean</strong><strong>, </strong><strong>median</strong><strong>, </strong><strong>mode and standard deviation.</strong> (<em>information</em>) – </p></li>
<li><p><strong>group_names</strong> (<em>list</em><em>, </em><em>default = None</em>) – </p></li>
<li><p><strong>group_features is passed</strong><strong>, </strong><strong>a name of the group can be passed into the group_names</strong> (<em>When</em>) – </p></li>
<li><p><strong>as a list containing strings. The length of a group_names list must equal to the</strong> (<em>param</em>) – </p></li>
<li><p><strong>of group_features. When the length doesn't match</strong><strong> or </strong><strong>the name is not passed</strong><strong>, </strong><strong>new</strong> (<em>length</em>) – </p></li>
<li><p><strong>are sequentially named such as group_1</strong><strong>, </strong><strong>group_2 etc.</strong> (<em>features</em>) – </p></li>
<li><p><strong>feature_selection</strong> (<em>bool</em><em>, </em><em>default = False</em>) – </p></li>
<li><p><strong>set to True</strong><strong>, </strong><strong>a subset of features are selected using a combination of various</strong> (<em>When</em>) – </p></li>
<li><p><strong>importance techniques including Random Forest</strong><strong>, </strong><strong>Adaboost and Linear</strong> (<em>permutation</em>) – </p></li>
<li><p><strong>with target variable. The size of the subset is dependent on the</strong> (<em>correlation</em>) – </p></li>
<li><p><strong>Generally</strong><strong>, </strong><strong>this is used to constrain the feature space</strong> (<em>feature_selection_param.</em>) – </p></li>
<li><p><strong>order to improve efficiency in modeling. When polynomial_features and</strong> (<em>in</em>) – </p></li>
<li><p><strong>are used</strong><strong>, </strong><strong>it is highly recommended to define the</strong> (<em>feature_interaction</em>) – </p></li>
<li><p><strong>param with a lower value.</strong> (<em>feature_selection_threshold</em>) – </p></li>
<li><p><strong>feature_selection_threshold</strong> (<em>float</em><em>, </em><em>default = 0.8</em>) – </p></li>
<li><p><strong>used for feature selection</strong><strong> (</strong><strong>including newly created polynomial features</strong><strong>)</strong><strong></strong> (<em>Threshold</em>) – </p></li>
<li><p><strong>higher value will result in a higher feature space. It is recommended to do multiple</strong> (<em>A</em>) – </p></li>
<li><p><strong>with different values of feature_selection_threshold specially in cases where</strong> (<em>trials</em>) – </p></li>
<li><p><strong>and feature_interaction are used. Setting a very low value may be</strong> (<em>polynomial_features</em>) – </p></li>
<li><p><strong>but could result in under-fitting.</strong> (<em>efficient</em>) – </p></li>
<li><p><strong>feature_interaction</strong> (<em>bool</em><em>, </em><em>default = False</em>) – </p></li>
<li><p><strong>set to True</strong><strong>, </strong><strong>it will create new features by interacting</strong><strong> (</strong><strong>a * b</strong><strong>) </strong><strong>for all numeric</strong> (<em>When</em>) – </p></li>
<li><p><strong>in the dataset including polynomial and trigonometric features</strong><strong> (</strong><strong>if created</strong><strong>)</strong><strong></strong> (<em>variables</em>) – </p></li>
<li><p><strong>feature is not scalable and may not work as expected on datasets with large</strong> (<em>This</em>) – </p></li>
<li><p><strong>space.</strong> (<em>feature</em>) – </p></li>
<li><p><strong>feature_ratio</strong> (<em>bool</em><em>, </em><em>default = False</em>) – </p></li>
<li><p><strong>set to True</strong><strong>, </strong><strong>it will create new features by calculating the ratios</strong><strong> (</strong><strong>a / b</strong><strong>) </strong><strong>of all</strong> (<em>When</em>) – </p></li>
<li><p><strong>variables in the dataset. This feature is not scalable and may not work as</strong> (<em>numeric</em>) – </p></li>
<li><p><strong>on datasets with large feature space.</strong> (<em>expected</em>) – </p></li>
<li><p><strong>interaction_threshold</strong> (<em>bool</em><em>, </em><em>default = 0.01</em>) – </p></li>
<li><p><strong>to polynomial_threshold</strong><strong>, </strong><strong>It is used to compress a sparse matrix of newly</strong> (<em>Similar</em>) – </p></li>
<li><p><strong>features through interaction. Features whose importance based on the</strong> (<em>created</em>) – </p></li>
<li><p><strong>of  Random Forest</strong><strong>, </strong><strong>AdaBoost and Linear correlation falls within the</strong> (<em>combination</em>) – </p></li>
<li><p><strong>of the  defined threshold are kept in the dataset. Remaining features</strong> (<em>percentile</em>) – </p></li>
<li><p><strong>dropped before further processing.</strong> – </p></li>
<li><p><strong>transform_target</strong> (<em>bool</em><em>, </em><em>default = False</em>) – </p></li>
<li><p><strong>set to True</strong><strong>, </strong><strong>target variable is transformed using the method defined in</strong> (<em>When</em>) – </p></li>
<li><p><strong>param. Target transformation is applied separately from</strong> (<em>transform_target_method</em>) – </p></li>
<li><p><strong>transformations.</strong> (<em>feature</em>) – </p></li>
<li><p><strong>transform_target_method</strong> (<em>string</em><em>, </em><em>default = 'box-cox'</em>) – </p></li>
<li><p><strong>and 'yeo-johnson' methods are supported. Box-Cox requires input data to</strong> (<em>'Box-cox'</em>) – </p></li>
<li><p><strong>strictly positive</strong><strong>, </strong><strong>while Yeo-Johnson supports both positive</strong><strong> or </strong><strong>negative data.</strong> (<em>be</em>) – </p></li>
<li><p><strong>transform_target_method is 'box-cox' and target variable contains negative</strong> (<em>When</em>) – </p></li>
<li><p><strong>method is internally forced to 'yeo-johnson' to avoid exceptions.</strong> (<em>values</em><em>,</em>) – </p></li>
<li><p><strong>data_split_shuffle</strong> (<em>bool</em><em>, </em><em>default = True</em>) – </p></li>
<li><p><strong>set to False</strong><strong>, </strong><strong>prevents shuffling of rows when splitting data</strong> (<em>If</em>) – </p></li>
<li><p><strong>folds_shuffle</strong> (<em>bool</em><em>, </em><em>default = True</em>) – </p></li>
<li><p><strong>set to False</strong><strong>, </strong><strong>prevents shuffling of rows when using cross validation</strong> (<em>If</em>) – </p></li>
<li><p><strong>n_jobs</strong> (<em>int</em><em>, </em><em>default = -1</em>) – </p></li>
<li><p><strong>number of jobs to run in parallel</strong><strong> (</strong><strong>for functions that supports parallel</strong> (<em>The</em>) – </p></li>
<li><p><strong>-1 means using all processors. To run all functions on single processor</strong> (<em>processing</em><em>)</em>) – </p></li>
<li><p><strong>n_jobs to None.</strong> (<em>set</em>) – </p></li>
<li><p><strong>html</strong> (<em>bool</em><em>, </em><em>default = True</em>) – </p></li>
<li><p><strong>set to False</strong><strong>, </strong><strong>prevents runtime display of monitor. This must be set to False</strong> (<em>If</em>) – </p></li>
<li><p><strong>using environment that doesnt support HTML.</strong> (<em>when</em>) – </p></li>
<li><p><strong>session_id</strong> (<em>int</em><em>, </em><em>default = None</em>) – </p></li>
<li><p><strong>None</strong><strong>, </strong><strong>a random seed is generated and returned in the Information grid. The</strong> (<em>If</em>) – </p></li>
<li><p><strong>number is then distributed as a seed in all functions used during the</strong> (<em>unique</em>) – </p></li>
<li><p><strong>This can be used for later reproducibility of the entire experiment.</strong> (<em>experiment.</em>) – </p></li>
<li><p><strong>silent</strong> (<em>bool</em><em>, </em><em>default = False</em>) – </p></li>
<li><p><strong>set to True</strong><strong>, </strong><strong>confirmation of data types is not required. All preprocessing will</strong> (<em>When</em>) – </p></li>
<li><p><strong>performed assuming automatically inferred data types. Not recommended for direct use</strong> (<em>be</em>) – </p></li>
<li><p><strong>for established pipelines.</strong> (<em>except</em>) – </p></li>
<li><p><strong>verbose</strong> (<em>Boolean</em><em>, </em><em>default = True</em>) – </p></li>
<li><p><strong>grid is not printed when verbose is set to False.</strong> (<em>Information</em>) – </p></li>
<li><p><strong>profile</strong> (<em>bool</em><em>, </em><em>default = False</em>) – </p></li>
<li><p><strong>set to true</strong><strong>, </strong><strong>a data profile for Exploratory Data Analysis will be displayed</strong> (<em>If</em>) – </p></li>
<li><p><strong>an interactive HTML report.</strong> (<em>in</em>) – </p></li>
<li><p><strong>Returns</strong> – </p></li>
<li><p><strong>--------</strong> – </p></li>
<li><p><strong>grid</strong> (<em>info</em>) – </p></li>
<li><p><strong>-----------</strong> – </p></li>
<li><p><strong>environment</strong> (<em>This function returns various outputs that are stored in variable</em>) – </p></li>
<li><p><strong>as tuple. They are used by other functions in pycaret.</strong> (<em>-----------</em>) – </p></li>
<li><p><strong>Warnings</strong> – </p></li>
<li><p><strong>---------</strong> – </p></li>
<li><p><strong>None</strong> – </p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pycaret.regression.stack_models">
<code class="sig-prename descclassname">pycaret.regression.</code><code class="sig-name descname">stack_models</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">estimator_list</span></em>, <em class="sig-param"><span class="n">meta_model</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">fold</span><span class="o">=</span><span class="default_value">10</span></em>, <em class="sig-param"><span class="n">round</span><span class="o">=</span><span class="default_value">4</span></em>, <em class="sig-param"><span class="n">restack</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">plot</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">improve_only</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">optimize</span><span class="o">=</span><span class="default_value">'r2'</span></em>, <em class="sig-param"><span class="n">finalize</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.regression.stack_models" title="Permalink to this definition">¶</a></dt>
<dd><p>This function creates a meta model and scores it using Kfold Cross Validation.
The predictions from the base level models as passed in the estimator_list param
are used as input features for the meta model. The restacking parameter controls
the ability to expose raw features to the meta model when set to True
(default = False).</p>
<p>The output prints a score grid that shows MAE, MSE, RMSE, R2, RMSLE and MAPE by
fold (default = 10 Folds).</p>
<p>This function returns a container which is the list of all models in stacking.</p>
<blockquote>
<div><p>from pycaret.datasets import get_data
boston = get_data(‘boston’)
experiment_name = setup(data = boston,  target = ‘medv’)
dt = create_model(‘dt’)
rf = create_model(‘rf’)
ada = create_model(‘ada’)
ridge = create_model(‘ridge’)
knn = create_model(‘knn’)</p>
<p>stacked_models = stack_models(estimator_list=[dt,rf,ada,ridge,knn])</p>
<p>This will create a meta model that will use the predictions of all the
models provided in estimator_list param. By default, the meta model is
Linear Regression but can be changed with meta_model param.</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>estimator_list</strong> (<em>list of object</em>) – </p></li>
<li><p><strong>meta_model</strong> (<em>object</em><em>, </em><em>default = None</em>) – </p></li>
<li><p><strong>set to None</strong><strong>, </strong><strong>Linear Regression is used as a meta model.</strong> (<em>if</em>) – </p></li>
<li><p><strong>fold</strong> (<em>integer</em><em>, </em><em>default = 10</em>) – </p></li>
<li><p><strong>of folds to be used in Kfold CV. Must be at least 2.</strong> (<em>Number</em>) – </p></li>
<li><p><strong>round</strong> (<em>integer</em><em>, </em><em>default = 4</em>) – </p></li>
<li><p><strong>of decimal places the metrics in the score grid will be rounded to.</strong> (<em>Number</em>) – </p></li>
<li><p><strong>restack</strong> (<em>Boolean</em><em>, </em><em>default = True</em>) – </p></li>
<li><p><strong>restack is set to True</strong><strong>, </strong><strong>raw data will be exposed to meta model when</strong> (<em>When</em>) – </p></li>
<li><p><strong>predictions</strong><strong>, </strong><strong>otherwise when False</strong><strong>, </strong><strong>only the predicted label is passed</strong> (<em>making</em>) – </p></li>
<li><p><strong>meta model when making final predictions.</strong> (<em>to</em>) – </p></li>
<li><p><strong>plot</strong> (<em>Boolean</em><em>, </em><em>default = False</em>) – </p></li>
<li><p><strong>plot is set to True</strong><strong>, </strong><strong>it will return the correlation plot of prediction</strong> (<em>When</em>) – </p></li>
<li><p><strong>all base models provided in estimator_list.</strong> (<em>from</em>) – </p></li>
<li><p><strong>improve_only</strong> (<em>Boolean</em><em>, </em><em>default = True</em>) – </p></li>
<li><p><strong>set to True</strong><strong>, </strong><strong>base estimator is returned when the metric doesn't</strong> (<em>When</em>) – </p></li>
<li><p><strong>by ensemble_model. This gurantees the returned object would perform</strong> (<em>improve</em>) – </p></li>
<li><p><strong>equivalent to base estimator created using create_model</strong><strong> or </strong><strong>model</strong> (<em>atleast</em>) – </p></li>
<li><p><strong>by compare_models.</strong> (<em>returned</em>) – </p></li>
<li><p><strong>optimize</strong> (<em>string</em><em>, </em><em>default = 'r2'</em>) – </p></li>
<li><p><strong>used when improve_only is set to True. optimize parameter is used</strong> (<em>Only</em>) – </p></li>
<li><p><strong>compare emsembled model with base estimator. Values accepted in</strong> (<em>to</em>) – </p></li>
<li><p><strong>parameter are 'mae'</strong><strong>, </strong><strong>'mse'</strong><strong>, </strong><strong>'rmse'</strong><strong>, </strong><strong>'r2'</strong><strong>, </strong><strong>'rmsle'</strong><strong>, </strong><strong>'mape'.</strong> (<em>optimize</em>) – </p></li>
<li><p><strong>finalize</strong> (<em>Boolean</em><em>, </em><em>default = False</em>) – </p></li>
<li><p><strong>finalize is set to True</strong><strong>, </strong><strong>it will fit the stacker on entire dataset</strong> (<em>When</em>) – </p></li>
<li><p><strong>the hold-out sample created during the setup</strong><strong>(</strong><strong>) </strong><strong>stage. It is not</strong> (<em>including</em>) – </p></li>
<li><p><strong>to set this to True here</strong><strong>, </strong><strong>If you would like to fit the stacker</strong> (<em>recommended</em>) – </p></li>
<li><p><strong>the entire dataset including the hold-out</strong><strong>, </strong><strong>use finalize_model</strong><strong>(</strong><strong>)</strong><strong></strong> (<em>on</em>) – </p></li>
<li><p><strong>verbose</strong> (<em>Boolean</em><em>, </em><em>default = True</em>) – </p></li>
<li><p><strong>grid is not printed when verbose is set to False.</strong> (<em>Score</em>) – </p></li>
<li><p><strong>Returns</strong> – </p></li>
<li><p><strong>--------</strong> – </p></li>
<li><p><strong>grid</strong> (<em>score</em>) – </p></li>
<li><p><strong>Scoring metrics used are MAE</strong><strong>, </strong><strong>MSE</strong><strong>, </strong><strong>RMSE</strong><strong>, </strong><strong>R2</strong><strong>, </strong><strong>RMSLE and MAPE.</strong> (<em>-----------</em>) – Mean and standard deviation of the scores across the folds are
also returned.</p></li>
<li><p><strong>container</strong> (<em>list of all the models where last element is meta model.</em>) – </p></li>
<li><p><strong>----------</strong> – </p></li>
<li><p><strong>Warnings</strong> – </p></li>
<li><p><strong>---------</strong> – </p></li>
<li><p><strong>None</strong> – </p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pycaret.regression.tune_model">
<code class="sig-prename descclassname">pycaret.regression.</code><code class="sig-name descname">tune_model</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">estimator</span></em>, <em class="sig-param"><span class="n">fold</span><span class="o">=</span><span class="default_value">10</span></em>, <em class="sig-param"><span class="n">round</span><span class="o">=</span><span class="default_value">4</span></em>, <em class="sig-param"><span class="n">n_iter</span><span class="o">=</span><span class="default_value">10</span></em>, <em class="sig-param"><span class="n">custom_grid</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">optimize</span><span class="o">=</span><span class="default_value">'r2'</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">improve_only</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.regression.tune_model" title="Permalink to this definition">¶</a></dt>
<dd><p>This function tunes the hyperparameters of a model and scores it using Kfold
Cross Validation. The output prints the score grid that shows MAE, MSE, RMSE,
R2, RMSLE and MAPE by fold (by default = 10 Folds).</p>
<p>This function returns a trained model object.</p>
<p>tune_model() only accepts a string parameter for estimator.</p>
<blockquote>
<div><p>from pycaret.datasets import get_data
boston = get_data(‘boston’)
experiment_name = setup(data = boston,  target = ‘medv’)</p>
<p>tuned_xgboost = tune_model(‘xgboost’)</p>
<p>This will tune the hyperparameters of Extreme Gradient Boosting Regressor.</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>estimator</strong> (<em>string</em><em>, </em><em>default = None</em>) – </p></li>
<li><p><strong>abbreviated name of the estimator class. List of estimators supported</strong> (<em>Enter</em>) – </p></li>
<li><p><strong>Abbreviated String    Original Implementation</strong> (<em>Estimator</em>) – </p></li>
<li><p><strong>------------------    -----------------------</strong> (<em>---------</em>) – </p></li>
<li><p><strong>Regression             'lr'                  linear_model.LinearRegression</strong> (<em>Linear</em>) – </p></li>
<li><p><strong>Regression              'lasso'               linear_model.Lasso</strong> (<em>Lasso</em>) – </p></li>
<li><p><strong>Regression              'ridge'               linear_model.Ridge</strong> (<em>Ridge</em>) – </p></li>
<li><p><strong>Net                   'en'                  linear_model.ElasticNet</strong> (<em>Elastic</em>) – </p></li>
<li><p><strong>Angle Regression        'lar'                 linear_model.Lars</strong> (<em>Least</em>) – </p></li>
<li><p><strong>Least Angle Regression  'llar'                linear_model.LassoLars</strong> (<em>Lasso</em>) – </p></li>
<li><p><strong>Matching Pursuit   'omp'                 linear_model.OMP</strong> (<em>Orthogonal</em>) – </p></li>
<li><p><strong>Ridge                'br'                  linear_model.BayesianRidge</strong> (<em>Bayesian</em>) – </p></li>
<li><p><strong>Relevance Determ.   'ard'                 linear_model.ARDRegression</strong> (<em>Automatic</em>) – </p></li>
<li><p><strong>Aggressive Regressor  'par'                 linear_model.PAR</strong> (<em>Passive</em>) – </p></li>
<li><p><strong>Sample Consensus       'ransac'              linear_model.RANSACRegressor</strong> (<em>Random</em>) – </p></li>
<li><p><strong>Regressor            'tr'                  linear_model.TheilSenRegressor</strong> (<em>TheilSen</em>) – </p></li>
<li><p><strong>Regressor               'huber'               linear_model.HuberRegressor</strong> (<em>Huber</em>) – </p></li>
<li><p><strong>Ridge                  'kr'                  kernel_ridge.KernelRidge</strong> (<em>Kernel</em>) – </p></li>
<li><p><strong>Vector Machine        'svm'                 svm.SVR</strong> (<em>Support</em>) – </p></li>
<li><p><strong>Neighbors Regressor         'knn'                 neighbors.KNeighborsRegressor</strong> (<em>K</em>) – </p></li>
<li><p><strong>Tree                 'dt'                  tree.DecisionTreeRegressor</strong> (<em>Decision</em>) – </p></li>
<li><p><strong>Forest                 'rf'                  ensemble.RandomForestRegressor</strong> (<em>Random</em>) – </p></li>
<li><p><strong>Trees Regressor         'et'                  ensemble.ExtraTreesRegressor</strong> (<em>Extra</em>) – </p></li>
<li><p><strong>Regressor            'ada'                 ensemble.AdaBoostRegressor</strong> (<em>AdaBoost</em>) – </p></li>
<li><p><strong>Boosting             'gbr'                 ensemble.GradientBoostingRegressor</strong> (<em>Gradient</em>) – </p></li>
<li><p><strong>Level Perceptron        'mlp'                 neural_network.MLPRegressor</strong> (<em>Multi</em>) – </p></li>
<li><p><strong>Gradient Boosting     'xgboost'             xgboost.readthedocs.io</strong> (<em>Extreme</em>) – </p></li>
<li><p><strong>Gradient Boosting       'lightgbm'            github.com/microsoft/LightGBM</strong> (<em>Light</em>) – </p></li>
<li><p><strong>Regressor            'catboost'            https</strong> (<em>CatBoost</em>) – </p></li>
<li><p><strong>fold</strong> (<em>integer</em><em>, </em><em>default = 10</em>) – </p></li>
<li><p><strong>of folds to be used in Kfold CV. Must be at least 2.</strong> (<em>Number</em>) – </p></li>
<li><p><strong>round</strong> (<em>integer</em><em>, </em><em>default = 4</em>) – </p></li>
<li><p><strong>of decimal places the metrics in the score grid will be rounded to.</strong> (<em>Number</em>) – </p></li>
<li><p><strong>n_iter</strong> (<em>integer</em><em>, </em><em>default = 10</em>) – </p></li>
<li><p><strong>of iterations within the Random Grid Search. For every iteration</strong><strong>,</strong> (<em>Number</em>) – </p></li>
<li><p><strong>model randomly selects one value from the pre-defined grid of hyperparameters.</strong> (<em>the</em>) – </p></li>
<li><p><strong>optimize</strong> (<em>string</em><em>, </em><em>default = 'r2'</em>) – </p></li>
<li><p><strong>used to select the best model through hyperparameter tuning.</strong> (<em>Measure</em>) – </p></li>
<li><p><strong>default scoring measure is 'r2'. Other measures include 'mae'</strong><strong>, </strong><strong>'mse'</strong><strong>, </strong><strong>'rmse'</strong><strong>,</strong> (<em>The</em>) – </p></li>
<li><p><strong>'mape'. When using 'rmse'</strong><strong> or </strong><strong>'rmsle' the base scorer is 'mse' and when using</strong> (<em>'rmsle'</em><em>,</em>) – </p></li>
<li><p><strong>the base scorer is 'mae'.</strong> (<em>'mape'</em>) – </p></li>
<li><p><strong>verbose</strong> (<em>Boolean</em><em>, </em><em>default = True</em>) – </p></li>
<li><p><strong>grid is not printed when verbose is set to False.</strong> (<em>Score</em>) – </p></li>
<li><p><strong>improve_only</strong> (<em>Boolean</em><em>, </em><em>default = True</em>) – </p></li>
<li><p><strong>set to set to True</strong><strong>, </strong><strong>base estimator is returned when the metric doesn't improve</strong> (<em>When</em>) – </p></li>
<li><p><strong>tune_model. This gurantees the returned object would perform atleast equivalent</strong> (<em>by</em>) – </p></li>
<li><p><strong>base estimator created using create_model</strong><strong> or </strong><strong>model returned by compare_models.</strong> (<em>to</em>) – </p></li>
<li><p><strong>Returns</strong> – </p></li>
<li><p><strong>--------</strong> – </p></li>
<li><p><strong>grid</strong> (<em>score</em>) – </p></li>
<li><p><strong>Scoring metrics used are MAE</strong><strong>, </strong><strong>MSE</strong><strong>, </strong><strong>RMSE</strong><strong>, </strong><strong>R2</strong><strong>, </strong><strong>RMSLE and MAPE.</strong> (<em>-----------</em>) – Mean and standard deviation of the scores across the folds are
also returned.</p></li>
<li><p><strong>model</strong> (<em>trained model object</em>) – </p></li>
<li><p><strong>-----------</strong> – </p></li>
<li><p><strong>Warnings</strong> – </p></li>
<li><p><strong>---------</strong> – </p></li>
<li><p><strong>estimator parameter takes an abbreviated string. Passing a trained model object</strong> (<em>-</em>) – returns an error. The tune_model() function internally calls create_model()
before tuning the hyperparameters.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-pycaret.nlp">
<span id="nlp"></span><h1>NLP<a class="headerlink" href="#module-pycaret.nlp" title="Permalink to this headline">¶</a></h1>
<dl class="py function">
<dt id="pycaret.nlp.assign_model">
<code class="sig-prename descclassname">pycaret.nlp.</code><code class="sig-name descname">assign_model</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">model</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.nlp.assign_model" title="Permalink to this definition">¶</a></dt>
<dd><p>This function assigns each of the data point in the dataset passed during setup
stage to one of the topic using trained model object passed as model param.
create_model() function must be called before using assign_model().</p>
<p>This function returns dataframe with topic weights, dominant topic and % of the
dominant topic (where applicable).</p>
<blockquote>
<div><p>from pycaret.datasets import get_data
kiva = get_data(‘kiva’)
experiment_name = setup(data = kiva, target = ‘en’)
lda = create_model(‘lda’)</p>
<p>lda_df = assign_model(lda)</p>
<p>This will return a dataframe with inferred topics using trained model.</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>trained model object</em><em>, </em><em>default = None</em>) – </p></li>
<li><p><strong>verbose</strong> (<em>Boolean</em><em>, </em><em>default = True</em>) – </p></li>
<li><p><strong>update is not printed when verbose is set to False.</strong> (<em>Status</em>) – </p></li>
<li><p><strong>Returns</strong> – </p></li>
<li><p><strong>--------</strong> – </p></li>
<li><p><strong>dataframe</strong> (<em>Returns dataframe with inferred topics using trained model object.</em>) – </p></li>
<li><p><strong>---------</strong> – </p></li>
<li><p><strong>Warnings</strong> – </p></li>
<li><p><strong>---------</strong> – </p></li>
<li><p><strong>None</strong> – </p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pycaret.nlp.create_model">
<code class="sig-prename descclassname">pycaret.nlp.</code><code class="sig-name descname">create_model</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">model</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">multi_core</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">num_topics</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.nlp.create_model" title="Permalink to this definition">¶</a></dt>
<dd><p>This function creates a model on the dataset passed as a data param during
the setup stage. setup() function must be called before using create_model().</p>
<p>This function returns a trained model object.</p>
<blockquote>
<div><p>from pycaret.datasets import get_data
kiva = get_data(‘kiva’)
experiment_name = setup(data = kiva, target = ‘en’)</p>
<p>lda = create_model(‘lda’)</p>
<p>This will return trained Latent Dirichlet Allocation model.</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>trained model object</em>) – </p></li>
<li><p><strong>abbreviated string of the model class. List of models supported</strong> (<em>Enter</em>) – </p></li>
<li><p><strong>Abbreviated String   Original Implementation</strong> (<em>Model</em>) – </p></li>
<li><p><strong>------------------   -----------------------</strong> (<em>---------</em>) – </p></li>
<li><p><strong>Dirichlet Allocation        'lda'                gensim/models/ldamodel.html</strong> (<em>Latent</em>) – </p></li>
<li><p><strong>Semantic Indexing           'lsi'                gensim/models/lsimodel.html</strong> (<em>Latent</em>) – </p></li>
<li><p><strong>Dirichlet Process     'hdp'                gensim/models/hdpmodel.html</strong> (<em>Hierarchical</em>) – </p></li>
<li><p><strong>Projections                 'rp'                 gensim/models/rpmodel.html</strong> (<em>Random</em>) – </p></li>
<li><p><strong>Matrix Factorization  'nmf'                sklearn.decomposition.NMF.html</strong> (<em>Non-Negative</em>) – </p></li>
<li><p><strong>multi_core</strong> (<em>Boolean</em><em>, </em><em>default = False</em>) – </p></li>
<li><p><strong>would utilize all CPU cores to parallelize and speed up model training. Only</strong> (<em>True</em>) – </p></li>
<li><p><strong>for 'lda'. For all other models</strong><strong>, </strong><strong>the multi_core parameter is ignored.</strong> (<em>available</em>) – </p></li>
<li><p><strong>num_topics</strong> (<em>integer</em><em>, </em><em>default = 4</em>) – </p></li>
<li><p><strong>of topics to be created. If None</strong><strong>, </strong><strong>default is set to 4.</strong> (<em>Number</em>) – </p></li>
<li><p><strong>verbose</strong> (<em>Boolean</em><em>, </em><em>default = True</em>) – </p></li>
<li><p><strong>update is not printed when verbose is set to False.</strong> (<em>Status</em>) – </p></li>
<li><p><strong>Returns</strong> – </p></li>
<li><p><strong>--------</strong> – </p></li>
<li><p><strong>model</strong> – </p></li>
<li><p><strong>------</strong> – </p></li>
<li><p><strong>Warnings</strong> – </p></li>
<li><p><strong>---------</strong> – </p></li>
<li><p><strong>None</strong> – </p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pycaret.nlp.evaluate_model">
<code class="sig-prename descclassname">pycaret.nlp.</code><code class="sig-name descname">evaluate_model</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">model</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.nlp.evaluate_model" title="Permalink to this definition">¶</a></dt>
<dd><p>This function displays the user interface for all the available plots
for a given model. It internally uses the plot_model() function.</p>
<blockquote>
<div><p>from pycaret.datasets import get_data
kiva = get_data(‘kiva’)
experiment_name = setup(data = kiva, target = ‘en’)
lda = create_model(‘lda’)</p>
<p>evaluate_model(lda)</p>
<p>This will display the User Interface for all of the plots for
given model.</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>object</em><em>, </em><em>default = none</em>) – </p></li>
<li><p><strong>trained model object should be passed.</strong> (<em>A</em>) – </p></li>
<li><p><strong>Returns</strong> – </p></li>
<li><p><strong>--------</strong> – </p></li>
<li><p><strong>Interface</strong> (<em>User</em>) – </p></li>
<li><p><strong>--------------</strong> – </p></li>
<li><p><strong>Warnings</strong> – </p></li>
<li><p><strong>---------</strong> – </p></li>
<li><p><strong>None</strong> – </p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pycaret.nlp.get_topics">
<code class="sig-prename descclassname">pycaret.nlp.</code><code class="sig-name descname">get_topics</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">text</span></em>, <em class="sig-param"><span class="n">model</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">num_topics</span><span class="o">=</span><span class="default_value">4</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.nlp.get_topics" title="Permalink to this definition">¶</a></dt>
<dd><p>Magic function to get topic model in Power Query / Power BI.</p>
</dd></dl>

<dl class="py function">
<dt id="pycaret.nlp.load_experiment">
<code class="sig-prename descclassname">pycaret.nlp.</code><code class="sig-name descname">load_experiment</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">experiment_name</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.nlp.load_experiment" title="Permalink to this definition">¶</a></dt>
<dd><p>This function loads a previously saved experiment from the current active
directory into current python environment. Load object must be a pickle file.</p>
<blockquote>
<div><p>saved_experiment = load_experiment(‘experiment_23122019’)</p>
<p>This will load the entire experiment pipeline into the object
saved_experiment. The experiment file must be in current directory.</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>experiment_name</strong> (<em>string</em><em>, </em><em>default = none</em>) – </p></li>
<li><p><strong>of pickle file to be passed as a string.</strong> (<em>Name</em>) – </p></li>
<li><p><strong>Returns</strong> – </p></li>
<li><p><strong>--------</strong> – </p></li>
<li><p><strong>Grid containing details of saved objects in experiment pipeline.</strong> (<em>Information</em>) – </p></li>
<li><p><strong>Warnings</strong> – </p></li>
<li><p><strong>---------</strong> – </p></li>
<li><p><strong>None</strong> – </p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pycaret.nlp.load_model">
<code class="sig-prename descclassname">pycaret.nlp.</code><code class="sig-name descname">load_model</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">model_name</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.nlp.load_model" title="Permalink to this definition">¶</a></dt>
<dd><p>This function loads a previously saved model from the current active directory
into the current python environment. Load object must be a pickle file.</p>
<blockquote>
<div><p>saved_lda = load_model(‘lda_model_23122019’)</p>
<p>This will call the trained model in saved_lr variable using model_name param.
The file must be in current directory.</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_name</strong> (<em>string</em><em>, </em><em>default = none</em>) – </p></li>
<li><p><strong>of pickle file to be passed as a string.</strong> (<em>Name</em>) – </p></li>
<li><p><strong>Returns</strong> – </p></li>
<li><p><strong>--------</strong> – </p></li>
<li><p><strong>Message</strong> (<em>Success</em>) – </p></li>
<li><p><strong>Warnings</strong> – </p></li>
<li><p><strong>---------</strong> – </p></li>
<li><p><strong>None</strong> – </p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pycaret.nlp.plot_model">
<code class="sig-prename descclassname">pycaret.nlp.</code><code class="sig-name descname">plot_model</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">model</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">plot</span><span class="o">=</span><span class="default_value">'frequency'</span></em>, <em class="sig-param"><span class="n">topic_num</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.nlp.plot_model" title="Permalink to this definition">¶</a></dt>
<dd><p>This function takes a trained model object (optional) and returns a plot based
on the inferred dataset by internally calling assign_model before generating a
plot. Where a model parameter is not passed, a plot on the entire dataset will
be returned instead of one at the topic level. As such, plot_model can be used
with or without model. All plots with a model parameter passed as a trained
model object will return a plot based on the first topic i.e.  ‘Topic 0’. This
can be changed using the topic_num param.</p>
<blockquote>
<div><p>from pycaret.datasets import get_data
kiva = get_data(‘kiva’)
experiment_name = setup(data = kiva, target = ‘en’)
lda = create_model(‘lda’)</p>
<p>plot_model(lda, plot = ‘frequency’)</p>
<p>This will return a frequency plot on a trained Latent Dirichlet Allocation
model for all documents in ‘Topic 0’. The topic number can be changed as
follows:</p>
<p>plot_model(lda, plot = ‘frequency’, topic_num = ‘Topic 1’)</p>
<p>This will now return a frequency plot on a trained LDA model for all
documents inferred in ‘Topic 1’.</p>
<p>Alternatively, if following is used:</p>
<p>plot_model(plot = ‘frequency’)</p>
<p>This will return frequency plot on the entire training corpus compiled
during setup stage.</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>object</em><em>, </em><em>default = none</em>) – </p></li>
<li><p><strong>trained model object can be passed. Model must be created using create_model</strong><strong>(</strong><strong>)</strong><strong></strong> (<em>A</em>) – </p></li>
<li><p><strong>plot</strong> (<em>string</em><em>, </em><em>default = 'frequency'</em>) – </p></li>
<li><p><strong>abbreviation for type of plot. The current list of plots supported are</strong> (<em>Enter</em>) – </p></li>
<li><p><strong>Abbreviated String</strong> (<em>Name</em>) – </p></li>
<li><p><strong>------------------</strong> (<em>---------</em>) – </p></li>
<li><p><strong>Token Frequency           'frequency'</strong> (<em>Word</em>) – </p></li>
<li><p><strong>Distribution Plot         'distribution'</strong> (<em>Word</em>) – </p></li>
<li><p><strong>Frequency Plot          'bigram'</strong> (<em>Bigram</em>) – </p></li>
<li><p><strong>Frequency Plot         'trigram'</strong> (<em>Trigram</em>) – </p></li>
<li><p><strong>Polarity Plot        'sentiment'</strong> (<em>Sentiment</em>) – </p></li>
<li><p><strong>of Speech Frequency       'pos'</strong> (<em>Part</em>) – </p></li>
<li><p><strong>(</strong><strong>3d</strong><strong>) </strong><strong>Dimension Plot      'tsne'</strong> (<em>t-SNE</em>) – </p></li>
<li><p><strong>Model</strong><strong> (</strong><strong>pyLDAvis</strong><strong>)         </strong><strong>'topic_model'</strong> (<em>Topic</em>) – </p></li>
<li><p><strong>Infer Distribution       'topic_distribution'</strong> (<em>Topic</em>) – </p></li>
<li><p><strong>'wordcloud'</strong> (<em>Wordcloud</em>) – </p></li>
<li><p><strong>Dimensionality Plot       'umap'</strong> (<em>UMAP</em>) – </p></li>
<li><p><strong>topic_num</strong> (<em>string</em><em>, </em><em>default = None</em>) – </p></li>
<li><p><strong>number to be passed as a string. If set to None</strong><strong>, </strong><strong>default generation will</strong> (<em>Topic</em>) – </p></li>
<li><p><strong>on 'Topic 0'</strong> (<em>be</em>) – </p></li>
<li><p><strong>Returns</strong> – </p></li>
<li><p><strong>--------</strong> – </p></li>
<li><p><strong>Plot</strong> (<em>Visual</em>) – </p></li>
<li><p><strong>------------</strong> – </p></li>
<li><p><strong>Warnings</strong> – </p></li>
<li><p><strong>---------</strong> – </p></li>
<li><p><strong>'pos' and 'umap' plot not available at model level. Hence the model parameter is</strong> (<em>-</em>) – ignored. The result will always be based on the entire training corpus.</p></li>
<li><p><strong>'topic_model' plot is based on pyLDAVis implementation. Hence its not available</strong> (<em>-</em>) – for model = ‘lsi’, ‘rp’ and ‘nmf’.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pycaret.nlp.save_experiment">
<code class="sig-prename descclassname">pycaret.nlp.</code><code class="sig-name descname">save_experiment</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">experiment_name</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.nlp.save_experiment" title="Permalink to this definition">¶</a></dt>
<dd><p>This function saves the entire experiment into the current active directory.
All outputs using pycaret are internally saved into a binary list which is
pickilized when save_experiment() is used.</p>
<blockquote>
<div><p>save_experiment()</p>
<p>This will save the entire experiment into the current active directory.
By default, the name of the experiment will use the session_id generated
during setup(). To use a custom name, a string must be passed to the
experiment_name param. For example:</p>
<p>save_experiment(‘experiment_23122019’)</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>experiment_name</strong> (<em>string</em><em>, </em><em>default = none</em>) – </p></li>
<li><p><strong>of pickle file to be passed as a string.</strong> (<em>Name</em>) – </p></li>
<li><p><strong>Returns</strong> – </p></li>
<li><p><strong>--------</strong> – </p></li>
<li><p><strong>Message</strong> (<em>Success</em>) – </p></li>
<li><p><strong>Warnings</strong> – </p></li>
<li><p><strong>---------</strong> – </p></li>
<li><p><strong>None</strong> – </p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pycaret.nlp.save_model">
<code class="sig-prename descclassname">pycaret.nlp.</code><code class="sig-name descname">save_model</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">model</span></em>, <em class="sig-param"><span class="n">model_name</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.nlp.save_model" title="Permalink to this definition">¶</a></dt>
<dd><p>This function saves the trained model object into the current active
directory as a pickle file for later use.</p>
<blockquote>
<div><p>from pycaret.datasets import get_data
kiva = get_data(‘kiva’)
experiment_name = setup(data = kiva, target = ‘en’)
lda = create_model(‘lda’)</p>
<p>save_model(lda, ‘lda_model_23122019’)</p>
<p>This will save the model as a binary pickle file in the current
directory.</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>object</em><em>, </em><em>default = none</em>) – </p></li>
<li><p><strong>trained model object should be passed.</strong> (<em>A</em>) – </p></li>
<li><p><strong>model_name</strong> (<em>string</em><em>, </em><em>default = none</em>) – </p></li>
<li><p><strong>of pickle file to be passed as a string.</strong> (<em>Name</em>) – </p></li>
<li><p><strong>Returns</strong> – </p></li>
<li><p><strong>--------</strong> – </p></li>
<li><p><strong>Message</strong> (<em>Success</em>) – </p></li>
<li><p><strong>Warnings</strong> – </p></li>
<li><p><strong>---------</strong> – </p></li>
<li><p><strong>None</strong> – </p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pycaret.nlp.setup">
<code class="sig-prename descclassname">pycaret.nlp.</code><code class="sig-name descname">setup</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">target</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">custom_stopwords</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">session_id</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.nlp.setup" title="Permalink to this definition">¶</a></dt>
<dd><p>This function initializes the environment in pycaret. setup() must called before
executing any other function in pycaret. It takes one mandatory parameter:
dataframe {array-like, sparse matrix} or object of type list. If a dataframe is
passed, target column containing text must be specified. When data passed is of
type list, no target parameter is required. All other parameters are optional.
This module only supports English Language at this time.</p>
<blockquote>
<div><p>from pycaret.datasets import get_data
kiva = get_data(‘kiva’)
experiment_name = setup(data = kiva, target = ‘en’)</p>
<p>‘kiva’ is a pandas Dataframe.</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<em>{array-like</em><em>, </em><em>sparse matrix}</em><em>, </em><em>shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>) </em><em>where n_samples</em>) – </p></li>
<li><p><strong>the number of samples and n_features is the number of features</strong><strong> or </strong><strong>object of type</strong> (<em>is</em>) – </p></li>
<li><p><strong>with n length.</strong> (<em>list</em>) – </p></li>
<li><p><strong>target</strong> (<em>string</em>) – </p></li>
<li><p><strong>data is of type DataFrame</strong><strong>, </strong><strong>name of column containing text values must be passed as</strong> (<em>If</em>) – </p></li>
<li><p><strong>string.</strong> – </p></li>
<li><p><strong>custom_stopwords</strong> (<em>list</em><em>, </em><em>default = None</em>) – </p></li>
<li><p><strong>containing custom stopwords.</strong> (<em>list</em>) – </p></li>
<li><p><strong>session_id</strong> (<em>int</em><em>, </em><em>default = None</em>) – </p></li>
<li><p><strong>None</strong><strong>, </strong><strong>a random seed is generated and returned in the Information grid. The</strong> (<em>If</em>) – </p></li>
<li><p><strong>number is then distributed as a seed in all functions used during the</strong> (<em>unique</em>) – </p></li>
<li><p><strong>This can be used for later reproducibility of the entire experiment.</strong> (<em>experiment.</em>) – </p></li>
</ul>
</dd>
</dl>
<p>environment:  This function returns various outputs that are stored in variable
———–   as tuple. They are used by other functions in pycaret.</p>
<ul>
<li><p>Some functionalities in pycaret.nlp requires you to have english language model.
The language model is not downloaded automatically when you install pycaret.
You will have to download two models using your Anaconda Prompt or python
command line interface. To download the model, please type the following in
your command line:</p>
<blockquote>
<div><p>python -m spacy download en_core_web_sm
python -m textblob.download_corpora</p>
</div></blockquote>
<p>Once downloaded, please restart your kernel and re-run the setup.</p>
</li>
</ul>
</dd></dl>

<dl class="py function">
<dt id="pycaret.nlp.tune_model">
<code class="sig-prename descclassname">pycaret.nlp.</code><code class="sig-name descname">tune_model</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">model</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">multi_core</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">supervised_target</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">estimator</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">optimize</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">auto_fe</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">fold</span><span class="o">=</span><span class="default_value">10</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.nlp.tune_model" title="Permalink to this definition">¶</a></dt>
<dd><p>This function tunes the num_topics model parameter using a predefined grid with
the objective of optimizing a supervised learning metric as defined in the optimize
param. You can choose the supervised estimator from a large library available in
pycaret. By default, supervised estimator is Linear.</p>
<p>This function returns the tuned model object.</p>
<blockquote>
<div><p>from pycaret.datasets import get_data
kiva = get_data(‘kiva’)
experiment_name = setup(data = kiva, target = ‘en’)</p>
<p>tuned_lda = tune_model(model = ‘lda’, supervised_target = ‘status’)</p>
<p>This will return trained Latent Dirichlet Allocation model.</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>trained model object with best K number of topics.</em>) – </p></li>
<li><p><strong>abbreviated name of the model. List of available models supported</strong> (<em>Enter</em>) – </p></li>
<li><p><strong>Abbreviated String   Original Implementation</strong> (<em>Model</em>) – </p></li>
<li><p><strong>------------------   -----------------------</strong> (<em>---------</em>) – </p></li>
<li><p><strong>Dirichlet Allocation        'lda'                gensim/models/ldamodel.html</strong> (<em>Latent</em>) – </p></li>
<li><p><strong>Semantic Indexing           'lsi'                gensim/models/lsimodel.html</strong> (<em>Latent</em>) – </p></li>
<li><p><strong>Dirichlet Process     'hdp'                gensim/models/hdpmodel.html</strong> (<em>Hierarchical</em>) – </p></li>
<li><p><strong>Projections                 'rp'                 gensim/models/rpmodel.html</strong> (<em>Random</em>) – </p></li>
<li><p><strong>Matrix Factorization  'nmf'                sklearn.decomposition.NMF.html</strong> (<em>Non-Negative</em>) – </p></li>
<li><p><strong>multi_core</strong> (<em>Boolean</em><em>, </em><em>default = False</em>) – </p></li>
<li><p><strong>would utilize all CPU cores to parallelize and speed up model training. Only</strong> (<em>True</em>) – </p></li>
<li><p><strong>for 'lda'. For all other models</strong><strong>, </strong><strong>multi_core parameter is ignored.</strong> (<em>available</em>) – </p></li>
<li><p><strong>supervised_target</strong> (<em>string</em>) – </p></li>
<li><p><strong>of the target column for supervised learning. If None</strong><strong>, </strong><strong>the mdel coherence value</strong> (<em>Name</em>) – </p></li>
<li><p><strong>used as the objective function.</strong> (<em>is</em>) – </p></li>
<li><p><strong>estimator</strong> (<em>string</em><em>, </em><em>default = None</em>) – </p></li>
<li><p><strong>Abbreviated String     Task</strong> (<em>Estimator</em>) – </p></li>
<li><p><strong>------------------     ---------------</strong> (<em>---------</em>) – </p></li>
<li><p><strong>Regression           'lr'                   Classification</strong> (<em>Logistic</em>) – </p></li>
<li><p><strong>Nearest Neighbour           'knn'                  Classification</strong> (<em>K</em>) – </p></li>
<li><p><strong>Bayes                  'nb'                   Classification</strong> (<em>Naives</em>) – </p></li>
<li><p><strong>Tree                 'dt'                   Classification</strong> (<em>Decision</em>) – </p></li>
<li><p><strong>(</strong><strong>Linear</strong><strong>)                  </strong><strong>'svm'                  Classification</strong> (<em>SVM</em>) – </p></li>
<li><p><strong>(</strong><strong>RBF</strong><strong>)                     </strong><strong>'rbfsvm'               Classification</strong> (<em>SVM</em>) – </p></li>
<li><p><strong>Process              'gpc'                  Classification</strong> (<em>Gaussian</em>) – </p></li>
<li><p><strong>Level Perceptron        'mlp'                  Classification</strong> (<em>Multi</em>) – </p></li>
<li><p><strong>Classifier              'ridge'                Classification</strong> (<em>Ridge</em>) – </p></li>
<li><p><strong>Forest                 'rf'                   Classification</strong> (<em>Random</em>) – </p></li>
<li><p><strong>Disc. Analysis      'qda'                  Classification</strong> (<em>Quadratic</em>) – </p></li>
<li><p><strong>'ada'                  Classification</strong> (<em>AdaBoost</em>) – </p></li>
<li><p><strong>Boosting             'gbc'                  Classification</strong> (<em>Gradient</em>) – </p></li>
<li><p><strong>Disc. Analysis         'lda'                  Classification</strong> (<em>Linear</em>) – </p></li>
<li><p><strong>Trees Classifier        'et'                   Classification</strong> (<em>Extra</em>) – </p></li>
<li><p><strong>Gradient Boosting     'xgboost'              Classification</strong> (<em>Extreme</em>) – </p></li>
<li><p><strong>Gradient Boosting       'lightgbm'             Classification</strong> (<em>Light</em>) – </p></li>
<li><p><strong>Classifier           'catboost'             Classification</strong> (<em>CatBoost</em>) – </p></li>
<li><p><strong>Regression             'lr'                   Regression</strong> (<em>Linear</em>) – </p></li>
<li><p><strong>Regression              'lasso'                Regression</strong> (<em>Lasso</em>) – </p></li>
<li><p><strong>Regression              'ridge'                Regression</strong> (<em>Ridge</em>) – </p></li>
<li><p><strong>Net                   'en'                   Regression</strong> (<em>Elastic</em>) – </p></li>
<li><p><strong>Angle Regression        'lar'                  Regression</strong> (<em>Least</em>) – </p></li>
<li><p><strong>Least Angle Regression  'llar'                 Regression</strong> (<em>Lasso</em>) – </p></li>
<li><p><strong>Matching Pursuit   'omp'                  Regression</strong> (<em>Orthogonal</em>) – </p></li>
<li><p><strong>Ridge                'br'                   Regression</strong> (<em>Bayesian</em>) – </p></li>
<li><p><strong>Relevance Determ.   'ard'                  Regression</strong> (<em>Automatic</em>) – </p></li>
<li><p><strong>Aggressive Regressor  'par'                  Regression</strong> (<em>Passive</em>) – </p></li>
<li><p><strong>Sample Consensus       'ransac'               Regression</strong> (<em>Random</em>) – </p></li>
<li><p><strong>Regressor            'tr'                   Regression</strong> (<em>TheilSen</em>) – </p></li>
<li><p><strong>Regressor               'huber'                Regression</strong> (<em>Huber</em>) – </p></li>
<li><p><strong>Ridge                  'kr'                   Regression</strong> (<em>Kernel</em>) – </p></li>
<li><p><strong>Vector Machine        'svm'                  Regression</strong> (<em>Support</em>) – </p></li>
<li><p><strong>Neighbors Regressor         'knn'                  Regression</strong> (<em>K</em>) – </p></li>
<li><p><strong>Tree                 'dt'                   Regression</strong> (<em>Decision</em>) – </p></li>
<li><p><strong>Forest                 'rf'                   Regression</strong> (<em>Random</em>) – </p></li>
<li><p><strong>Trees Regressor         'et'                   Regression</strong> (<em>Extra</em>) – </p></li>
<li><p><strong>Regressor            'ada'                  Regression</strong> (<em>AdaBoost</em>) – </p></li>
<li><p><strong>Boosting             'gbr'                  Regression</strong> (<em>Gradient</em>) – </p></li>
<li><p><strong>Level Perceptron        'mlp'                  Regression</strong> (<em>Multi</em>) – </p></li>
<li><p><strong>Gradient Boosting     'xgboost'              Regression</strong> (<em>Extreme</em>) – </p></li>
<li><p><strong>Gradient Boosting       'lightgbm'             Regression</strong> (<em>Light</em>) – </p></li>
<li><p><strong>Regressor            'catboost'             Regression</strong> (<em>CatBoost</em>) – </p></li>
<li><p><strong>set to None</strong><strong>, </strong><strong>Linear model is used by default for both classification</strong> (<em>If</em>) – </p></li>
<li><p><strong>regression tasks.</strong> (<em>and</em>) – </p></li>
<li><p><strong>optimize</strong> (<em>string</em><em>, </em><em>default = None</em>) – </p></li>
<li><p><strong>Classification tasks</strong> (<em>For</em>) – </p></li>
<li><p><strong>AUC</strong><strong>, </strong><strong>Recall</strong><strong>, </strong><strong>Precision</strong><strong>, </strong><strong>F1</strong><strong>, </strong><strong>Kappa</strong> (<em>Accuracy</em><em>,</em>) – </p></li>
<li><p><strong>Regression tasks</strong> (<em>For</em>) – </p></li>
<li><p><strong>MSE</strong><strong>, </strong><strong>RMSE</strong><strong>, </strong><strong>R2</strong><strong>, </strong><strong>ME</strong> (<em>MAE</em><em>,</em>) – </p></li>
<li><p><strong>set to None</strong><strong>, </strong><strong>default is 'Accuracy' for classification and 'R2' for</strong> (<em>If</em>) – </p></li>
<li><p><strong>tasks.</strong> (<em>regression</em>) – </p></li>
<li><p><strong>auto_fe</strong> (<em>boolean</em><em>, </em><em>default = True</em>) – </p></li>
<li><p><strong>text feature engineering. Only used when supervised_target is</strong> (<em>Automatic</em>) – </p></li>
<li><p><strong>When set to true</strong><strong>, </strong><strong>it will generate text based features such as</strong> (<em>passed.</em>) – </p></li>
<li><p><strong>subjectivity</strong><strong>, </strong><strong>wordcounts to be used in supervised learning.</strong> (<em>polarity</em><em>,</em>) – </p></li>
<li><p><strong>when supervised_target is set to None.</strong> (<em>Ignored</em>) – </p></li>
<li><p><strong>fold</strong> (<em>integer</em><em>, </em><em>default = 10</em>) – </p></li>
<li><p><strong>of folds to be used in Kfold CV. Must be at least 2.</strong> (<em>Number</em>) – </p></li>
<li><p><strong>Returns</strong> – </p></li>
<li><p><strong>--------</strong> – </p></li>
<li><p><strong>plot</strong> (<em>visual</em>) – </p></li>
<li><p><strong>optimize on y-axis. Coherence is used when learning is</strong> (<em>-----------</em>) – unsupervised. Also, prints the best model metric.</p></li>
<li><p><strong>model</strong> – </p></li>
<li><p><strong>-----------</strong> – </p></li>
<li><p><strong>Warnings</strong> – </p></li>
<li><p><strong>---------</strong> – </p></li>
<li><p><strong>Random Projections</strong><strong> (</strong><strong>'rp'</strong><strong>) </strong><strong>and Non Negative Matrix Factorization</strong><strong> (</strong><strong>'nmf'</strong><strong>)</strong> (<em>-</em>) – is not available for unsupervised learning. Error is raised when ‘rp’ or
‘nmf’ is passed without supervised_target.</p></li>
<li><p><strong>Estimators using kernel based methods such as Kernel Ridge Regressor</strong><strong>,</strong> (<em>-</em>) – Automatic Relevance Determinant, Gaussian Process Classifier, Radial Basis
Support Vector Machine and Multi Level Perceptron may have longer training
times.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-pycaret.preprocess">
<span id="preprocess"></span><h1>Preprocess<a class="headerlink" href="#module-pycaret.preprocess" title="Permalink to this headline">¶</a></h1>
<dl class="py class">
<dt id="pycaret.preprocess.Advanced_Feature_Selection_Classic">
<em class="property">class </em><code class="sig-prename descclassname">pycaret.preprocess.</code><code class="sig-name descname">Advanced_Feature_Selection_Classic</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">target</span></em>, <em class="sig-param"><span class="n">ml_usecase</span><span class="o">=</span><span class="default_value">'classification'</span></em>, <em class="sig-param"><span class="n">top_features_to_pick</span><span class="o">=</span><span class="default_value">0.1</span></em>, <em class="sig-param"><span class="n">random_state</span><span class="o">=</span><span class="default_value">42</span></em>, <em class="sig-param"><span class="n">subclass</span><span class="o">=</span><span class="default_value">'ignore'</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.preprocess.Advanced_Feature_Selection_Classic" title="Permalink to this definition">¶</a></dt>
<dd><ul class="simple">
<li><p>Selects important features and reduces the feature space. Feature selection is based on Random Forest , Light GBM and Correlation</p></li>
<li><p>to run on multiclass classification , set the subclass argument to ‘multi’</p></li>
</ul>
<dl class="py method">
<dt id="pycaret.preprocess.Advanced_Feature_Selection_Classic.fit_transform">
<code class="sig-name descname">fit_transform</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">dataset</span></em>, <em class="sig-param"><span class="n">y</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.preprocess.Advanced_Feature_Selection_Classic.fit_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit to data, then transform it.</p>
<p>Fits transformer to X and y with optional parameters fit_params
and returns a transformed version of X.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>numpy array of shape</em><em> [</em><em>n_samples</em><em>, </em><em>n_features</em><em>]</em>) – Training set.</p></li>
<li><p><strong>y</strong> (<em>numpy array of shape</em><em> [</em><em>n_samples</em><em>]</em>) – Target values.</p></li>
<li><p><strong>**fit_params</strong> (<em>dict</em>) – Additional fit parameters.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>X_new</strong> – Transformed array.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>numpy array of shape [n_samples, n_features_new]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="pycaret.preprocess.Binning">
<em class="property">class </em><code class="sig-prename descclassname">pycaret.preprocess.</code><code class="sig-name descname">Binning</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">features_to_discretize</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.preprocess.Binning" title="Permalink to this definition">¶</a></dt>
<dd><ul class="simple">
<li><p>Converts numerical variables to catagorical variable through binning</p></li>
<li><p>Number of binns are automitically determined through Sturges method</p></li>
<li><dl class="simple">
<dt>Once discretize, original feature will be dropped</dt><dd><dl class="simple">
<dt>Args:</dt><dd><p>features_to_discretize: list of featur names to be binned</p>
</dd>
</dl>
</dd>
</dl>
</li>
</ul>
<dl class="py method">
<dt id="pycaret.preprocess.Binning.fit_transform">
<code class="sig-name descname">fit_transform</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">dataset</span></em>, <em class="sig-param"><span class="n">y</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.preprocess.Binning.fit_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit to data, then transform it.</p>
<p>Fits transformer to X and y with optional parameters fit_params
and returns a transformed version of X.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>numpy array of shape</em><em> [</em><em>n_samples</em><em>, </em><em>n_features</em><em>]</em>) – Training set.</p></li>
<li><p><strong>y</strong> (<em>numpy array of shape</em><em> [</em><em>n_samples</em><em>]</em>) – Target values.</p></li>
<li><p><strong>**fit_params</strong> (<em>dict</em>) – Additional fit parameters.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>X_new</strong> – Transformed array.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>numpy array of shape [n_samples, n_features_new]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="pycaret.preprocess.Catagorical_variables_With_Rare_levels">
<em class="property">class </em><code class="sig-prename descclassname">pycaret.preprocess.</code><code class="sig-name descname">Catagorical_variables_With_Rare_levels</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">target</span></em>, <em class="sig-param"><span class="n">new_level_name</span><span class="o">=</span><span class="default_value">'others_infrequent'</span></em>, <em class="sig-param"><span class="n">threshold</span><span class="o">=</span><span class="default_value">0.05</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.preprocess.Catagorical_variables_With_Rare_levels" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>-Merges levels in catagorical features with more frequent level  if they appear less than a threshold count</dt><dd><p>e.g. Col=[a,a,a,a,b,b,c,c]
if threshold is set to 2 , then c will be mrged with b because both are below threshold
There has to be atleast two levels belwo threshold for this to work
the process will keep going until all the levels have atleast 2(threshold) counts</p>
</dd>
</dl>
<p>-Only handles catagorical features
-It is recommended to run the Zroe_NearZero_Variance and Define_dataTypes first
-Ignores target variable</p>
<blockquote>
<div><dl class="simple">
<dt>Args:</dt><dd><p>threshold: int , default 10
target: string , name of the target variable
new_level_name: string , name given to the new level generated, default ‘others’</p>
</dd>
</dl>
</div></blockquote>
<dl class="py method">
<dt id="pycaret.preprocess.Catagorical_variables_With_Rare_levels.fit_transform">
<code class="sig-name descname">fit_transform</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">dataset</span></em>, <em class="sig-param"><span class="n">y</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.preprocess.Catagorical_variables_With_Rare_levels.fit_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit to data, then transform it.</p>
<p>Fits transformer to X and y with optional parameters fit_params
and returns a transformed version of X.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>numpy array of shape</em><em> [</em><em>n_samples</em><em>, </em><em>n_features</em><em>]</em>) – Training set.</p></li>
<li><p><strong>y</strong> (<em>numpy array of shape</em><em> [</em><em>n_samples</em><em>]</em>) – Target values.</p></li>
<li><p><strong>**fit_params</strong> (<em>dict</em>) – Additional fit parameters.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>X_new</strong> – Transformed array.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>numpy array of shape [n_samples, n_features_new]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="pycaret.preprocess.Clean_Colum_Names">
<em class="property">class </em><code class="sig-prename descclassname">pycaret.preprocess.</code><code class="sig-name descname">Clean_Colum_Names</code><a class="headerlink" href="#pycaret.preprocess.Clean_Colum_Names" title="Permalink to this definition">¶</a></dt>
<dd><ul class="simple">
<li><p>Cleans special chars that are not supported by jason format</p></li>
</ul>
<dl class="py method">
<dt id="pycaret.preprocess.Clean_Colum_Names.fit_transform">
<code class="sig-name descname">fit_transform</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">dataset</span></em>, <em class="sig-param"><span class="n">y</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.preprocess.Clean_Colum_Names.fit_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit to data, then transform it.</p>
<p>Fits transformer to X and y with optional parameters fit_params
and returns a transformed version of X.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>numpy array of shape</em><em> [</em><em>n_samples</em><em>, </em><em>n_features</em><em>]</em>) – Training set.</p></li>
<li><p><strong>y</strong> (<em>numpy array of shape</em><em> [</em><em>n_samples</em><em>]</em>) – Target values.</p></li>
<li><p><strong>**fit_params</strong> (<em>dict</em>) – Additional fit parameters.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>X_new</strong> – Transformed array.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>numpy array of shape [n_samples, n_features_new]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="pycaret.preprocess.Cluster_Entire_Data">
<em class="property">class </em><code class="sig-prename descclassname">pycaret.preprocess.</code><code class="sig-name descname">Cluster_Entire_Data</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">target_variable</span></em>, <em class="sig-param"><span class="n">check_clusters_upto</span><span class="o">=</span><span class="default_value">20</span></em>, <em class="sig-param"><span class="n">random_state</span><span class="o">=</span><span class="default_value">42</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.preprocess.Cluster_Entire_Data" title="Permalink to this definition">¶</a></dt>
<dd><ul>
<li><p>Applies kmeans clustering to the entire data set and produce clusters</p></li>
<li><p>Highly recommended to run the DataTypes_Auto_infer class first
Args:</p>
<blockquote>
<div><p>target_variable: target variable (integer or numerical only)
check_clusters_upto: to determine optimum number of kmeans clusters, set the uppler limit of clusters</p>
</div></blockquote>
</li>
</ul>
<dl class="py method">
<dt id="pycaret.preprocess.Cluster_Entire_Data.fit_transform">
<code class="sig-name descname">fit_transform</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">dataset</span></em>, <em class="sig-param"><span class="n">y</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.preprocess.Cluster_Entire_Data.fit_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit to data, then transform it.</p>
<p>Fits transformer to X and y with optional parameters fit_params
and returns a transformed version of X.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>numpy array of shape</em><em> [</em><em>n_samples</em><em>, </em><em>n_features</em><em>]</em>) – Training set.</p></li>
<li><p><strong>y</strong> (<em>numpy array of shape</em><em> [</em><em>n_samples</em><em>]</em>) – Target values.</p></li>
<li><p><strong>**fit_params</strong> (<em>dict</em>) – Additional fit parameters.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>X_new</strong> – Transformed array.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>numpy array of shape [n_samples, n_features_new]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="pycaret.preprocess.DFS_Classic">
<em class="property">class </em><code class="sig-prename descclassname">pycaret.preprocess.</code><code class="sig-name descname">DFS_Classic</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">target</span></em>, <em class="sig-param"><span class="n">ml_usecase</span><span class="o">=</span><span class="default_value">'classification'</span></em>, <em class="sig-param"><span class="n">interactions</span><span class="o">=</span><span class="default_value">['multiply', 'divide', 'add', 'subtract']</span></em>, <em class="sig-param"><span class="n">top_features_to_pick_percentage</span><span class="o">=</span><span class="default_value">0.05</span></em>, <em class="sig-param"><span class="n">random_state</span><span class="o">=</span><span class="default_value">42</span></em>, <em class="sig-param"><span class="n">subclass</span><span class="o">=</span><span class="default_value">'ignore'</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.preprocess.DFS_Classic" title="Permalink to this definition">¶</a></dt>
<dd><ul class="simple">
<li><p>Automated feature interactions using multiplication, division , addition &amp; substraction</p></li>
<li><p>Only accepts numeric / One Hot Encoded features</p></li>
<li><p>Takes DF, return same DF</p></li>
<li><p>for Multiclass classification problem , set subclass arg as ‘multi’</p></li>
</ul>
<dl class="py method">
<dt id="pycaret.preprocess.DFS_Classic.fit_transform">
<code class="sig-name descname">fit_transform</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">dataset</span></em>, <em class="sig-param"><span class="n">y</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.preprocess.DFS_Classic.fit_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit to data, then transform it.</p>
<p>Fits transformer to X and y with optional parameters fit_params
and returns a transformed version of X.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>numpy array of shape</em><em> [</em><em>n_samples</em><em>, </em><em>n_features</em><em>]</em>) – Training set.</p></li>
<li><p><strong>y</strong> (<em>numpy array of shape</em><em> [</em><em>n_samples</em><em>]</em>) – Target values.</p></li>
<li><p><strong>**fit_params</strong> (<em>dict</em>) – Additional fit parameters.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>X_new</strong> – Transformed array.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>numpy array of shape [n_samples, n_features_new]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="pycaret.preprocess.DataTypes_Auto_infer">
<em class="property">class </em><code class="sig-prename descclassname">pycaret.preprocess.</code><code class="sig-name descname">DataTypes_Auto_infer</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">target</span></em>, <em class="sig-param"><span class="n">ml_usecase</span></em>, <em class="sig-param"><span class="n">categorical_features</span><span class="o">=</span><span class="default_value">[]</span></em>, <em class="sig-param"><span class="n">numerical_features</span><span class="o">=</span><span class="default_value">[]</span></em>, <em class="sig-param"><span class="n">time_features</span><span class="o">=</span><span class="default_value">[]</span></em>, <em class="sig-param"><span class="n">features_todrop</span><span class="o">=</span><span class="default_value">[]</span></em>, <em class="sig-param"><span class="n">display_types</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.preprocess.DataTypes_Auto_infer" title="Permalink to this definition">¶</a></dt>
<dd><ul class="simple">
<li><p>This will try to infer data types automatically, option to override learent data types is also available.</p></li>
<li><p>This alos automatically delets duplicate columns (values or same colume name), removes rows where target variable is null and
remove columns and rows where all the records are null</p></li>
</ul>
<dl class="py method">
<dt id="pycaret.preprocess.DataTypes_Auto_infer.fit">
<code class="sig-name descname">fit</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">dataset</span></em>, <em class="sig-param"><span class="n">y</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.preprocess.DataTypes_Auto_infer.fit" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>data</strong> – accepts a pandas data frame</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Panda Data Frame</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="pycaret.preprocess.DataTypes_Auto_infer.fit_transform">
<code class="sig-name descname">fit_transform</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">dataset</span></em>, <em class="sig-param"><span class="n">y</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.preprocess.DataTypes_Auto_infer.fit_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit to data, then transform it.</p>
<p>Fits transformer to X and y with optional parameters fit_params
and returns a transformed version of X.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>numpy array of shape</em><em> [</em><em>n_samples</em><em>, </em><em>n_features</em><em>]</em>) – Training set.</p></li>
<li><p><strong>y</strong> (<em>numpy array of shape</em><em> [</em><em>n_samples</em><em>]</em>) – Target values.</p></li>
<li><p><strong>**fit_params</strong> (<em>dict</em>) – Additional fit parameters.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>X_new</strong> – Transformed array.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>numpy array of shape [n_samples, n_features_new]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="pycaret.preprocess.DataTypes_Auto_infer.transform">
<code class="sig-name descname">transform</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">dataset</span></em>, <em class="sig-param"><span class="n">y</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.preprocess.DataTypes_Auto_infer.transform" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>data</strong> – accepts a pandas data frame</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Panda Data Frame</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="pycaret.preprocess.Dummify">
<em class="property">class </em><code class="sig-prename descclassname">pycaret.preprocess.</code><code class="sig-name descname">Dummify</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">target</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.preprocess.Dummify" title="Permalink to this definition">¶</a></dt>
<dd><ul>
<li><p>makes one hot encoded variables for dummy variable</p></li>
<li><p>it is HIGHLY recommended to run the Select_Data_Type class first</p></li>
<li><p>Ignores target variable</p>
<dl class="simple">
<dt>Args:</dt><dd><p>target: string , name of the target variable</p>
</dd>
</dl>
</li>
</ul>
<dl class="py method">
<dt id="pycaret.preprocess.Dummify.fit_transform">
<code class="sig-name descname">fit_transform</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">dataset</span></em>, <em class="sig-param"><span class="n">y</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.preprocess.Dummify.fit_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit to data, then transform it.</p>
<p>Fits transformer to X and y with optional parameters fit_params
and returns a transformed version of X.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>numpy array of shape</em><em> [</em><em>n_samples</em><em>, </em><em>n_features</em><em>]</em>) – Training set.</p></li>
<li><p><strong>y</strong> (<em>numpy array of shape</em><em> [</em><em>n_samples</em><em>]</em>) – Target values.</p></li>
<li><p><strong>**fit_params</strong> (<em>dict</em>) – Additional fit parameters.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>X_new</strong> – Transformed array.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>numpy array of shape [n_samples, n_features_new]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="pycaret.preprocess.Empty">
<em class="property">class </em><code class="sig-prename descclassname">pycaret.preprocess.</code><code class="sig-name descname">Empty</code><a class="headerlink" href="#pycaret.preprocess.Empty" title="Permalink to this definition">¶</a></dt>
<dd><ul class="simple">
<li><p>Takes DF, return same DF</p></li>
</ul>
<dl class="py method">
<dt id="pycaret.preprocess.Empty.fit_transform">
<code class="sig-name descname">fit_transform</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">y</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.preprocess.Empty.fit_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit to data, then transform it.</p>
<p>Fits transformer to X and y with optional parameters fit_params
and returns a transformed version of X.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>numpy array of shape</em><em> [</em><em>n_samples</em><em>, </em><em>n_features</em><em>]</em>) – Training set.</p></li>
<li><p><strong>y</strong> (<em>numpy array of shape</em><em> [</em><em>n_samples</em><em>]</em>) – Target values.</p></li>
<li><p><strong>**fit_params</strong> (<em>dict</em>) – Additional fit parameters.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>X_new</strong> – Transformed array.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>numpy array of shape [n_samples, n_features_new]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="pycaret.preprocess.Fix_multicollinearity">
<em class="property">class </em><code class="sig-prename descclassname">pycaret.preprocess.</code><code class="sig-name descname">Fix_multicollinearity</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">threshold</span></em>, <em class="sig-param"><span class="n">target_variable</span></em>, <em class="sig-param"><span class="n">correlation_with_target_threshold</span><span class="o">=</span><span class="default_value">0.0</span></em>, <em class="sig-param"><span class="n">correlation_with_target_preference</span><span class="o">=</span><span class="default_value">1.0</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.preprocess.Fix_multicollinearity" title="Permalink to this definition">¶</a></dt>
<dd><p>Fixes multicollinearity between predictor variables , also considering the correlation between target variable.
Only applies to regression or two class classification ML use case
Takes numerical and one hot encoded variables only</p>
<blockquote>
<div><dl class="simple">
<dt>Args:</dt><dd><p>threshold (float): The utmost absolute pearson correlation tolerated beyween featres from 0.0 to 1.0
target_variable (str): The target variable/column name
correlation_with_target_threshold: minimum absolute correlation required between every feature and the target variable , default 1.0 (0.0 to 1.0)
correlation_with_target_preference: float (0.0 to 1.0), default .08 ,while choosing between a pair of features w.r.t multicol &amp; correlation target , this gives
the option to favour one measur to another. e.g. if value is .6 , during feature selection tug of war, correlation target measure will have a higher say.
A value of .5 means both measure have equal say</p>
</dd>
</dl>
</div></blockquote>
<dl class="py method">
<dt id="pycaret.preprocess.Fix_multicollinearity.fit">
<code class="sig-name descname">fit</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">y</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.preprocess.Fix_multicollinearity.fit" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>= takes preprocessed data frame</strong> (<em>data</em>) – </p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="pycaret.preprocess.Fix_multicollinearity.fit_transform">
<code class="sig-name descname">fit_transform</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">y</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.preprocess.Fix_multicollinearity.fit_transform" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>= takes preprocessed data frame</strong> (<em>data</em>) – </p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>data frame</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="pycaret.preprocess.Fix_multicollinearity.transform">
<code class="sig-name descname">transform</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">dataset</span></em>, <em class="sig-param"><span class="n">y</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.preprocess.Fix_multicollinearity.transform" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Args:f</dt><dd><p>data = takes preprocessed data frame</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>data frame</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="pycaret.preprocess.Group_Similar_Features">
<em class="property">class </em><code class="sig-prename descclassname">pycaret.preprocess.</code><code class="sig-name descname">Group_Similar_Features</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">group_name</span><span class="o">=</span><span class="default_value">[]</span></em>, <em class="sig-param"><span class="n">list_of_grouped_features</span><span class="o">=</span><span class="default_value">[[]]</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.preprocess.Group_Similar_Features" title="Permalink to this definition">¶</a></dt>
<dd><ul>
<li><p>Given a list of features , it creates aggregate features</p></li>
<li><p>features created are Min, Max, Mean, Median, Mode &amp; Std</p></li>
<li><p>Only works on numerical features
Args:</p>
<blockquote>
<div><p>list_of_similar_features: list of list, string , e.g. [[‘col’,col2],[‘col3’,’col4’]]
group_name: list, group name/names to be added as prefix to aggregate features, e.g [‘gorup1’,’group2’]</p>
</div></blockquote>
</li>
</ul>
<dl class="py method">
<dt id="pycaret.preprocess.Group_Similar_Features.fit_transform">
<code class="sig-name descname">fit_transform</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">y</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.preprocess.Group_Similar_Features.fit_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit to data, then transform it.</p>
<p>Fits transformer to X and y with optional parameters fit_params
and returns a transformed version of X.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>numpy array of shape</em><em> [</em><em>n_samples</em><em>, </em><em>n_features</em><em>]</em>) – Training set.</p></li>
<li><p><strong>y</strong> (<em>numpy array of shape</em><em> [</em><em>n_samples</em><em>]</em>) – Target values.</p></li>
<li><p><strong>**fit_params</strong> (<em>dict</em>) – Additional fit parameters.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>X_new</strong> – Transformed array.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>numpy array of shape [n_samples, n_features_new]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="pycaret.preprocess.Make_NonLiner_Features">
<em class="property">class </em><code class="sig-prename descclassname">pycaret.preprocess.</code><code class="sig-name descname">Make_NonLiner_Features</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">target</span></em>, <em class="sig-param"><span class="n">ml_usecase</span><span class="o">=</span><span class="default_value">'classification'</span></em>, <em class="sig-param"><span class="n">Polynomial_degree</span><span class="o">=</span><span class="default_value">2</span></em>, <em class="sig-param"><span class="n">other_nonliner_features</span><span class="o">=</span><span class="default_value">['sin', 'cos', 'tan']</span></em>, <em class="sig-param"><span class="n">top_features_to_pick</span><span class="o">=</span><span class="default_value">0.2</span></em>, <em class="sig-param"><span class="n">random_state</span><span class="o">=</span><span class="default_value">42</span></em>, <em class="sig-param"><span class="n">subclass</span><span class="o">=</span><span class="default_value">'ignore'</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.preprocess.Make_NonLiner_Features" title="Permalink to this definition">¶</a></dt>
<dd><ul>
<li><p>convert numerical features into polynomial features</p></li>
<li><p>it is HIGHLY recommended to run the Autoinfer_Data_Type class first</p></li>
<li><p>Ignores target variable</p></li>
<li><p>it picks up data type float64 as numerical</p></li>
<li><p>for multiclass classification problem , set subclass arg to ‘multi’</p>
<dl class="simple">
<dt>Args:</dt><dd><p>target: string , name of the target variable
Polynomial_degree: int ,default 2</p>
</dd>
</dl>
</li>
</ul>
<dl class="py method">
<dt id="pycaret.preprocess.Make_NonLiner_Features.fit_transform">
<code class="sig-name descname">fit_transform</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">dataset</span></em>, <em class="sig-param"><span class="n">y</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.preprocess.Make_NonLiner_Features.fit_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit to data, then transform it.</p>
<p>Fits transformer to X and y with optional parameters fit_params
and returns a transformed version of X.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>numpy array of shape</em><em> [</em><em>n_samples</em><em>, </em><em>n_features</em><em>]</em>) – Training set.</p></li>
<li><p><strong>y</strong> (<em>numpy array of shape</em><em> [</em><em>n_samples</em><em>]</em>) – Target values.</p></li>
<li><p><strong>**fit_params</strong> (<em>dict</em>) – Additional fit parameters.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>X_new</strong> – Transformed array.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>numpy array of shape [n_samples, n_features_new]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="pycaret.preprocess.Make_Time_Features">
<em class="property">class </em><code class="sig-prename descclassname">pycaret.preprocess.</code><code class="sig-name descname">Make_Time_Features</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">time_feature</span><span class="o">=</span><span class="default_value">[]</span></em>, <em class="sig-param"><span class="n">list_of_features</span><span class="o">=</span><span class="default_value">['month', 'weekday', 'is_month_end', 'is_month_start', 'hour']</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.preprocess.Make_Time_Features" title="Permalink to this definition">¶</a></dt>
<dd><p>-Given a time feature , it extracts more features
- Only accepts / works where feature / data type is datetime64[ns]
- full list of features is:</p>
<blockquote>
<div><p>[‘month’,’weekday’,is_month_end’,’is_month_start’,’hour’]</p>
</div></blockquote>
<ul class="simple">
<li><p>all extracted features are defined as string / object</p></li>
</ul>
<dl class="simple">
<dt>-it is recommended to run Define_dataTypes first</dt><dd><dl class="simple">
<dt>Args:</dt><dd><p>time_feature: list of feature names as datetime64[ns] , default empty/none , if empty/None , it will try to pickup dates automatically where data type is datetime64[ns]
list_of_features: list of required features , default value [‘month’,’weekday’,’is_month_end’,’is_month_start’,’hour’]</p>
</dd>
</dl>
</dd>
</dl>
<dl class="py method">
<dt id="pycaret.preprocess.Make_Time_Features.fit_transform">
<code class="sig-name descname">fit_transform</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">dataset</span></em>, <em class="sig-param"><span class="n">y</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.preprocess.Make_Time_Features.fit_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit to data, then transform it.</p>
<p>Fits transformer to X and y with optional parameters fit_params
and returns a transformed version of X.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>numpy array of shape</em><em> [</em><em>n_samples</em><em>, </em><em>n_features</em><em>]</em>) – Training set.</p></li>
<li><p><strong>y</strong> (<em>numpy array of shape</em><em> [</em><em>n_samples</em><em>]</em>) – Target values.</p></li>
<li><p><strong>**fit_params</strong> (<em>dict</em>) – Additional fit parameters.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>X_new</strong> – Transformed array.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>numpy array of shape [n_samples, n_features_new]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="pycaret.preprocess.New_Catagorical_Levels_in_TestData">
<em class="property">class </em><code class="sig-prename descclassname">pycaret.preprocess.</code><code class="sig-name descname">New_Catagorical_Levels_in_TestData</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">target</span></em>, <em class="sig-param"><span class="n">replacement_strategy</span><span class="o">=</span><span class="default_value">'most frequent'</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.preprocess.New_Catagorical_Levels_in_TestData" title="Permalink to this definition">¶</a></dt>
<dd><p>-This treats if a new level appears in the test dataset catagorical’s feature (i.e a level on whihc model was not trained previously)
-It simply replaces the new level in test data set with the most frequent or least frequent level in the same feature in the training data set
-It is recommended to run the Zroe_NearZero_Variance and Define_dataTypes first
-Ignores target variable</p>
<blockquote>
<div><dl class="simple">
<dt>Args:</dt><dd><p>target: string , name of the target variable
replacement_strategy:string , ‘least frequent’ or ‘most frequent’ (default ‘most frequent’ )</p>
</dd>
</dl>
</div></blockquote>
<dl class="py method">
<dt id="pycaret.preprocess.New_Catagorical_Levels_in_TestData.fit_transform">
<code class="sig-name descname">fit_transform</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">y</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.preprocess.New_Catagorical_Levels_in_TestData.fit_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit to data, then transform it.</p>
<p>Fits transformer to X and y with optional parameters fit_params
and returns a transformed version of X.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>numpy array of shape</em><em> [</em><em>n_samples</em><em>, </em><em>n_features</em><em>]</em>) – Training set.</p></li>
<li><p><strong>y</strong> (<em>numpy array of shape</em><em> [</em><em>n_samples</em><em>]</em>) – Target values.</p></li>
<li><p><strong>**fit_params</strong> (<em>dict</em>) – Additional fit parameters.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>X_new</strong> – Transformed array.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>numpy array of shape [n_samples, n_features_new]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="pycaret.preprocess.Ordinal">
<em class="property">class </em><code class="sig-prename descclassname">pycaret.preprocess.</code><code class="sig-name descname">Ordinal</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">info_as_dict</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.preprocess.Ordinal" title="Permalink to this definition">¶</a></dt>
<dd><ul class="simple">
<li><p>converts categorical features into ordinal values</p></li>
<li><p>takes a dataframe , and information about column names and ordered categories as dict</p></li>
<li><p>returns float panda data frame</p></li>
</ul>
<dl class="py method">
<dt id="pycaret.preprocess.Ordinal.fit_transform">
<code class="sig-name descname">fit_transform</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">dataset</span></em>, <em class="sig-param"><span class="n">y</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.preprocess.Ordinal.fit_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit to data, then transform it.</p>
<p>Fits transformer to X and y with optional parameters fit_params
and returns a transformed version of X.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>numpy array of shape</em><em> [</em><em>n_samples</em><em>, </em><em>n_features</em><em>]</em>) – Training set.</p></li>
<li><p><strong>y</strong> (<em>numpy array of shape</em><em> [</em><em>n_samples</em><em>]</em>) – Target values.</p></li>
<li><p><strong>**fit_params</strong> (<em>dict</em>) – Additional fit parameters.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>X_new</strong> – Transformed array.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>numpy array of shape [n_samples, n_features_new]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="pycaret.preprocess.Outlier">
<em class="property">class </em><code class="sig-prename descclassname">pycaret.preprocess.</code><code class="sig-name descname">Outlier</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">target</span></em>, <em class="sig-param"><span class="n">contamination</span><span class="o">=</span><span class="default_value">0.2</span></em>, <em class="sig-param"><span class="n">random_state</span><span class="o">=</span><span class="default_value">42</span></em>, <em class="sig-param"><span class="n">methods</span><span class="o">=</span><span class="default_value">['knn', 'iso', 'pca']</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.preprocess.Outlier" title="Permalink to this definition">¶</a></dt>
<dd><ul class="simple">
<li><p>Removes outlier using ABOD,KNN,IFO,PCA &amp; HOBS using hard voting</p></li>
<li><p>Only takes numerical / One Hot Encoded features</p></li>
</ul>
<dl class="py method">
<dt id="pycaret.preprocess.Outlier.fit_transform">
<code class="sig-name descname">fit_transform</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">dataset</span></em>, <em class="sig-param"><span class="n">y</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.preprocess.Outlier.fit_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit to data, then transform it.</p>
<p>Fits transformer to X and y with optional parameters fit_params
and returns a transformed version of X.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>numpy array of shape</em><em> [</em><em>n_samples</em><em>, </em><em>n_features</em><em>]</em>) – Training set.</p></li>
<li><p><strong>y</strong> (<em>numpy array of shape</em><em> [</em><em>n_samples</em><em>]</em>) – Target values.</p></li>
<li><p><strong>**fit_params</strong> (<em>dict</em>) – Additional fit parameters.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>X_new</strong> – Transformed array.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>numpy array of shape [n_samples, n_features_new]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt id="pycaret.preprocess.Preprocess_Path_One">
<code class="sig-prename descclassname">pycaret.preprocess.</code><code class="sig-name descname">Preprocess_Path_One</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">train_data</span></em>, <em class="sig-param"><span class="n">target_variable</span></em>, <em class="sig-param"><span class="n">ml_usecase</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">test_data</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">categorical_features</span><span class="o">=</span><span class="default_value">[]</span></em>, <em class="sig-param"><span class="n">numerical_features</span><span class="o">=</span><span class="default_value">[]</span></em>, <em class="sig-param"><span class="n">time_features</span><span class="o">=</span><span class="default_value">[]</span></em>, <em class="sig-param"><span class="n">features_todrop</span><span class="o">=</span><span class="default_value">[]</span></em>, <em class="sig-param"><span class="n">display_types</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">imputation_type</span><span class="o">=</span><span class="default_value">'simple imputer'</span></em>, <em class="sig-param"><span class="n">numeric_imputation_strategy</span><span class="o">=</span><span class="default_value">'mean'</span></em>, <em class="sig-param"><span class="n">categorical_imputation_strategy</span><span class="o">=</span><span class="default_value">'not_available'</span></em>, <em class="sig-param"><span class="n">apply_zero_nearZero_variance</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">club_rare_levels</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">rara_level_threshold_percentage</span><span class="o">=</span><span class="default_value">0.05</span></em>, <em class="sig-param"><span class="n">apply_untrained_levels_treatment</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">untrained_levels_treatment_method</span><span class="o">=</span><span class="default_value">'least frequent'</span></em>, <em class="sig-param"><span class="n">apply_ordinal_encoding</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">ordinal_columns_and_categories</span><span class="o">=</span><span class="default_value">{}</span></em>, <em class="sig-param"><span class="n">apply_cardinality_reduction</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">cardinal_method</span><span class="o">=</span><span class="default_value">'cluster'</span></em>, <em class="sig-param"><span class="n">cardinal_features</span><span class="o">=</span><span class="default_value">[]</span></em>, <em class="sig-param"><span class="n">apply_binning</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">features_to_binn</span><span class="o">=</span><span class="default_value">[]</span></em>, <em class="sig-param"><span class="n">apply_grouping</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">group_name</span><span class="o">=</span><span class="default_value">[]</span></em>, <em class="sig-param"><span class="n">features_to_group_ListofList</span><span class="o">=</span><span class="default_value">[[]]</span></em>, <em class="sig-param"><span class="n">apply_polynomial_trigonometry_features</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">max_polynomial</span><span class="o">=</span><span class="default_value">2</span></em>, <em class="sig-param"><span class="n">trigonometry_calculations</span><span class="o">=</span><span class="default_value">['sin', 'cos', 'tan']</span></em>, <em class="sig-param"><span class="n">top_poly_trig_features_to_select_percentage</span><span class="o">=</span><span class="default_value">0.2</span></em>, <em class="sig-param"><span class="n">scale_data</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">scaling_method</span><span class="o">=</span><span class="default_value">'zscore'</span></em>, <em class="sig-param"><span class="n">Power_transform_data</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">Power_transform_method</span><span class="o">=</span><span class="default_value">'quantile'</span></em>, <em class="sig-param"><span class="n">target_transformation</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">target_transformation_method</span><span class="o">=</span><span class="default_value">'bc'</span></em>, <em class="sig-param"><span class="n">remove_outliers</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">outlier_contamination_percentage</span><span class="o">=</span><span class="default_value">0.01</span></em>, <em class="sig-param"><span class="n">outlier_methods</span><span class="o">=</span><span class="default_value">['pca', 'iso', 'knn']</span></em>, <em class="sig-param"><span class="n">apply_feature_selection</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">feature_selection_top_features_percentage</span><span class="o">=</span><span class="default_value">0.8</span></em>, <em class="sig-param"><span class="n">remove_multicollinearity</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">maximum_correlation_between_features</span><span class="o">=</span><span class="default_value">0.9</span></em>, <em class="sig-param"><span class="n">remove_perfect_collinearity</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">apply_feature_interactions</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">feature_interactions_to_apply</span><span class="o">=</span><span class="default_value">['multiply', 'divide', 'add', 'subtract']</span></em>, <em class="sig-param"><span class="n">feature_interactions_top_features_to_select_percentage</span><span class="o">=</span><span class="default_value">0.01</span></em>, <em class="sig-param"><span class="n">cluster_entire_data</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">range_of_clusters_to_try</span><span class="o">=</span><span class="default_value">20</span></em>, <em class="sig-param"><span class="n">apply_pca</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">pca_method</span><span class="o">=</span><span class="default_value">'pca_liner'</span></em>, <em class="sig-param"><span class="n">pca_variance_retained_or_number_of_components</span><span class="o">=</span><span class="default_value">0.99</span></em>, <em class="sig-param"><span class="n">random_state</span><span class="o">=</span><span class="default_value">42</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.preprocess.Preprocess_Path_One" title="Permalink to this definition">¶</a></dt>
<dd><dl>
<dt>Follwoing preprocess steps are taken:</dt><dd><ul class="simple">
<li><ol class="arabic simple">
<li><p>Auto infer data types</p></li>
</ol>
</li>
<li><ol class="arabic simple" start="2">
<li><p>Impute (simple or with surrogate columns)</p></li>
</ol>
</li>
<li><ol class="arabic simple" start="3">
<li><p>Ordinal Encoder</p></li>
</ol>
</li>
<li><ol class="arabic simple" start="4">
<li><p>Drop categorical variables that have zero variance or near zero variance</p></li>
</ol>
</li>
<li><ol class="arabic simple" start="5">
<li><p>Club categorical variables levels togather as a new level (other_infrequent) that are rare / at the bottom 5% of the variable distribution</p></li>
</ol>
</li>
<li><ol class="arabic simple" start="6">
<li><p>Club unseen levels in test dataset with most/least frequent levels in train dataset</p></li>
</ol>
</li>
<li><ol class="arabic simple" start="7">
<li><p>Reduce high cardinality in categorical features using clustering or counts</p></li>
</ol>
</li>
<li><ol class="arabic simple" start="8">
<li><p>Generate sub features from time feature such as ‘month’,’weekday’,is_month_end’,’is_month_start’ &amp; ‘hour’</p></li>
</ol>
</li>
<li><ol class="arabic simple" start="9">
<li><p>Group features by calculating min, max, mean, median &amp; sd of similar features</p></li>
</ol>
</li>
</ul>
<p>-10) Make nonliner features (polynomial, sin , cos &amp; tan)
-11) Scales &amp; Power Transform (zscore,minmax,yeo-johnson,quantile,maxabs,robust) , including option to transform target variable
-12) Apply binning to continious variable when numeric features are provided as a list
-13) Detect &amp; remove outliers using isolation forest, knn and PCA
-14) Apply clusters to segment entire data
-15) One Hot / Dummy encoding
-16) Remove special characters from column names such as commas, square brackets etc to make it competible with jason dependednt models
-17) Feature Selection throuh Random Forest , LightGBM and Pearson Correlation
-18) Fix multicollinearity
-19) Feature Interaction (DFS) , multiply , divided , add and substract features
-20) Apply diamension reduction techniques such as pca_liner, pca_kernal, incremental, tsne</p>
<blockquote>
<div><ul class="simple">
<li><p>except for pca_liner, all other method only takes number of component (as integer) i.e no variance explaination metohd available</p></li>
</ul>
</div></blockquote>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pycaret.preprocess.Preprocess_Path_Two">
<code class="sig-prename descclassname">pycaret.preprocess.</code><code class="sig-name descname">Preprocess_Path_Two</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">train_data</span></em>, <em class="sig-param"><span class="n">ml_usecase</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">test_data</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">categorical_features</span><span class="o">=</span><span class="default_value">[]</span></em>, <em class="sig-param"><span class="n">numerical_features</span><span class="o">=</span><span class="default_value">[]</span></em>, <em class="sig-param"><span class="n">time_features</span><span class="o">=</span><span class="default_value">[]</span></em>, <em class="sig-param"><span class="n">features_todrop</span><span class="o">=</span><span class="default_value">[]</span></em>, <em class="sig-param"><span class="n">display_types</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">imputation_type</span><span class="o">=</span><span class="default_value">'simple imputer'</span></em>, <em class="sig-param"><span class="n">numeric_imputation_strategy</span><span class="o">=</span><span class="default_value">'mean'</span></em>, <em class="sig-param"><span class="n">categorical_imputation_strategy</span><span class="o">=</span><span class="default_value">'not_available'</span></em>, <em class="sig-param"><span class="n">apply_zero_nearZero_variance</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">club_rare_levels</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">rara_level_threshold_percentage</span><span class="o">=</span><span class="default_value">0.05</span></em>, <em class="sig-param"><span class="n">apply_untrained_levels_treatment</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">untrained_levels_treatment_method</span><span class="o">=</span><span class="default_value">'least frequent'</span></em>, <em class="sig-param"><span class="n">apply_cardinality_reduction</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">cardinal_method</span><span class="o">=</span><span class="default_value">'cluster'</span></em>, <em class="sig-param"><span class="n">cardinal_features</span><span class="o">=</span><span class="default_value">[]</span></em>, <em class="sig-param"><span class="n">apply_ordinal_encoding</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">ordinal_columns_and_categories</span><span class="o">=</span><span class="default_value">{}</span></em>, <em class="sig-param"><span class="n">apply_binning</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">features_to_binn</span><span class="o">=</span><span class="default_value">[]</span></em>, <em class="sig-param"><span class="n">apply_grouping</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">group_name</span><span class="o">=</span><span class="default_value">[]</span></em>, <em class="sig-param"><span class="n">features_to_group_ListofList</span><span class="o">=</span><span class="default_value">[[]]</span></em>, <em class="sig-param"><span class="n">scale_data</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">scaling_method</span><span class="o">=</span><span class="default_value">'zscore'</span></em>, <em class="sig-param"><span class="n">Power_transform_data</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">Power_transform_method</span><span class="o">=</span><span class="default_value">'quantile'</span></em>, <em class="sig-param"><span class="n">remove_outliers</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">outlier_contamination_percentage</span><span class="o">=</span><span class="default_value">0.01</span></em>, <em class="sig-param"><span class="n">outlier_methods</span><span class="o">=</span><span class="default_value">['pca', 'iso', 'knn']</span></em>, <em class="sig-param"><span class="n">remove_multicollinearity</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">maximum_correlation_between_features</span><span class="o">=</span><span class="default_value">0.9</span></em>, <em class="sig-param"><span class="n">remove_perfect_collinearity</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">apply_pca</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">pca_method</span><span class="o">=</span><span class="default_value">'pca_liner'</span></em>, <em class="sig-param"><span class="n">pca_variance_retained_or_number_of_components</span><span class="o">=</span><span class="default_value">0.99</span></em>, <em class="sig-param"><span class="n">random_state</span><span class="o">=</span><span class="default_value">42</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.preprocess.Preprocess_Path_Two" title="Permalink to this definition">¶</a></dt>
<dd><dl>
<dt>Follwoing preprocess steps are taken:</dt><dd><ul class="simple">
<li><p>THIS IS BUILt FOR UNSUPERVISED LEARNING</p></li>
<li><ol class="arabic simple">
<li><p>Auto infer data types</p></li>
</ol>
</li>
<li><ol class="arabic simple" start="2">
<li><p>Impute (simple or with surrogate columns)</p></li>
</ol>
</li>
<li><ol class="arabic simple" start="3">
<li><p>Ordinal Encoder</p></li>
</ol>
</li>
<li><ol class="arabic simple" start="4">
<li><p>Drop categorical variables that have zero variance or near zero variance</p></li>
</ol>
</li>
<li><ol class="arabic simple" start="5">
<li><p>Club categorical variables levels togather as a new level (other_infrequent) that are rare / at the bottom 5% of the variable distribution</p></li>
</ol>
</li>
<li><ol class="arabic simple" start="6">
<li><p>Club unseen levels in test dataset with most/least frequent levels in train dataset</p></li>
</ol>
</li>
<li><ol class="arabic simple" start="7">
<li><p>Reduce high cardinality in categorical features using clustering or counts</p></li>
</ol>
</li>
<li><ol class="arabic simple" start="8">
<li><p>Generate sub features from time feature such as ‘month’,’weekday’,is_month_end’,’is_month_start’ &amp; ‘hour’</p></li>
</ol>
</li>
<li><ol class="arabic simple" start="9">
<li><p>Group features by calculating min, max, mean, median &amp; sd of similar features</p></li>
</ol>
</li>
</ul>
<p>-10) Scales &amp; Power Transform (zscore,minmax,yeo-johnson,quantile,maxabs,robust) , including option to transform target variable
-11) Apply binning to continious variable when numeric features are provided as a list
-12) Detect &amp; remove outliers using isolation forest, knn and PCA
-13) One Hot / Dummy encoding
-14) Remove special characters from column names such as commas, square brackets etc to make it competible with jason dependednt models
-15) Fix multicollinearity
-16) Apply diamension reduction techniques such as pca_liner, pca_kernal, incremental, tsne</p>
<blockquote>
<div><ul class="simple">
<li><p>except for pca_liner, all other method only takes number of component (as integer) i.e no variance explaination metohd available</p></li>
</ul>
</div></blockquote>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt id="pycaret.preprocess.Reduce_Cardinality_with_Clustering">
<em class="property">class </em><code class="sig-prename descclassname">pycaret.preprocess.</code><code class="sig-name descname">Reduce_Cardinality_with_Clustering</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">target_variable</span></em>, <em class="sig-param"><span class="n">catagorical_feature</span><span class="o">=</span><span class="default_value">[]</span></em>, <em class="sig-param"><span class="n">check_clusters_upto</span><span class="o">=</span><span class="default_value">30</span></em>, <em class="sig-param"><span class="n">random_state</span><span class="o">=</span><span class="default_value">42</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.preprocess.Reduce_Cardinality_with_Clustering" title="Permalink to this definition">¶</a></dt>
<dd><ul>
<li><p>Reduces the level of catagorical column / cardinality through clustering</p></li>
<li><p>Highly recommended to run the DataTypes_Auto_infer class first
Args:</p>
<blockquote>
<div><p>target_variable: target variable (integer or numerical only)
catagorical_feature: list of features on which clustering  is to be applied / cardinality to be reduced
check_clusters_upto: to determine optimum number of kmeans clusters, set the uppler limit of clusters</p>
</div></blockquote>
</li>
</ul>
<dl class="py method">
<dt id="pycaret.preprocess.Reduce_Cardinality_with_Clustering.fit_transform">
<code class="sig-name descname">fit_transform</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">dataset</span></em>, <em class="sig-param"><span class="n">y</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.preprocess.Reduce_Cardinality_with_Clustering.fit_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit to data, then transform it.</p>
<p>Fits transformer to X and y with optional parameters fit_params
and returns a transformed version of X.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>numpy array of shape</em><em> [</em><em>n_samples</em><em>, </em><em>n_features</em><em>]</em>) – Training set.</p></li>
<li><p><strong>y</strong> (<em>numpy array of shape</em><em> [</em><em>n_samples</em><em>]</em>) – Target values.</p></li>
<li><p><strong>**fit_params</strong> (<em>dict</em>) – Additional fit parameters.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>X_new</strong> – Transformed array.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>numpy array of shape [n_samples, n_features_new]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="pycaret.preprocess.Reduce_Cardinality_with_Counts">
<em class="property">class </em><code class="sig-prename descclassname">pycaret.preprocess.</code><code class="sig-name descname">Reduce_Cardinality_with_Counts</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">catagorical_feature</span><span class="o">=</span><span class="default_value">[]</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.preprocess.Reduce_Cardinality_with_Counts" title="Permalink to this definition">¶</a></dt>
<dd><ul>
<li><p>Reduces the level of catagorical column by replacing levels with their count &amp; converting objects into float
Args:</p>
<blockquote>
<div><p>catagorical_feature: list of features on which clustering is to be applied</p>
</div></blockquote>
</li>
</ul>
<dl class="py method">
<dt id="pycaret.preprocess.Reduce_Cardinality_with_Counts.fit_transform">
<code class="sig-name descname">fit_transform</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">dataset</span></em>, <em class="sig-param"><span class="n">y</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.preprocess.Reduce_Cardinality_with_Counts.fit_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit to data, then transform it.</p>
<p>Fits transformer to X and y with optional parameters fit_params
and returns a transformed version of X.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>numpy array of shape</em><em> [</em><em>n_samples</em><em>, </em><em>n_features</em><em>]</em>) – Training set.</p></li>
<li><p><strong>y</strong> (<em>numpy array of shape</em><em> [</em><em>n_samples</em><em>]</em>) – Target values.</p></li>
<li><p><strong>**fit_params</strong> (<em>dict</em>) – Additional fit parameters.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>X_new</strong> – Transformed array.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>numpy array of shape [n_samples, n_features_new]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="pycaret.preprocess.Reduce_Dimensions_For_Supervised_Path">
<em class="property">class </em><code class="sig-prename descclassname">pycaret.preprocess.</code><code class="sig-name descname">Reduce_Dimensions_For_Supervised_Path</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">target</span></em>, <em class="sig-param"><span class="n">method</span><span class="o">=</span><span class="default_value">'pca_liner'</span></em>, <em class="sig-param"><span class="n">variance_retained_or_number_of_components</span><span class="o">=</span><span class="default_value">0.99</span></em>, <em class="sig-param"><span class="n">random_state</span><span class="o">=</span><span class="default_value">42</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.preprocess.Reduce_Dimensions_For_Supervised_Path" title="Permalink to this definition">¶</a></dt>
<dd><ul class="simple">
<li><p>Takes DF, return same DF with different types of dimensionality reduction modles (pca_liner , pca_kernal, tsne , pls, incremental)</p></li>
<li><p>except pca_liner, every other method takes integer as number of components</p></li>
<li><p>only takes numeric variables (float &amp; One Hot Encoded)</p></li>
<li><p>it is intended to solve supervised ML usecases , such as classification / regression</p></li>
</ul>
<dl class="py method">
<dt id="pycaret.preprocess.Reduce_Dimensions_For_Supervised_Path.fit_transform">
<code class="sig-name descname">fit_transform</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">dataset</span></em>, <em class="sig-param"><span class="n">y</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.preprocess.Reduce_Dimensions_For_Supervised_Path.fit_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit to data, then transform it.</p>
<p>Fits transformer to X and y with optional parameters fit_params
and returns a transformed version of X.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>numpy array of shape</em><em> [</em><em>n_samples</em><em>, </em><em>n_features</em><em>]</em>) – Training set.</p></li>
<li><p><strong>y</strong> (<em>numpy array of shape</em><em> [</em><em>n_samples</em><em>]</em>) – Target values.</p></li>
<li><p><strong>**fit_params</strong> (<em>dict</em>) – Additional fit parameters.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>X_new</strong> – Transformed array.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>numpy array of shape [n_samples, n_features_new]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="pycaret.preprocess.Remove_100">
<em class="property">class </em><code class="sig-prename descclassname">pycaret.preprocess.</code><code class="sig-name descname">Remove_100</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">target</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.preprocess.Remove_100" title="Permalink to this definition">¶</a></dt>
<dd><ul class="simple">
<li><p>Takes DF, return data frame while removing features that are perfectly correlated (droping one)</p></li>
</ul>
<dl class="py method">
<dt id="pycaret.preprocess.Remove_100.fit_transform">
<code class="sig-name descname">fit_transform</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">dataset</span></em>, <em class="sig-param"><span class="n">y</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.preprocess.Remove_100.fit_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit to data, then transform it.</p>
<p>Fits transformer to X and y with optional parameters fit_params
and returns a transformed version of X.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>numpy array of shape</em><em> [</em><em>n_samples</em><em>, </em><em>n_features</em><em>]</em>) – Training set.</p></li>
<li><p><strong>y</strong> (<em>numpy array of shape</em><em> [</em><em>n_samples</em><em>]</em>) – Target values.</p></li>
<li><p><strong>**fit_params</strong> (<em>dict</em>) – Additional fit parameters.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>X_new</strong> – Transformed array.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>numpy array of shape [n_samples, n_features_new]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="pycaret.preprocess.Scaling_and_Power_transformation">
<em class="property">class </em><code class="sig-prename descclassname">pycaret.preprocess.</code><code class="sig-name descname">Scaling_and_Power_transformation</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">target</span></em>, <em class="sig-param"><span class="n">function_to_apply</span><span class="o">=</span><span class="default_value">'zscore'</span></em>, <em class="sig-param"><span class="n">random_state_quantile</span><span class="o">=</span><span class="default_value">42</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.preprocess.Scaling_and_Power_transformation" title="Permalink to this definition">¶</a></dt>
<dd><p>-Given a data set, applies Min Max, Standar Scaler or Power Transformation (yeo-johnson)
-it is recommended to run Define_dataTypes first
- ignores target variable</p>
<blockquote>
<div><dl class="simple">
<dt>Args:</dt><dd><p>target: string , name of the target variable
function_to_apply: string , default ‘zscore’ (standard scaler), all other {‘minmaxm’,’yj’,’quantile’,’robust’,’maxabs’} ( min max,yeo-johnson &amp; quantile power transformation, robust and MaxAbs scaler )</p>
</dd>
</dl>
</div></blockquote>
<dl class="py method">
<dt id="pycaret.preprocess.Scaling_and_Power_transformation.fit_transform">
<code class="sig-name descname">fit_transform</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">dataset</span></em>, <em class="sig-param"><span class="n">y</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.preprocess.Scaling_and_Power_transformation.fit_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit to data, then transform it.</p>
<p>Fits transformer to X and y with optional parameters fit_params
and returns a transformed version of X.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>numpy array of shape</em><em> [</em><em>n_samples</em><em>, </em><em>n_features</em><em>]</em>) – Training set.</p></li>
<li><p><strong>y</strong> (<em>numpy array of shape</em><em> [</em><em>n_samples</em><em>]</em>) – Target values.</p></li>
<li><p><strong>**fit_params</strong> (<em>dict</em>) – Additional fit parameters.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>X_new</strong> – Transformed array.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>numpy array of shape [n_samples, n_features_new]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="pycaret.preprocess.Simple_Imputer">
<em class="property">class </em><code class="sig-prename descclassname">pycaret.preprocess.</code><code class="sig-name descname">Simple_Imputer</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">numeric_strategy</span></em>, <em class="sig-param"><span class="n">categorical_strategy</span></em>, <em class="sig-param"><span class="n">target_variable</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.preprocess.Simple_Imputer" title="Permalink to this definition">¶</a></dt>
<dd><dl>
<dt>Imputes all type of data (numerical,categorical &amp; Time).</dt><dd><p>Highly recommended to run Define_dataTypes class first
Numerical values can be imputed with mean or median
categorical missing values will be replaced with “Other”
Time values are imputed with the most frequesnt value
Ignores target (y) variable
Args:</p>
<blockquote>
<div><p>Numeric_strategy: string , all possible values {‘mean’,’median’}
categorical_strategy: string , all possible values {‘not_available’,’most frequent’}
target: string , name of the target variable</p>
</div></blockquote>
</dd>
</dl>
<dl class="py method">
<dt id="pycaret.preprocess.Simple_Imputer.fit_transform">
<code class="sig-name descname">fit_transform</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">dataset</span></em>, <em class="sig-param"><span class="n">y</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.preprocess.Simple_Imputer.fit_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit to data, then transform it.</p>
<p>Fits transformer to X and y with optional parameters fit_params
and returns a transformed version of X.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>numpy array of shape</em><em> [</em><em>n_samples</em><em>, </em><em>n_features</em><em>]</em>) – Training set.</p></li>
<li><p><strong>y</strong> (<em>numpy array of shape</em><em> [</em><em>n_samples</em><em>]</em>) – Target values.</p></li>
<li><p><strong>**fit_params</strong> (<em>dict</em>) – Additional fit parameters.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>X_new</strong> – Transformed array.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>numpy array of shape [n_samples, n_features_new]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="pycaret.preprocess.Surrogate_Imputer">
<em class="property">class </em><code class="sig-prename descclassname">pycaret.preprocess.</code><code class="sig-name descname">Surrogate_Imputer</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">numeric_strategy</span></em>, <em class="sig-param"><span class="n">categorical_strategy</span></em>, <em class="sig-param"><span class="n">target_variable</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.preprocess.Surrogate_Imputer" title="Permalink to this definition">¶</a></dt>
<dd><dl>
<dt>Imputes feature with surrogate column (numerical,categorical &amp; Time).</dt><dd><ul class="simple">
<li><p>Highly recommended to run Define_dataTypes class first</p></li>
<li><p>it is also recommended to only apply this to features where it makes business sense to creat surrogate column</p></li>
<li><p>feature name has to be provided</p></li>
<li><p>only able to handle one feature at a time</p></li>
<li><p>Numerical values can be imputed with mean or median</p></li>
<li><p>categorical missing values will be replaced with “Other”</p></li>
<li><p>Time values are imputed with the most frequesnt value</p></li>
<li><p>Ignores target (y) variable</p></li>
</ul>
<dl class="simple">
<dt>Args:</dt><dd><p>feature_name: string, provide features name
feature_type: string , all possible values {‘numeric’,’categorical’,’date’}
strategy: string ,all possible values {‘mean’,’median’,’not_available’,’most frequent’}
target: string , name of the target variable</p>
</dd>
</dl>
</dd>
</dl>
<dl class="py method">
<dt id="pycaret.preprocess.Surrogate_Imputer.fit_transform">
<code class="sig-name descname">fit_transform</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">dataset</span></em>, <em class="sig-param"><span class="n">y</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.preprocess.Surrogate_Imputer.fit_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit to data, then transform it.</p>
<p>Fits transformer to X and y with optional parameters fit_params
and returns a transformed version of X.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>numpy array of shape</em><em> [</em><em>n_samples</em><em>, </em><em>n_features</em><em>]</em>) – Training set.</p></li>
<li><p><strong>y</strong> (<em>numpy array of shape</em><em> [</em><em>n_samples</em><em>]</em>) – Target values.</p></li>
<li><p><strong>**fit_params</strong> (<em>dict</em>) – Additional fit parameters.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>X_new</strong> – Transformed array.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>numpy array of shape [n_samples, n_features_new]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="pycaret.preprocess.Target_Transformation">
<em class="property">class </em><code class="sig-prename descclassname">pycaret.preprocess.</code><code class="sig-name descname">Target_Transformation</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">target</span></em>, <em class="sig-param"><span class="n">function_to_apply</span><span class="o">=</span><span class="default_value">'bc'</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.preprocess.Target_Transformation" title="Permalink to this definition">¶</a></dt>
<dd><ul class="simple">
<li><p>Applies Power Transformation (yeo-johnson , Box-Cox) to target variable (Applicable to Regression only)
- ‘bc’ for Box_Coc &amp; ‘yj’ for yeo-johnson, default is Box-Cox</p></li>
<li><p>if target containes negtive / zero values , yeo-johnson is automatically selected</p></li>
</ul>
<dl class="py method">
<dt id="pycaret.preprocess.Target_Transformation.fit_transform">
<code class="sig-name descname">fit_transform</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">dataset</span></em>, <em class="sig-param"><span class="n">y</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.preprocess.Target_Transformation.fit_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit to data, then transform it.</p>
<p>Fits transformer to X and y with optional parameters fit_params
and returns a transformed version of X.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>numpy array of shape</em><em> [</em><em>n_samples</em><em>, </em><em>n_features</em><em>]</em>) – Training set.</p></li>
<li><p><strong>y</strong> (<em>numpy array of shape</em><em> [</em><em>n_samples</em><em>]</em>) – Target values.</p></li>
<li><p><strong>**fit_params</strong> (<em>dict</em>) – Additional fit parameters.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>X_new</strong> – Transformed array.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>numpy array of shape [n_samples, n_features_new]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="pycaret.preprocess.Zroe_NearZero_Variance">
<em class="property">class </em><code class="sig-prename descclassname">pycaret.preprocess.</code><code class="sig-name descname">Zroe_NearZero_Variance</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">target</span></em>, <em class="sig-param"><span class="n">threshold_1</span><span class="o">=</span><span class="default_value">0.1</span></em>, <em class="sig-param"><span class="n">threshold_2</span><span class="o">=</span><span class="default_value">20</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.preprocess.Zroe_NearZero_Variance" title="Permalink to this definition">¶</a></dt>
<dd><ul class="simple">
<li><p>it eliminates the features having zero variance</p></li>
<li><p>it eliminates the features haveing near zero variance</p></li>
<li><p>Near zero variance is determined by
-1) Count of unique points divided by the total length of the feature has to be lower than a pre sepcified threshold
-2) Most common point(count) divided by the second most common point(count) in the feature is greater than a pre specified threshold
Once both conditions are met , the feature is dropped</p></li>
</ul>
<p>-Ignores target variable</p>
<blockquote>
<div><dl class="simple">
<dt>Args:</dt><dd><p>threshold_1: float (between 0.0 to 1.0) , default is .10
threshold_2: int (between 1 to 100), default is 20
tatget variable : string, name of the target variable</p>
</dd>
</dl>
</div></blockquote>
<dl class="py method">
<dt id="pycaret.preprocess.Zroe_NearZero_Variance.fit_transform">
<code class="sig-name descname">fit_transform</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">dataset</span></em>, <em class="sig-param"><span class="n">y</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.preprocess.Zroe_NearZero_Variance.fit_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit to data, then transform it.</p>
<p>Fits transformer to X and y with optional parameters fit_params
and returns a transformed version of X.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>numpy array of shape</em><em> [</em><em>n_samples</em><em>, </em><em>n_features</em><em>]</em>) – Training set.</p></li>
<li><p><strong>y</strong> (<em>numpy array of shape</em><em> [</em><em>n_samples</em><em>]</em>) – Target values.</p></li>
<li><p><strong>**fit_params</strong> (<em>dict</em>) – Additional fit parameters.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>X_new</strong> – Transformed array.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>numpy array of shape [n_samples, n_features_new]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-pycaret.datasets">
<span id="datasets"></span><h1>Datasets<a class="headerlink" href="#module-pycaret.datasets" title="Permalink to this headline">¶</a></h1>
<dl class="py function">
<dt id="pycaret.datasets.get_data">
<code class="sig-prename descclassname">pycaret.datasets.</code><code class="sig-name descname">get_data</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">dataset</span></em>, <em class="sig-param"><span class="n">save_copy</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">profile</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.datasets.get_data" title="Permalink to this definition">¶</a></dt>
<dd><p>This function loads sample datasets that are available in the pycaret git
repository. The full list of available datasets and their descriptions can
be viewed by calling index.</p>
<blockquote>
<div><p>data = get_data(‘index’)</p>
<p>This will display the list of available datasets that can be loaded
using the get_data() function. For example, to load the credit dataset:</p>
<p>credit = get_data(‘credit’)</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dataset</strong> (<em>string</em>) – </p></li>
<li><p><strong>value of dataset</strong> (<em>index</em>) – </p></li>
<li><p><strong>save_copy</strong> (<em>bool</em><em>, </em><em>default = False</em>) – </p></li>
<li><p><strong>set to true</strong><strong>, </strong><strong>it saves a copy of the dataset to your local active directory.</strong> (<em>When</em>) – </p></li>
<li><p><strong>profile</strong> (<em>bool</em><em>, </em><em>default = False</em>) – </p></li>
<li><p><strong>set to true</strong><strong>, </strong><strong>a data profile for Exploratory Data Analysis will be displayed</strong> (<em>If</em>) – </p></li>
<li><p><strong>an interactive HTML report.</strong> (<em>in</em>) – </p></li>
<li><p><strong>Returns</strong> – </p></li>
<li><p><strong>--------</strong> – </p></li>
<li><p><strong>DataFrame</strong> (<em>Pandas dataframe is returned.</em>) – </p></li>
<li><p><strong>----------</strong> – </p></li>
<li><p><strong>Warnings</strong> – </p></li>
<li><p><strong>---------</strong> – </p></li>
<li><p><strong>Use of get_data</strong><strong>(</strong><strong>) </strong><strong>requires internet connection.</strong> (<em>-</em>) – </p></li>
</ul>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="clustering">
<h1>Clustering<a class="headerlink" href="#clustering" title="Permalink to this headline">¶</a></h1>
</div>
<div class="section" id="classification">
<h1>Classification<a class="headerlink" href="#classification" title="Permalink to this headline">¶</a></h1>
</div>
<div class="section" id="module-pycaret.arules">
<span id="arules"></span><h1>Arules<a class="headerlink" href="#module-pycaret.arules" title="Permalink to this headline">¶</a></h1>
<dl class="py function">
<dt id="pycaret.arules.create_model">
<code class="sig-prename descclassname">pycaret.arules.</code><code class="sig-name descname">create_model</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">metric</span><span class="o">=</span><span class="default_value">'confidence'</span></em>, <em class="sig-param"><span class="n">threshold</span><span class="o">=</span><span class="default_value">0.5</span></em>, <em class="sig-param"><span class="n">min_support</span><span class="o">=</span><span class="default_value">0.05</span></em>, <em class="sig-param"><span class="n">round</span><span class="o">=</span><span class="default_value">4</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.arules.create_model" title="Permalink to this definition">¶</a></dt>
<dd><p>This function creates an association rules model using data and identifiers
passed at setup stage. This function internally transforms the data for
association rule mining.</p>
<p>setup() function must be called before using create_model()</p>
<blockquote>
<div><p>from pycaret.datasets import get_data
france get_data(‘france’)
experiment_name = setup(data = data, transaction_id = ‘InvoiceNo’,</p>
<blockquote>
<div><p>item_id = ‘ProductName’)</p>
</div></blockquote>
<p>This will return dataframe containing rules sorted by metric param.</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>metric</strong> (<em>string</em><em>, </em><em>default = 'confidence'</em>) – </p></li>
<li><p><strong>to evaluate if a rule is of interest. Default is set to confidence.</strong> (<em>Metric</em>) – </p></li>
<li><p><strong>available metrics include 'support'</strong><strong>, </strong><strong>'lift'</strong><strong>, </strong><strong>'leverage'</strong><strong>, </strong><strong>'conviction'.</strong> (<em>Other</em>) – </p></li>
<li><p><strong>metrics are computed as follows</strong> (<em>These</em>) – </p></li>
<li><p><strong>support</strong><strong>(</strong><strong>A-&gt;C</strong><strong>) </strong><strong>= support</strong><strong>(</strong><strong>A+C</strong><strong>) </strong><strong>[</strong><strong>aka 'support'</strong><strong>]</strong><strong>, </strong><strong>range</strong> (<em>-</em>) – </p></li>
<li><p><strong>confidence</strong><strong>(</strong><strong>A-&gt;C</strong><strong>) </strong><strong>= support</strong><strong>(</strong><strong>A+C</strong><strong>) </strong><strong>/ support</strong><strong>(</strong><strong>A</strong><strong>)</strong><strong>, </strong><strong>range</strong> (<em>-</em>) – </p></li>
<li><p><strong>lift</strong><strong>(</strong><strong>A-&gt;C</strong><strong>) </strong><strong>= confidence</strong><strong>(</strong><strong>A-&gt;C</strong><strong>) </strong><strong>/ support</strong><strong>(</strong><strong>C</strong><strong>)</strong><strong>, </strong><strong>range</strong> (<em>-</em>) – </p></li>
<li><p><strong>leverage</strong><strong>(</strong><strong>A-&gt;C</strong><strong>) </strong><strong>= support</strong><strong>(</strong><strong>A-&gt;C</strong><strong>) </strong><strong>- support</strong><strong>(</strong><strong>A</strong><strong>)</strong><strong>*support</strong><strong>(</strong><strong>C</strong><strong>)</strong><strong>,</strong> (<em>-</em>) – range: [-1, 1]</p></li>
<li><p><strong>conviction =</strong><strong> [</strong><strong>1 - support</strong><strong>(</strong><strong>C</strong><strong>)</strong><strong>] </strong><strong>/</strong><strong> [</strong><strong>1 - confidence</strong><strong>(</strong><strong>A-&gt;C</strong><strong>)</strong><strong>]</strong><strong>,</strong> (<em>-</em>) – range: [0, inf]</p></li>
<li><p><strong>threshold</strong> (<em>float</em><em>, </em><em>default = 0.5</em>) – </p></li>
<li><p><strong>threshold for the evaluation metric</strong><strong>, </strong><strong>via the metric parameter</strong><strong>,</strong> (<em>Minimal</em>) – </p></li>
<li><p><strong>decide whether a candidate rule is of interest.</strong> (<em>to</em>) – </p></li>
<li><p><strong>min_support</strong> (<em>float</em><em>, </em><em>default = 0.05</em>) – </p></li>
<li><p><strong>float between 0 and 1 for minumum support of the itemsets returned.</strong> (<em>A</em>) – </p></li>
<li><p><strong>support is computed as the fraction `transactions_where_item</strong><strong>(</strong><strong>s</strong><strong>)</strong><strong>_occur /</strong> (<em>The</em>) – </p></li>
<li><p><strong>total_transactions`.</strong> – </p></li>
<li><p><strong>round</strong> (<em>integer</em><em>, </em><em>default = 4</em>) – </p></li>
<li><p><strong>of decimal places metrics in score grid will be rounded to.</strong> (<em>Number</em>) – </p></li>
</ul>
</dd>
</dl>
<p>DataFrame:   Dataframe containing rules of interest with all metrics
———    including antecedents, consequents, antecedent support,</p>
<blockquote>
<div><p>consequent support, support, confidence, lift, leverage,
conviction.</p>
</div></blockquote>
<ul class="simple">
<li><p>Setting low values for min_support may increase training time.</p></li>
</ul>
</dd></dl>

<dl class="py function">
<dt id="pycaret.arules.get_rules">
<code class="sig-prename descclassname">pycaret.arules.</code><code class="sig-name descname">get_rules</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">transaction_id</span></em>, <em class="sig-param"><span class="n">item_id</span></em>, <em class="sig-param"><span class="n">ignore_items</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">metric</span><span class="o">=</span><span class="default_value">'confidence'</span></em>, <em class="sig-param"><span class="n">threshold</span><span class="o">=</span><span class="default_value">0.5</span></em>, <em class="sig-param"><span class="n">min_support</span><span class="o">=</span><span class="default_value">0.05</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.arules.get_rules" title="Permalink to this definition">¶</a></dt>
<dd><p>Magic function to get Association Rules in Power Query / Power BI.</p>
</dd></dl>

<dl class="py function">
<dt id="pycaret.arules.plot_model">
<code class="sig-prename descclassname">pycaret.arules.</code><code class="sig-name descname">plot_model</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">model</span></em>, <em class="sig-param"><span class="n">plot</span><span class="o">=</span><span class="default_value">'2d'</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.arules.plot_model" title="Permalink to this definition">¶</a></dt>
<dd><p>This function takes a model dataframe returned by create_model() function.
‘2d’ and ‘3d’ plots are available.</p>
<blockquote>
<div><p>rule1 = create_model(metric=’confidence’, threshold=0.7, min_support=0.05)
plot_model(rule1, plot=’2d’)
plot_model(rule1, plot=’3d’)</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>DataFrame</em><em>, </em><em>default = none</em>) – </p></li>
<li><p><strong>returned by trained model using create_model</strong><strong>(</strong><strong>)</strong><strong></strong> (<em>DataFrame</em>) – </p></li>
<li><p><strong>plot</strong> (<em>string</em><em>, </em><em>default = '2d'</em>) – </p></li>
<li><p><strong>abbreviation of type of plot. The current list of plots supported are</strong> (<em>Enter</em>) – </p></li>
<li><p><strong>Abbreviated String</strong> (<em>Name</em>) – </p></li>
<li><p><strong>------------------</strong> (<em>---------</em>) – </p></li>
<li><p><strong>Confidence and Lift</strong><strong> (</strong><strong>2d</strong><strong>)    </strong><strong>'2d'</strong> (<em>Support</em><em>,</em>) – </p></li>
<li><p><strong>Confidence and Lift</strong><strong> (</strong><strong>3d</strong><strong>)    </strong><strong>'3d'</strong> (<em>Support</em><em>,</em>) – </p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pycaret.arules.setup">
<code class="sig-prename descclassname">pycaret.arules.</code><code class="sig-name descname">setup</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">transaction_id</span></em>, <em class="sig-param"><span class="n">item_id</span></em>, <em class="sig-param"><span class="n">ignore_items</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">session_id</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.arules.setup" title="Permalink to this definition">¶</a></dt>
<dd><p>This function initializes the environment in pycaret. setup() must called before
executing any other function in pycaret. It takes three mandatory parameters:
(i) dataframe {array-like, sparse matrix}, (ii) transaction_id param identifying
basket and (iii) item_id param used to create rules. These three params are
normally found in any transactional dataset. pycaret will internally convert the
dataframe into a sparse matrix which is required for association rules mining.</p>
<blockquote>
<div><p>from pycaret.datasets import get_data
france get_data(‘france’)</p>
<dl class="simple">
<dt>experiment_name = setup(data = data, transaction_id = ‘InvoiceNo’,</dt><dd><p>item_id = ‘ProductName’)</p>
</dd>
</dl>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<em>{array-like</em><em>, </em><em>sparse matrix}</em><em>, </em><em>shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>) </em><em>where n_samples</em>) – </p></li>
<li><p><strong>the number of samples and n_features is the number of features.</strong> (<em>is</em>) – </p></li>
<li><p><strong>transaction_id</strong> (<em>string</em>) – </p></li>
<li><p><strong>of column representing transaction id. This will be used to pivot the matrix.</strong> (<em>Name</em>) – </p></li>
<li><p><strong>item_id</strong> (<em>string</em>) – </p></li>
<li><p><strong>of column used for creation of rules. Normally</strong><strong>, </strong><strong>this will be the variable of</strong> (<em>Name</em>) – </p></li>
<li><p><strong>interest.</strong> – </p></li>
<li><p><strong>ignore_items</strong> (<em>list</em><em>, </em><em>default = None</em>) – </p></li>
<li><p><strong>of strings to be ignored when considering rule mining.</strong> (<em>list</em>) – </p></li>
<li><p><strong>session_id</strong> (<em>int</em><em>, </em><em>default = None</em>) – </p></li>
<li><p><strong>None</strong><strong>, </strong><strong>a random seed is generated and returned in the Information grid. The</strong> (<em>If</em>) – </p></li>
<li><p><strong>number is then distributed as a seed in all functions used during the</strong> (<em>unique</em>) – </p></li>
<li><p><strong>This can be used for later reproducibility of the entire experiment.</strong> (<em>experiment.</em>) – </p></li>
<li><p><strong>Returns</strong> – </p></li>
<li><p><strong>--------</strong> – </p></li>
<li><p><strong>grid</strong> (<em>info</em>) – </p></li>
<li><p><strong>-----------</strong> – </p></li>
<li><p><strong>environment</strong> (<em>This function returns various outputs that are stored in variable</em>) – </p></li>
<li><p><strong>as tuple. They are used by other functions in pycaret.</strong> (<em>-----------</em>) – </p></li>
<li><p><strong>Warnings</strong> – </p></li>
<li><p><strong>---------</strong> – </p></li>
<li><p><strong>None</strong> – </p></li>
</ul>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-pycaret.anomaly">
<span id="anomaly"></span><h1>Anomaly<a class="headerlink" href="#module-pycaret.anomaly" title="Permalink to this headline">¶</a></h1>
<dl class="py function">
<dt id="pycaret.anomaly.assign_model">
<code class="sig-prename descclassname">pycaret.anomaly.</code><code class="sig-name descname">assign_model</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">model</span></em>, <em class="sig-param"><span class="n">transformation</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">score</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.anomaly.assign_model" title="Permalink to this definition">¶</a></dt>
<dd><p>This function flags each of the data point in the dataset passed during setup
stage as either outlier or inlier (1 = outlier, 0 = inlier) using trained model
object passed as model param. create_model() function must be called before using
assign_model().</p>
<p>This function returns dataframe with Outlier flag (1 = outlier, 0 = inlier) and
decision score, when score is set to True.</p>
<blockquote>
<div><p>from pycaret.datasets import get_data
anomaly = get_data(‘anomaly’)
experiment_name = setup(data = anomaly, normalize = True)
knn = create_model(‘knn’)</p>
<p>knn_df = assign_model(knn)</p>
<p>This will return a dataframe with inferred outliers using trained model.</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>trained model object</em><em>, </em><em>default = None</em>) – </p></li>
<li><p><strong>transformation</strong> (<em>bool</em><em>, </em><em>default = False</em>) – </p></li>
<li><p><strong>set to True</strong><strong>, </strong><strong>assigned outliers are returned on transformed dataset instead</strong> (<em>When</em>) – </p></li>
<li><p><strong>original dataset passed during setup</strong><strong>(</strong><strong>)</strong><strong></strong> (<em>of</em>) – </p></li>
<li><p><strong>score</strong> (<em>Boolean</em><em>, </em><em>default = True</em>) – </p></li>
<li><p><strong>outlier scores of the training data. The higher</strong><strong>, </strong><strong>the more abnormal.</strong> (<em>The</em>) – </p></li>
<li><p><strong>tend to have higher scores. This value is available once the model</strong> (<em>Outliers</em>) – </p></li>
<li><p><strong>fitted. If set to False</strong><strong>, </strong><strong>it will only return the flag</strong><strong> (</strong><strong>1 = outlier</strong><strong>, </strong><strong>0 = inlier</strong><strong>)</strong><strong></strong> (<em>is</em>) – </p></li>
<li><p><strong>verbose</strong> (<em>Boolean</em><em>, </em><em>default = True</em>) – </p></li>
<li><p><strong>update is not printed when verbose is set to False.</strong> (<em>Status</em>) – </p></li>
<li><p><strong>Returns</strong> – </p></li>
<li><p><strong>--------</strong> – </p></li>
<li><p><strong>dataframe</strong> (<em>Returns a dataframe with inferred outliers using a trained model.</em>) – </p></li>
<li><p><strong>---------</strong> – </p></li>
<li><p><strong>Warnings</strong> – </p></li>
<li><p><strong>---------</strong> – </p></li>
<li><p><strong>None</strong> – </p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pycaret.anomaly.create_model">
<code class="sig-prename descclassname">pycaret.anomaly.</code><code class="sig-name descname">create_model</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">model</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">fraction</span><span class="o">=</span><span class="default_value">0.05</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.anomaly.create_model" title="Permalink to this definition">¶</a></dt>
<dd><p>This function creates a model on the dataset passed as a data param during
the setup stage. setup() function must be called before using create_model().</p>
<p>This function returns a trained model object.</p>
<blockquote>
<div><p>from pycaret.datasets import get_data
anomaly = get_data(‘anomaly’)
experiment_name = setup(data = anomaly, normalize = True)</p>
<p>knn = create_model(‘knn’)</p>
<p>This will return trained k-Nearest Neighbors model.</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>trained model object</em>) – </p></li>
<li><p><strong>abbreviated string of the model class. List of available models supported</strong> (<em>Enter</em>) – </p></li>
<li><p><strong>Abbreviated String   Original Implementation</strong> (<em>Model</em>) – </p></li>
<li><p><strong>------------------   -----------------------</strong> (<em>---------</em>) – </p></li>
<li><p><strong>Outlier Detection       'abod'               pyod.models.abod.ABOD</strong> (<em>Angle-base</em>) – </p></li>
<li><p><strong>Forest                   'iforest'            module-pyod.models.iforest</strong> (<em>Isolation</em>) – </p></li>
<li><p><strong>Local Outlier     'cluster'            pyod.models.cblof</strong> (<em>Clustering-Based</em>) – </p></li>
<li><p><strong>Outlier Factor  'cof'                module-pyod.models.cof</strong> (<em>Connectivity-Based</em>) – </p></li>
<li><p><strong>Outlier Detection  'histogram'          module-pyod.models.hbos</strong> (<em>Histogram-based</em>) – </p></li>
<li><p><strong>Neighbors Detector       'knn'                module-pyod.models.knn</strong> (<em>k-Nearest</em>) – </p></li>
<li><p><strong>Outlier Factor               'lof'                module-pyod.models.lof</strong> (<em>Local</em>) – </p></li>
<li><p><strong>SVM detector             'svm'                module-pyod.models.ocsvm</strong> (<em>One-class</em>) – </p></li>
<li><p><strong>Component Analysis       'pca'                module-pyod.models.pca</strong> (<em>Principal</em>) – </p></li>
<li><p><strong>Covariance Determinant     'mcd'                module-pyod.models.mcd</strong> (<em>Minimum</em>) – </p></li>
<li><p><strong>Outlier Detection         'sod'                module-pyod.models.sod</strong> (<em>Subspace</em>) – </p></li>
<li><p><strong>Outlier Selection       'sos'                module-pyod.models.sos</strong> (<em>Stochastic</em>) – </p></li>
<li><p><strong>fraction</strong> (<em>float</em><em>, </em><em>default = 0.05</em>) – </p></li>
<li><p><strong>percentage / proportion of outliers in the dataset.</strong> (<em>The</em>) – </p></li>
<li><p><strong>verbose</strong> (<em>Boolean</em><em>, </em><em>default = True</em>) – </p></li>
<li><p><strong>update is not printed when verbose is set to False.</strong> (<em>Status</em>) – </p></li>
<li><p><strong>Returns</strong> – </p></li>
<li><p><strong>--------</strong> – </p></li>
<li><p><strong>model</strong> – </p></li>
<li><p><strong>------</strong> – </p></li>
<li><p><strong>Warnings</strong> – </p></li>
<li><p><strong>---------</strong> – </p></li>
<li><p><strong>None</strong> – </p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pycaret.anomaly.deploy_model">
<code class="sig-prename descclassname">pycaret.anomaly.</code><code class="sig-name descname">deploy_model</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">model</span></em>, <em class="sig-param"><span class="n">model_name</span></em>, <em class="sig-param"><span class="n">authentication</span></em>, <em class="sig-param"><span class="n">platform</span><span class="o">=</span><span class="default_value">'aws'</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.anomaly.deploy_model" title="Permalink to this definition">¶</a></dt>
<dd><p>(In Preview)</p>
<p>This function deploys the transformation pipeline and trained model object for
production use. The platform of deployment can be defined under the platform
param along with the applicable authentication tokens which are passed as a
dictionary to the authentication param.</p>
<blockquote>
<div><p>from pycaret.datasets import get_data
anomaly = get_data(‘anomaly’)
experiment_name = setup(data = anomaly, normalize=True)
knn = create_model(‘knn’)</p>
<dl class="simple">
<dt>deploy_model(model = knn, model_name = ‘deploy_knn’, platform = ‘aws’,</dt><dd><p>authentication = {‘bucket’ : ‘pycaret-test’})</p>
</dd>
</dl>
<p>This will deploy the model on an AWS S3 account under bucket ‘pycaret-test’</p>
<p>Before deploying a model to an AWS S3 (‘aws’), environment variables must be
configured using the command line interface. To configure AWS env. variables,
type aws configure in your python command line. The following information is
required which can be generated using the Identity and Access Management (IAM)
portal of your amazon console account:</p>
<blockquote>
<div><ul class="simple">
<li><p>AWS Access Key ID</p></li>
<li><p>AWS Secret Key Access</p></li>
<li><p>Default Region Name (can be seen under Global settings on your AWS console)</p></li>
<li><p>Default output format (must be left blank)</p></li>
</ul>
</div></blockquote>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>object</em>) – </p></li>
<li><p><strong>trained model object should be passed as an estimator.</strong> (<em>A</em>) – </p></li>
<li><p><strong>model_name</strong> (<em>string</em>) – </p></li>
<li><p><strong>of model to be passed as a string.</strong> (<em>Name</em>) – </p></li>
<li><p><strong>authentication</strong> (<em>dict</em>) – </p></li>
<li><p><strong>of applicable authentication tokens.</strong> (<em>dictionary</em>) – When platform = ‘aws’:
{‘bucket’ : ‘Name of Bucket on S3’}</p></li>
<li><p><strong>platform</strong> (<em>string</em><em>, </em><em>default = 'aws'</em>) – </p></li>
<li><p><strong>of platform for deployment. Current available options are</strong> (<em>Name</em>) – </p></li>
<li><p><strong>Returns</strong> – </p></li>
<li><p><strong>--------</strong> – </p></li>
<li><p><strong>Message</strong> (<em>Success</em>) – </p></li>
<li><p><strong>Warnings</strong> – </p></li>
<li><p><strong>---------</strong> – </p></li>
<li><p><strong>None</strong> – </p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pycaret.anomaly.get_outliers">
<code class="sig-prename descclassname">pycaret.anomaly.</code><code class="sig-name descname">get_outliers</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">model</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">fraction</span><span class="o">=</span><span class="default_value">0.05</span></em>, <em class="sig-param"><span class="n">ignore_features</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">normalize</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">transformation</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">pca</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">pca_components</span><span class="o">=</span><span class="default_value">0.99</span></em>, <em class="sig-param"><span class="n">ignore_low_variance</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">combine_rare_levels</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">rare_level_threshold</span><span class="o">=</span><span class="default_value">0.1</span></em>, <em class="sig-param"><span class="n">remove_multicollinearity</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">multicollinearity_threshold</span><span class="o">=</span><span class="default_value">0.9</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.anomaly.get_outliers" title="Permalink to this definition">¶</a></dt>
<dd><p>Magic function to get outliers in Power Query / Power BI.</p>
</dd></dl>

<dl class="py function">
<dt id="pycaret.anomaly.load_experiment">
<code class="sig-prename descclassname">pycaret.anomaly.</code><code class="sig-name descname">load_experiment</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">experiment_name</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.anomaly.load_experiment" title="Permalink to this definition">¶</a></dt>
<dd><p>This function loads a previously saved experiment from the current active
directory into current python environment. Load object must be a pickle file.</p>
<blockquote>
<div><p>saved_experiment = load_experiment(‘experiment_23122019’)</p>
<p>This will load the entire experiment pipeline into the object saved_experiment.
The experiment file must be in current directory.</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>experiment_name</strong> (<em>string</em><em>, </em><em>default = none</em>) – </p></li>
<li><p><strong>of pickle file to be passed as a string.</strong> (<em>Name</em>) – </p></li>
<li><p><strong>Returns</strong> – </p></li>
<li><p><strong>--------</strong> – </p></li>
<li><p><strong>Grid containing details of saved objects in experiment pipeline.</strong> (<em>Information</em>) – </p></li>
<li><p><strong>Warnings</strong> – </p></li>
<li><p><strong>---------</strong> – </p></li>
<li><p><strong>None</strong> – </p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pycaret.anomaly.load_model">
<code class="sig-prename descclassname">pycaret.anomaly.</code><code class="sig-name descname">load_model</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">model_name</span></em>, <em class="sig-param"><span class="n">platform</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">authentication</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.anomaly.load_model" title="Permalink to this definition">¶</a></dt>
<dd><p>This function loads a previously saved transformation pipeline and model
from the current active directory into the current python environment.
Load object must be a pickle file.</p>
<blockquote>
<div><p>saved_knn = load_model(‘knn_model_23122019’)</p>
<p>This will load the previously saved model in saved_lr variable. The file
must be in the current directory.</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_name</strong> (<em>string</em><em>, </em><em>default = none</em>) – </p></li>
<li><p><strong>of pickle file to be passed as a string.</strong> (<em>Name</em>) – </p></li>
<li><p><strong>Returns</strong> – </p></li>
<li><p><strong>--------</strong> – </p></li>
<li><p><strong>Message</strong> (<em>Success</em>) – </p></li>
<li><p><strong>Warnings</strong> – </p></li>
<li><p><strong>---------</strong> – </p></li>
<li><p><strong>None</strong> – </p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pycaret.anomaly.plot_model">
<code class="sig-prename descclassname">pycaret.anomaly.</code><code class="sig-name descname">plot_model</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">model</span></em>, <em class="sig-param"><span class="n">plot</span><span class="o">=</span><span class="default_value">'tsne'</span></em>, <em class="sig-param"><span class="n">feature</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.anomaly.plot_model" title="Permalink to this definition">¶</a></dt>
<dd><p>This function takes a trained model object and returns a plot on the dataset
passed during setup stage. This function internally calls assign_model before
generating a plot.</p>
<blockquote>
<div><p>from pycaret.datasets import get_data
anomaly = get_data(‘anomaly’)
experiment_name = setup(data = anomaly, normalize = True)
knn = create_model(‘knn’)</p>
<p>plot_model(knn)</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>object</em>) – </p></li>
<li><p><strong>trained model object can be passed. Model must be created using create_model</strong><strong>(</strong><strong>)</strong><strong></strong> (<em>A</em>) – </p></li>
<li><p><strong>plot</strong> (<em>string</em><em>, </em><em>default = 'tsne'</em>) – </p></li>
<li><p><strong>abbreviation of type of plot. The current list of plots supported are</strong> (<em>Enter</em>) – </p></li>
<li><p><strong>Abbreviated String</strong> (<em>Name</em>) – </p></li>
<li><p><strong>------------------</strong> (<em>---------</em>) – </p></li>
<li><p><strong>(</strong><strong>3d</strong><strong>) </strong><strong>Dimension Plot      'tsne'</strong> (<em>t-SNE</em>) – </p></li>
<li><p><strong>Dimensionality Plot       'umap'</strong> (<em>UMAP</em>) – </p></li>
<li><p><strong>feature</strong> (<em>string</em><em>, </em><em>default = None</em>) – </p></li>
<li><p><strong>column is used as a hoverover tooltip. By default</strong><strong>, </strong><strong>first of column of the</strong> (<em>feature</em>) – </p></li>
<li><p><strong>is chosen as hoverover tooltip</strong><strong>, </strong><strong>when no feature is passed.</strong> (<em>dataset</em>) – </p></li>
<li><p><strong>Returns</strong> – </p></li>
<li><p><strong>--------</strong> – </p></li>
<li><p><strong>Plot</strong> (<em>Visual</em>) – </p></li>
<li><p><strong>------------</strong> – </p></li>
<li><p><strong>Warnings</strong> – </p></li>
<li><p><strong>---------</strong> – </p></li>
<li><p><strong>None</strong> (<em>-</em>) – </p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pycaret.anomaly.predict_model">
<code class="sig-prename descclassname">pycaret.anomaly.</code><code class="sig-name descname">predict_model</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">model</span></em>, <em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">platform</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">authentication</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.anomaly.predict_model" title="Permalink to this definition">¶</a></dt>
<dd><p>This function is used to predict new data using a trained model. It requires a
trained model object created using one of the function in pycaret that returns
a trained model object. New data must be passed to data param as pandas Dataframe.</p>
<blockquote>
<div><p>from pycaret.datasets import get_data
anomaly = get_data(‘anomaly’)
experiment_name = setup(data = anomaly)
knn = create_model(‘knn’)</p>
<p>knn_predictions = predict_model(model = knn, data = anomaly)</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>object / string</em><em>,  </em><em>default = None</em>) – </p></li>
<li><p><strong>model is passed as string</strong><strong>, </strong><strong>load_model</strong><strong>(</strong><strong>) </strong><strong>is called internally to load the</strong> (<em>When</em>) – </p></li>
<li><p><strong>file from active directory</strong><strong> or </strong><strong>cloud platform when platform param is passed.</strong> (<em>pickle</em>) – </p></li>
<li><p><strong>data</strong> (<em>{array-like</em><em>, </em><em>sparse matrix}</em><em>, </em><em>shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>) </em><em>where n_samples</em>) – </p></li>
<li><p><strong>the number of samples and n_features is the number of features. All features</strong> (<em>is</em>) – </p></li>
<li><p><strong>during training must be present in the new dataset.</strong> (<em>used</em>) – </p></li>
<li><p><strong>Returns</strong> – </p></li>
<li><p><strong>--------</strong> – </p></li>
<li><p><strong>grid</strong> (<em>info</em>) – </p></li>
<li><p><strong>----------</strong> – </p></li>
<li><p><strong>Warnings</strong> – </p></li>
<li><p><strong>---------</strong> – </p></li>
<li><p><strong>Models that donot support 'predict' function cannot be used in predict_model</strong><strong>(</strong><strong>)</strong><strong></strong> (<em>-</em>) – </p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pycaret.anomaly.save_experiment">
<code class="sig-prename descclassname">pycaret.anomaly.</code><code class="sig-name descname">save_experiment</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">experiment_name</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.anomaly.save_experiment" title="Permalink to this definition">¶</a></dt>
<dd><p>This function saves the entire experiment into the current active directory.
All outputs using pycaret are internally saved into a binary list which is
pickilized when save_experiment() is used.</p>
<blockquote>
<div><p>save_experiment()</p>
<p>This will save the entire experiment into the current active directory. By
default, the name of the experiment will use the session_id generated during
setup(). To use a custom name, a string must be passed to the experiment_name
param. For example:</p>
<p>save_experiment(‘experiment_23122019’)</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>experiment_name</strong> (<em>string</em><em>, </em><em>default = none</em>) – </p></li>
<li><p><strong>of pickle file to be passed as a string.</strong> (<em>Name</em>) – </p></li>
<li><p><strong>Returns</strong> – </p></li>
<li><p><strong>--------</strong> – </p></li>
<li><p><strong>Message</strong> (<em>Success</em>) – </p></li>
<li><p><strong>Warnings</strong> – </p></li>
<li><p><strong>---------</strong> – </p></li>
<li><p><strong>None</strong> – </p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pycaret.anomaly.save_model">
<code class="sig-prename descclassname">pycaret.anomaly.</code><code class="sig-name descname">save_model</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">model</span></em>, <em class="sig-param"><span class="n">model_name</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.anomaly.save_model" title="Permalink to this definition">¶</a></dt>
<dd><p>This function saves the transformation pipeline and trained model object
into the current active directory as a pickle file for later use.</p>
<blockquote>
<div><p>from pycaret.datasets import get_data
anomaly = get_data(‘anomaly’)
experiment_name = setup(data = anomaly, normalize = True)
knn = create_model(‘knn’)</p>
<p>save_model(knn, ‘knn_model_23122019’)</p>
<p>This will save the transformation pipeline and model as a binary pickle
file in the current directory.</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>object</em><em>, </em><em>default = none</em>) – </p></li>
<li><p><strong>trained model object should be passed.</strong> (<em>A</em>) – </p></li>
<li><p><strong>model_name</strong> (<em>string</em><em>, </em><em>default = none</em>) – </p></li>
<li><p><strong>of pickle file to be passed as a string.</strong> (<em>Name</em>) – </p></li>
<li><p><strong>Returns</strong> – </p></li>
<li><p><strong>--------</strong> – </p></li>
<li><p><strong>Message</strong> (<em>Success</em>) – </p></li>
<li><p><strong>Warnings</strong> – </p></li>
<li><p><strong>---------</strong> – </p></li>
<li><p><strong>None</strong> – </p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pycaret.anomaly.setup">
<code class="sig-prename descclassname">pycaret.anomaly.</code><code class="sig-name descname">setup</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">categorical_features</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">categorical_imputation</span><span class="o">=</span><span class="default_value">'constant'</span></em>, <em class="sig-param"><span class="n">ordinal_features</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">high_cardinality_features</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">numeric_features</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">numeric_imputation</span><span class="o">=</span><span class="default_value">'mean'</span></em>, <em class="sig-param"><span class="n">date_features</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">ignore_features</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">normalize</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">normalize_method</span><span class="o">=</span><span class="default_value">'zscore'</span></em>, <em class="sig-param"><span class="n">transformation</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">transformation_method</span><span class="o">=</span><span class="default_value">'yeo-johnson'</span></em>, <em class="sig-param"><span class="n">handle_unknown_categorical</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">unknown_categorical_method</span><span class="o">=</span><span class="default_value">'least_frequent'</span></em>, <em class="sig-param"><span class="n">pca</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">pca_method</span><span class="o">=</span><span class="default_value">'linear'</span></em>, <em class="sig-param"><span class="n">pca_components</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">ignore_low_variance</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">combine_rare_levels</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">rare_level_threshold</span><span class="o">=</span><span class="default_value">0.1</span></em>, <em class="sig-param"><span class="n">bin_numeric_features</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">remove_multicollinearity</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">multicollinearity_threshold</span><span class="o">=</span><span class="default_value">0.9</span></em>, <em class="sig-param"><span class="n">group_features</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">group_names</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">supervised</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">supervised_target</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">session_id</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">profile</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.anomaly.setup" title="Permalink to this definition">¶</a></dt>
<dd><p>This function initializes the environment in pycaret. setup() must called before
executing any other function in pycaret. It takes one mandatory parameter:
dataframe {array-like, sparse matrix}.</p>
<blockquote>
<div><p>from pycaret.datasets import get_data
anomaly = get_data(‘anomaly’)</p>
<p>experiment_name = setup(data = anomaly, normalize = True)</p>
<p>‘anomaly’ is a pandas Dataframe.</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<em>{array-like</em><em>, </em><em>sparse matrix}</em><em>, </em><em>shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>) </em><em>where n_samples</em>) – </p></li>
<li><p><strong>the number of samples and n_features is the number of features in dataframe.</strong> (<em>is</em>) – </p></li>
<li><p><strong>categorical_features</strong> (<em>string</em><em>, </em><em>default = None</em>) – </p></li>
<li><p><strong>the inferred data types are not correct</strong><strong>, </strong><strong>categorical_features can be used to</strong> (<em>If</em>) – </p></li>
<li><p><strong>the inferred type. If when running setup the type of 'column1' is</strong> (<em>overwrite</em>) – </p></li>
<li><p><strong>as numeric instead of categorical</strong><strong>, </strong><strong>then this parameter can be used</strong> (<em>inferred</em>) – </p></li>
<li><p><strong>overwrite the type by passing categorical_features =</strong><strong> [</strong><strong>'column1'</strong><strong>]</strong><strong></strong> (<em>to</em>) – </p></li>
<li><p><strong>categorical_imputation</strong> (<em>string</em><em>, </em><em>default = 'constant'</em>) – </p></li>
<li><p><strong>missing values are found in categorical features</strong><strong>, </strong><strong>they will be imputed with</strong> (<em>If</em>) – </p></li>
<li><p><strong>constant 'not_available' value. The other available option is 'mode' which</strong> (<em>a</em>) – </p></li>
<li><p><strong>the missing value using most frequent value in the training dataset.</strong> (<em>imputes</em>) – </p></li>
<li><p><strong>ordinal_features</strong> (<em>dictionary</em><em>, </em><em>default = None</em>) – </p></li>
<li><p><strong>the data contains ordinal features</strong><strong>, </strong><strong>they must be encoded differently using</strong> (<em>When</em>) – </p></li>
<li><p><strong>ordinal_features param. If the data has a categorical variable with values</strong> (<em>the</em>) – </p></li>
<li><p><strong>'low'</strong><strong>, </strong><strong>'medium'</strong><strong>, </strong><strong>'high' and it is known that low &lt; medium &lt; high</strong><strong>, </strong><strong>then it can</strong> (<em>of</em>) – </p></li>
<li><p><strong>passed as ordinal_features = { 'column_name'</strong> (<em>be</em>) – </p></li>
<li><p><strong>list sequence must be in increasing order from lowest to highest.</strong> (<em>The</em>) – </p></li>
<li><p><strong>high_cardinality_features</strong> (<em>string</em><em>, </em><em>default = None</em>) – </p></li>
<li><p><strong>the data containts features with high cardinality</strong><strong>, </strong><strong>they can be compressed</strong> (<em>When</em>) – </p></li>
<li><p><strong>fewer levels by passing them as a list of column names with high cardinality.</strong> (<em>into</em>) – </p></li>
<li><p><strong>are compressed using frequency distribution. As such original features</strong> (<em>Features</em>) – </p></li>
<li><p><strong>replaced with the frequency distribution and converted into numeric variable.</strong> (<em>are</em>) – </p></li>
<li><p><strong>numeric_features</strong> (<em>string</em><em>, </em><em>default = None</em>) – </p></li>
<li><p><strong>the inferred data types are not correct</strong><strong>, </strong><strong>numeric_features can be used to</strong> (<em>If</em>) – </p></li>
<li><p><strong>the inferred type. If when running setup the type of 'column1' is</strong> – </p></li>
<li><p><strong>as a categorical instead of numeric</strong><strong>, </strong><strong>then this parameter can be used</strong> (<em>inferred</em>) – </p></li>
<li><p><strong>overwrite by passing numeric_features =</strong><strong> [</strong><strong>'column1'</strong><strong>]</strong><strong></strong> (<em>to</em>) – </p></li>
<li><p><strong>numeric_imputation</strong> (<em>string</em><em>, </em><em>default = 'mean'</em>) – </p></li>
<li><p><strong>missing values are found in numeric features</strong><strong>, </strong><strong>they will be imputed with the</strong> (<em>If</em>) – </p></li>
<li><p><strong>value of the feature. The other available option is 'median' which imputes</strong> (<em>mean</em>) – </p></li>
<li><p><strong>value using the median value in the training dataset.</strong> (<em>the</em>) – </p></li>
<li><p><strong>date_features</strong> (<em>string</em><em>, </em><em>default = None</em>) – </p></li>
<li><p><strong>the data has a DateTime column that is not automatically detected when running</strong> (<em>If</em>) – </p></li>
<li><p><strong>this parameter can be used by passing date_features = 'date_column_name'.</strong> (<em>setup</em><em>,</em>) – </p></li>
<li><p><strong>can work with multiple date columns. Date columns are not used in modeling.</strong> (<em>It</em>) – </p></li>
<li><p><strong>feature extraction is performed and date columns are dropped from the</strong> (<em>Instead</em><em>,</em>) – </p></li>
<li><p><strong>If the date column includes a time stamp</strong><strong>, </strong><strong>features related to time will</strong> (<em>dataset.</em>) – </p></li>
<li><p><strong>be extracted.</strong> (<em>also</em>) – </p></li>
<li><p><strong>ignore_features</strong> (<em>string</em><em>, </em><em>default = None</em>) – </p></li>
<li><p><strong>any feature should be ignored for modeling</strong><strong>, </strong><strong>it can be passed to the param</strong> (<em>If</em>) – </p></li>
<li><p><strong>The ID and DateTime columns when inferred</strong><strong>, </strong><strong>are automatically</strong> (<em>ignore_features.</em>) – </p></li>
<li><p><strong>to ignore for modeling.</strong> (<em>set</em>) – </p></li>
<li><p><strong>normalize</strong> (<em>bool</em><em>, </em><em>default = False</em>) – </p></li>
<li><p><strong>set to True</strong><strong>, </strong><strong>the feature space is transformed using the normalized_method</strong> (<em>When</em>) – </p></li>
<li><p><strong>Generally</strong><strong>, </strong><strong>linear algorithms perform better with normalized data however</strong><strong>,</strong> (<em>param.</em>) – </p></li>
<li><p><strong>results may vary and it is advised to run multiple experiments to evaluate</strong> (<em>the</em>) – </p></li>
<li><p><strong>benefit of normalization.</strong> (<em>the</em>) – </p></li>
<li><p><strong>normalize_method</strong> (<em>string</em><em>, </em><em>default = 'zscore'</em>) – </p></li>
<li><p><strong>the method to be used for normalization. By default</strong><strong>, </strong><strong>normalize method</strong> (<em>Defines</em>) – </p></li>
<li><p><strong>set to 'zscore'. The standard zscore is calculated as z =</strong><strong> (</strong><strong>x - u</strong><strong>) </strong><strong>/ s. The</strong> (<em>is</em>) – </p></li>
<li><p><strong>available options are</strong> (<em>other</em>) – </p></li>
<li><p><strong>'minmax'</strong> (<em>scales and translates each feature individually such that it is in</em>) – the range of 0 - 1.</p></li>
<li><p><strong>'maxabs'</strong> (<em>scales and translates each feature individually such that the maximal</em>) – absolute value of each feature will be 1.0. It does not shift/center
the data, and thus does not destroy any sparsity.</p></li>
<li><p><strong>'robust'</strong> (<em>scales and translates each feature according to the Interquartile range.</em>) – When the dataset contains outliers, robust scaler often gives better
results.</p></li>
<li><p><strong>transformation</strong> (<em>bool</em><em>, </em><em>default = False</em>) – </p></li>
<li><p><strong>set to True</strong><strong>, </strong><strong>a power transformation is applied to make the data more normal /</strong> (<em>When</em>) – </p></li>
<li><p><strong>This is useful for modeling issues related to heteroscedasticity or</strong> (<em>Gaussian-like.</em>) – </p></li>
<li><p><strong>situations where normality is desired. The optimal parameter for stabilizing</strong> (<em>other</em>) – </p></li>
<li><p><strong>and minimizing skewness is estimated through maximum likelihood.</strong> (<em>variance</em>) – </p></li>
<li><p><strong>transformation_method</strong> (<em>string</em><em>, </em><em>default = 'yeo-johnson'</em>) – </p></li>
<li><p><strong>the method for transformation. By default</strong><strong>, </strong><strong>the transformation method is set</strong> (<em>Defines</em>) – </p></li>
<li><p><strong>'yeo-johnson'. The other available option is 'quantile' transformation. Both</strong> (<em>to</em>) – </p></li>
<li><p><strong>transformation transforms the feature set to follow a Gaussian-like</strong><strong> or </strong><strong>normal</strong> (<em>the</em>) – </p></li>
<li><p><strong>Note that the quantile transformer is non-linear and may distort linear</strong> (<em>distribution.</em>) – </p></li>
<li><p><strong>between variables measured at the same scale.</strong> (<em>correlations</em>) – </p></li>
<li><p><strong>handle_unknown_categorical</strong> (<em>bool</em><em>, </em><em>default = True</em>) – </p></li>
<li><p><strong>set to True</strong><strong>, </strong><strong>unknown categorical levels in new / unseen data are replaced by</strong> (<em>When</em>) – </p></li>
<li><p><strong>most</strong><strong> or </strong><strong>least frequent level as learned in the training data. The method is</strong> (<em>the</em>) – </p></li>
<li><p><strong>under the unknown_categorical_method param.</strong> (<em>defined</em>) – </p></li>
<li><p><strong>unknown_categorical_method</strong> (<em>string</em><em>, </em><em>default = 'least_frequent'</em>) – </p></li>
<li><p><strong>used to replace unknown categorical levels in unseen data. Method can be</strong> (<em>Method</em>) – </p></li>
<li><p><strong>to 'least_frequent'</strong><strong> or </strong><strong>'most_frequent'.</strong> (<em>set</em>) – </p></li>
<li><p><strong>pca</strong> (<em>bool</em><em>, </em><em>default = False</em>) – </p></li>
<li><p><strong>set to True</strong><strong>, </strong><strong>dimensionality reduction is applied to project the data into</strong> (<em>When</em>) – </p></li>
<li><p><strong>lower dimensional space using the method defined in pca_method param. In</strong> (<em>a</em>) – </p></li>
<li><p><strong>learning pca is generally performed when dealing with high feature</strong> (<em>supervised</em>) – </p></li>
<li><p><strong>and memory is a constraint. Note that not all datasets can be decomposed</strong> (<em>space</em>) – </p></li>
<li><p><strong>using a linear PCA technique and that applying PCA may result in loss</strong> (<em>efficiently</em>) – </p></li>
<li><p><strong>information. As such</strong><strong>, </strong><strong>it is advised to run multiple experiments with different</strong> (<em>of</em>) – </p></li>
<li><p><strong>to evaluate the impact.</strong> (<em>pca_methods</em>) – </p></li>
<li><p><strong>pca_method</strong> (<em>string</em><em>, </em><em>default = 'linear'</em>) – </p></li>
<li><p><strong>'linear' method performs Linear dimensionality reduction using Singular Value</strong> (<em>The</em>) – </p></li>
<li><p><strong>The other available options are</strong> (<em>Decomposition.</em>) – </p></li>
<li><p><strong>kernel</strong> (<em>dimensionality reduction through the use of RVF kernel.</em>) – </p></li>
<li><p><strong>incremental</strong> (<em>replacement for 'linear' pca when the dataset to be decomposed is</em>) – too large to fit in memory</p></li>
<li><p><strong>pca_components</strong> (<em>int/float</em><em>, </em><em>default = 0.99</em>) – </p></li>
<li><p><strong>of components to keep. if pca_components is a float</strong><strong>, </strong><strong>it is treated as a</strong> (<em>Number</em>) – </p></li>
<li><p><strong>percentage for information retention. When pca_components is an integer</strong> (<em>target</em>) – </p></li>
<li><p><strong>is treated as the number of features to be kept. pca_components must be strictly</strong> (<em>it</em>) – </p></li>
<li><p><strong>than the original number of features in the dataset.</strong> (<em>less</em>) – </p></li>
<li><p><strong>ignore_low_variance</strong> (<em>bool</em><em>, </em><em>default = False</em>) – </p></li>
<li><p><strong>set to True</strong><strong>, </strong><strong>all categorical features with statistically insignificant variances</strong> (<em>When</em>) – </p></li>
<li><p><strong>removed from the dataset. The variance is calculated using the ratio of unique</strong> (<em>are</em>) – </p></li>
<li><p><strong>to the number of samples</strong><strong>, </strong><strong>and the ratio of the most common value to the</strong> (<em>values</em>) – </p></li>
<li><p><strong>of the second most common value.</strong> (<em>frequency</em>) – </p></li>
<li><p><strong>combine_rare_levels</strong> (<em>bool</em><em>, </em><em>default = False</em>) – </p></li>
<li><p><strong>set to True</strong><strong>, </strong><strong>all levels in categorical features below the threshold defined</strong> (<em>When</em>) – </p></li>
<li><p><strong>rare_level_threshold param are combined together as a single level. There must be</strong> (<em>in</em>) – </p></li>
<li><p><strong>two levels under the threshold for this to take effect. rare_level_threshold</strong> (<em>atleast</em>) – </p></li>
<li><p><strong>the percentile distribution of level frequency. Generally</strong><strong>, </strong><strong>this technique</strong> (<em>represents</em>) – </p></li>
<li><p><strong>applied to limit a sparse matrix caused by high numbers of levels in categorical</strong> (<em>is</em>) – </p></li>
<li><p><strong>features.</strong> – </p></li>
<li><p><strong>rare_level_threshold</strong> (<em>float</em><em>, </em><em>default = 0.1</em>) – </p></li>
<li><p><strong>distribution below which rare categories are combined. Only comes into</strong> (<em>Percentile</em>) – </p></li>
<li><p><strong>when combine_rare_levels is set to True.</strong> (<em>effect</em>) – </p></li>
<li><p><strong>bin_numeric_features</strong> (<em>list</em><em>, </em><em>default = None</em>) – </p></li>
<li><p><strong>a list of numeric features is passed they are transformed into categorical</strong> (<em>When</em>) – </p></li>
<li><p><strong>using KMeans</strong><strong>, </strong><strong>where values in each bin have the same nearest center of a</strong> (<em>features</em>) – </p></li>
<li><p><strong>k-means cluster. The number of clusters are determined based on the 'sturges'</strong> (<em>1D</em>) – </p></li>
<li><p><strong>It is only optimal for gaussian data and underestimates the number of bins</strong> (<em>method.</em>) – </p></li>
<li><p><strong>large non-gaussian datasets.</strong> (<em>for</em>) – </p></li>
<li><p><strong>remove_multicollinearity</strong> (<em>bool</em><em>, </em><em>default = False</em>) – </p></li>
<li><p><strong>set to True</strong><strong>, </strong><strong>the variables with inter-correlations higher than the threshold</strong> (<em>When</em>) – </p></li>
<li><p><strong>under the multicollinearity_threshold param are dropped. When two features</strong> (<em>defined</em>) – </p></li>
<li><p><strong>highly correlated with each other</strong><strong>, </strong><strong>the feature with higher average correlation</strong> (<em>are</em>) – </p></li>
<li><p><strong>the feature space is dropped.</strong> (<em>in</em>) – </p></li>
<li><p><strong>multicollinearity_threshold</strong> (<em>float</em><em>, </em><em>default = 0.9</em>) – </p></li>
<li><p><strong>used for dropping the correlated features. Only comes into effect when</strong> (<em>Threshold</em>) – </p></li>
<li><p><strong>is set to True.</strong> (<em>remove_multicollinearity</em>) – </p></li>
<li><p><strong>group_features</strong> (<em>list</em><em> or </em><em>list of list</em><em>, </em><em>default = None</em>) – </p></li>
<li><p><strong>a dataset contains features that have related characteristics</strong><strong>, </strong><strong>the group_features</strong> (<em>When</em>) – </p></li>
<li><p><strong>can be used for statistical feature extraction. For example</strong><strong>, </strong><strong>if a dataset has</strong> (<em>param</em>) – </p></li>
<li><p><strong>features that are related with each other</strong><strong> (</strong><strong>i.e 'Col1'</strong><strong>, </strong><strong>'Col2'</strong><strong>, </strong><strong>'Col3'</strong><strong>)</strong><strong>, </strong><strong>a list</strong> (<em>numeric</em>) – </p></li>
<li><p><strong>the column names can be passed under group_features to extract statistical</strong> (<em>containing</em>) – </p></li>
<li><p><strong>such as the mean</strong><strong>, </strong><strong>median</strong><strong>, </strong><strong>mode and standard deviation.</strong> (<em>information</em>) – </p></li>
<li><p><strong>group_names</strong> (<em>list</em><em>, </em><em>default = None</em>) – </p></li>
<li><p><strong>group_features is passed</strong><strong>, </strong><strong>a name of the group can be passed into the group_names</strong> (<em>When</em>) – </p></li>
<li><p><strong>as a list containing strings. The length of a group_names list must equal to the</strong> (<em>param</em>) – </p></li>
<li><p><strong>of group_features. When the length doesn't match</strong><strong> or </strong><strong>the name is not passed</strong><strong>, </strong><strong>new</strong> (<em>length</em>) – </p></li>
<li><p><strong>are sequentially named such as group_1</strong><strong>, </strong><strong>group_2 etc.</strong> (<em>features</em>) – </p></li>
<li><p><strong>supervised</strong> (<em>bool</em><em>, </em><em>default = False</em>) – </p></li>
<li><p><strong>set to True</strong><strong>, </strong><strong>supervised_target column is ignored for transformation. This</strong> (<em>When</em>) – </p></li>
<li><p><strong>is only for internal use.</strong> (<em>param</em>) – </p></li>
<li><p><strong>supervised_target</strong> (<em>string</em><em>, </em><em>default = None</em>) – </p></li>
<li><p><strong>of supervised_target column that will be ignored for transformation. Only</strong> (<em>Name</em>) – </p></li>
<li><p><strong>when tune_model</strong><strong>(</strong><strong>) </strong><strong>function is used. This param is only for internal use.</strong> (<em>applciable</em>) – </p></li>
<li><p><strong>session_id</strong> (<em>int</em><em>, </em><em>default = None</em>) – </p></li>
<li><p><strong>None</strong><strong>, </strong><strong>a random seed is generated and returned in the Information grid. The</strong> (<em>If</em>) – </p></li>
<li><p><strong>number is then distributed as a seed in all functions used during the</strong> (<em>unique</em>) – </p></li>
<li><p><strong>This can be used for later reproducibility of the entire experiment.</strong> (<em>experiment.</em>) – </p></li>
<li><p><strong>profile</strong> (<em>bool</em><em>, </em><em>default = False</em>) – </p></li>
<li><p><strong>set to true</strong><strong>, </strong><strong>a data profile for Exploratory Data Analysis will be displayed</strong> (<em>If</em>) – </p></li>
<li><p><strong>an interactive HTML report.</strong> (<em>in</em>) – </p></li>
<li><p><strong>verbose</strong> (<em>Boolean</em><em>, </em><em>default = True</em>) – </p></li>
<li><p><strong>grid is not printed when verbose is set to False.</strong> (<em>Information</em>) – </p></li>
<li><p><strong>Returns</strong> – </p></li>
<li><p><strong>--------</strong> – </p></li>
<li><p><strong>grid</strong> (<em>info</em>) – </p></li>
<li><p><strong>-----------</strong> – </p></li>
<li><p><strong>environment</strong> (<em>This function returns various outputs that are stored in variable</em>) – </p></li>
<li><p><strong>as tuple. They are used by other functions in pycaret.</strong> (<em>-----------</em>) – </p></li>
<li><p><strong>Warnings</strong> – </p></li>
<li><p><strong>---------</strong> – </p></li>
<li><p><strong>None</strong> – </p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pycaret.anomaly.tune_model">
<code class="sig-prename descclassname">pycaret.anomaly.</code><code class="sig-name descname">tune_model</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">model</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">supervised_target</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">method</span><span class="o">=</span><span class="default_value">'drop'</span></em>, <em class="sig-param"><span class="n">estimator</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">optimize</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">fold</span><span class="o">=</span><span class="default_value">10</span></em><span class="sig-paren">)</span><a class="headerlink" href="#pycaret.anomaly.tune_model" title="Permalink to this definition">¶</a></dt>
<dd><p>This function tunes the fraction parameter using a predefined grid with
the objective of optimizing a supervised learning metric as defined in
the optimize param. You can choose the supervised estimator from a large
library available in pycaret. By default, supervised estimator is Linear.</p>
<p>This function returns the tuned model object.</p>
<blockquote>
<div><p>from pycaret.datasets import get_data
boston = get_data(‘boston’)
experiment_name = setup(data = boston, normalize = True)</p>
<p>tuned_knn = tune_model(model = ‘knn’, supervised_target = ‘medv’)</p>
<p>This will return tuned k-Nearest Neighbors model.</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>trained model object with best fraction param.</em>) – </p></li>
<li><p><strong>abbreviated name of the model. List of available models supported</strong> (<em>Enter</em>) – </p></li>
<li><p><strong>Abbreviated String   Original Implementation</strong> (<em>Model</em>) – </p></li>
<li><p><strong>------------------   -----------------------</strong> (<em>---------</em>) – </p></li>
<li><p><strong>Outlier Detection       'abod'               pyod.models.abod.ABOD</strong> (<em>Angle-base</em>) – </p></li>
<li><p><strong>Forest                   'iforest'            module-pyod.models.iforest</strong> (<em>Isolation</em>) – </p></li>
<li><p><strong>Local Outlier     'cluster'            pyod.models.cblof</strong> (<em>Clustering-Based</em>) – </p></li>
<li><p><strong>Outlier Factor  'cof'                module-pyod.models.cof</strong> (<em>Connectivity-Based</em>) – </p></li>
<li><p><strong>Outlier Detection  'histogram'          module-pyod.models.hbos</strong> (<em>Histogram-based</em>) – </p></li>
<li><p><strong>Neighbors Detector       'knn'                module-pyod.models.knn</strong> (<em>k-Nearest</em>) – </p></li>
<li><p><strong>Outlier Factor               'lof'                module-pyod.models.lof</strong> (<em>Local</em>) – </p></li>
<li><p><strong>SVM detector             'svm'                module-pyod.models.ocsvm</strong> (<em>One-class</em>) – </p></li>
<li><p><strong>Component Analysis       'pca'                module-pyod.models.pca</strong> (<em>Principal</em>) – </p></li>
<li><p><strong>Covariance Determinant     'mcd'                module-pyod.models.mcd</strong> (<em>Minimum</em>) – </p></li>
<li><p><strong>Outlier Detection         'sod'                module-pyod.models.sod</strong> (<em>Subspace</em>) – </p></li>
<li><p><strong>Outlier Selection       'sos'                module-pyod.models.sos</strong> (<em>Stochastic</em>) – </p></li>
<li><p><strong>supervised_target</strong> (<em>string</em>) – </p></li>
<li><p><strong>of the target column for supervised learning.</strong> (<em>Name</em>) – </p></li>
<li><p><strong>method</strong> (<em>string</em><em>, </em><em>default = 'drop'</em>) – </p></li>
<li><p><strong>method set to drop</strong><strong>, </strong><strong>it will drop the outlier rows from training dataset</strong> (<em>When</em>) – </p></li>
<li><p><strong>supervised estimator</strong><strong>, </strong><strong>when method set to 'surrogate'</strong><strong>, </strong><strong>it will use the</strong> (<em>of</em>) – </p></li>
<li><p><strong>function and label as a feature without dropping the outliers from</strong> (<em>decision</em>) – </p></li>
<li><p><strong>dataset.</strong> (<em>training</em>) – </p></li>
<li><p><strong>estimator</strong> (<em>string</em><em>, </em><em>default = None</em>) – </p></li>
<li><p><strong>Abbreviated String     Task</strong> (<em>Estimator</em>) – </p></li>
<li><p><strong>------------------     ---------------</strong> (<em>---------</em>) – </p></li>
<li><p><strong>Regression           'lr'                   Classification</strong> (<em>Logistic</em>) – </p></li>
<li><p><strong>Nearest Neighbour           'knn'                  Classification</strong> (<em>K</em>) – </p></li>
<li><p><strong>Bayes                  'nb'                   Classification</strong> (<em>Naives</em>) – </p></li>
<li><p><strong>Tree                 'dt'                   Classification</strong> (<em>Decision</em>) – </p></li>
<li><p><strong>(</strong><strong>Linear</strong><strong>)                  </strong><strong>'svm'                  Classification</strong> (<em>SVM</em>) – </p></li>
<li><p><strong>(</strong><strong>RBF</strong><strong>)                     </strong><strong>'rbfsvm'               Classification</strong> (<em>SVM</em>) – </p></li>
<li><p><strong>Process              'gpc'                  Classification</strong> (<em>Gaussian</em>) – </p></li>
<li><p><strong>Level Perceptron        'mlp'                  Classification</strong> (<em>Multi</em>) – </p></li>
<li><p><strong>Classifier              'ridge'                Classification</strong> (<em>Ridge</em>) – </p></li>
<li><p><strong>Forest                 'rf'                   Classification</strong> (<em>Random</em>) – </p></li>
<li><p><strong>Disc. Analysis      'qda'                  Classification</strong> (<em>Quadratic</em>) – </p></li>
<li><p><strong>'ada'                  Classification</strong> (<em>AdaBoost</em>) – </p></li>
<li><p><strong>Boosting             'gbc'                  Classification</strong> (<em>Gradient</em>) – </p></li>
<li><p><strong>Disc. Analysis         'lda'                  Classification</strong> (<em>Linear</em>) – </p></li>
<li><p><strong>Trees Classifier        'et'                   Classification</strong> (<em>Extra</em>) – </p></li>
<li><p><strong>Gradient Boosting     'xgboost'              Classification</strong> (<em>Extreme</em>) – </p></li>
<li><p><strong>Gradient Boosting       'lightgbm'             Classification</strong> (<em>Light</em>) – </p></li>
<li><p><strong>Classifier           'catboost'             Classification</strong> (<em>CatBoost</em>) – </p></li>
<li><p><strong>Regression             'lr'                   Regression</strong> (<em>Linear</em>) – </p></li>
<li><p><strong>Regression              'lasso'                Regression</strong> (<em>Lasso</em>) – </p></li>
<li><p><strong>Regression              'ridge'                Regression</strong> (<em>Ridge</em>) – </p></li>
<li><p><strong>Net                   'en'                   Regression</strong> (<em>Elastic</em>) – </p></li>
<li><p><strong>Angle Regression        'lar'                  Regression</strong> (<em>Least</em>) – </p></li>
<li><p><strong>Least Angle Regression  'llar'                 Regression</strong> (<em>Lasso</em>) – </p></li>
<li><p><strong>Matching Pursuit   'omp'                  Regression</strong> (<em>Orthogonal</em>) – </p></li>
<li><p><strong>Ridge                'br'                   Regression</strong> (<em>Bayesian</em>) – </p></li>
<li><p><strong>Relevance Determ.   'ard'                  Regression</strong> (<em>Automatic</em>) – </p></li>
<li><p><strong>Aggressive Regressor  'par'                  Regression</strong> (<em>Passive</em>) – </p></li>
<li><p><strong>Sample Consensus       'ransac'               Regression</strong> (<em>Random</em>) – </p></li>
<li><p><strong>Regressor            'tr'                   Regression</strong> (<em>TheilSen</em>) – </p></li>
<li><p><strong>Regressor               'huber'                Regression</strong> (<em>Huber</em>) – </p></li>
<li><p><strong>Ridge                  'kr'                   Regression</strong> (<em>Kernel</em>) – </p></li>
<li><p><strong>Vector Machine        'svm'                  Regression</strong> (<em>Support</em>) – </p></li>
<li><p><strong>Neighbors Regressor         'knn'                  Regression</strong> (<em>K</em>) – </p></li>
<li><p><strong>Tree                 'dt'                   Regression</strong> (<em>Decision</em>) – </p></li>
<li><p><strong>Forest                 'rf'                   Regression</strong> (<em>Random</em>) – </p></li>
<li><p><strong>Trees Regressor         'et'                   Regression</strong> (<em>Extra</em>) – </p></li>
<li><p><strong>Regressor            'ada'                  Regression</strong> (<em>AdaBoost</em>) – </p></li>
<li><p><strong>Boosting             'gbr'                  Regression</strong> (<em>Gradient</em>) – </p></li>
<li><p><strong>Level Perceptron        'mlp'                  Regression</strong> (<em>Multi</em>) – </p></li>
<li><p><strong>Gradient Boosting     'xgboost'              Regression</strong> (<em>Extreme</em>) – </p></li>
<li><p><strong>Gradient Boosting       'lightgbm'             Regression</strong> (<em>Light</em>) – </p></li>
<li><p><strong>Regressor            'catboost'             Regression</strong> (<em>CatBoost</em>) – </p></li>
<li><p><strong>set to None</strong><strong>, </strong><strong>Linear model is used by default for both classification</strong> (<em>If</em>) – </p></li>
<li><p><strong>regression tasks.</strong> (<em>and</em>) – </p></li>
<li><p><strong>optimize</strong> (<em>string</em><em>, </em><em>default = None</em>) – </p></li>
<li><p><strong>Classification tasks</strong> (<em>For</em>) – </p></li>
<li><p><strong>AUC</strong><strong>, </strong><strong>Recall</strong><strong>, </strong><strong>Precision</strong><strong>, </strong><strong>F1</strong><strong>, </strong><strong>Kappa</strong> (<em>Accuracy</em><em>,</em>) – </p></li>
<li><p><strong>Regression tasks</strong> (<em>For</em>) – </p></li>
<li><p><strong>MSE</strong><strong>, </strong><strong>RMSE</strong><strong>, </strong><strong>R2</strong><strong>, </strong><strong>RMSLE</strong><strong>, </strong><strong>MAPE</strong> (<em>MAE</em><em>,</em>) – </p></li>
<li><p><strong>set to None</strong><strong>, </strong><strong>default is 'Accuracy' for classification and 'R2' for</strong> (<em>If</em>) – </p></li>
<li><p><strong>tasks.</strong> (<em>regression</em>) – </p></li>
<li><p><strong>fold</strong> (<em>integer</em><em>, </em><em>default = 10</em>) – </p></li>
<li><p><strong>of folds to be used in Kfold CV. Must be at least 2.</strong> (<em>Number</em>) – </p></li>
<li><p><strong>Returns</strong> – </p></li>
<li><p><strong>--------</strong> – </p></li>
<li><p><strong>plot</strong> (<em>visual</em>) – </p></li>
<li><p><strong>optimize on y-axis. Also</strong><strong>, </strong><strong>prints the best model metric.</strong> (<em>-----------</em>) – </p></li>
<li><p><strong>model</strong> – </p></li>
<li><p><strong>-----------</strong> – </p></li>
<li><p><strong>Warnings</strong> – </p></li>
<li><p><strong>---------</strong> – </p></li>
<li><p><strong>None</strong> – </p></li>
</ul>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="indices-and-tables">
<h1>Indices and tables<a class="headerlink" href="#indices-and-tables" title="Permalink to this headline">¶</a></h1>
<ul class="simple">
<li><p><a class="reference internal" href="genindex.html"><span class="std std-ref">Index</span></a></p></li>
<li><p><a class="reference internal" href="py-modindex.html"><span class="std std-ref">Module Index</span></a></p></li>
<li><p><a class="reference internal" href="search.html"><span class="std std-ref">Search Page</span></a></p></li>
</ul>
</div>


           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2020, Moez Ali

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>